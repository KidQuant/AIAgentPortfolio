{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78388360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from transformers import DecisionTransformerModel\n",
    "import gymnasium as gym\n",
    "import os\n",
    "import pandas as pd\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import INDICATORS, TRAINED_MODEL_DIR, RESULTS_DIR\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from stable_baselines3 import PPO\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "\n",
    "\n",
    "check_and_make_directories([TRAINED_MODEL_DIR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14b437b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00d96072",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "train = train.set_index(train.columns[0])\n",
    "train.index.names =['']\n",
    "\n",
    "trade = pd.read_csv('data/trade.csv')\n",
    "trade = trade.set_index(trade.columns[0])\n",
    "trade.index.names = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa3230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and trade DataFrames from pickle files instead of CSV\n",
    "train = pd.read_pickle('data/train.pickle')\n",
    "train.index.names = ['']\n",
    "\n",
    "trade = pd.read_pickle('data/trade.pickle')\n",
    "trade.index.names = ['']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cf3fd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 394, State Space: 3941\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(trade.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a10b8a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.005] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "e_trade_gym = StockTradingEnv(df=trade, **env_kwargs)\n",
    "env, obs = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29328f45",
   "metadata": {},
   "source": [
    "Here `scale=1000.0` is the normalization factor used training to scale return-to-go. The same value used in the data collator (`DecisionTransformerGymCollator`). It also ensures consistent scaling between training and evalution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc902068",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 1000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8bf93c",
   "metadata": {},
   "source": [
    "Target performance goal for the Decision Transformer (3.6 normalized units). Represents a desired cumulative return of 3600, and the DT will condition its action on achieving this target return. This is the key advantage of Decision Transformers - you can specify different performance goals without retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9d227eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_RETURN = 3600 / scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35b382c",
   "metadata": {},
   "source": [
    "We have the state space dimension, extract the observation space size from the trading environment, and ensure compatbility between the model and environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "434dfbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f03a5e",
   "metadata": {},
   "source": [
    "Here we have the action space dimension, which extracts the action space size from the trading enviroment. This matches the number of stocks being traded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "154305cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_dim = env.action_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba0fca9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3941, 394)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dim, act_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fd8bff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4caf50a82ed44567aab7e783144d33ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk('data/dataset/')\n",
    "\n",
    "state_mean = dataset['state_mean']\n",
    "state_std = dataset['state_std']\n",
    "\n",
    "state_mean = state_mean[:state_dim]\n",
    "state_std = state_std[:state_dim]\n",
    "\n",
    "state_mean = torch.Tensor(state_mean).to(device)\n",
    "state_std = torch.Tensor(state_std).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc4bfef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.0128, -0.0341, -0.0044,  0.0166,  0.0122,  0.0242, -0.0028, -0.0047,\n",
      "          0.0233, -0.0024, -0.0091,  0.0192, -0.0156, -0.0004, -0.0162, -0.0014,\n",
      "         -0.0035, -0.0020, -0.0028,  0.0152,  0.0119,  0.0075, -0.0005, -0.0363,\n",
      "          0.0218, -0.0098,  0.0107, -0.0255, -0.0226,  0.0035,  0.0130, -0.0247,\n",
      "         -0.0025,  0.0002, -0.0202,  0.0056, -0.0101,  0.0394, -0.0184,  0.0301,\n",
      "          0.0017, -0.0112, -0.0177, -0.0022, -0.0097,  0.0270,  0.0065,  0.0073,\n",
      "         -0.0181, -0.0062, -0.0447,  0.0112, -0.0008, -0.0002,  0.0188, -0.0085,\n",
      "         -0.0292,  0.0458, -0.0058,  0.0001, -0.0148,  0.0200, -0.0132,  0.0167,\n",
      "         -0.0113,  0.0187,  0.0211,  0.0154,  0.0254, -0.0035, -0.0044,  0.0016,\n",
      "         -0.0069,  0.0028, -0.0158,  0.0141, -0.0096,  0.0300, -0.0063,  0.0408,\n",
      "         -0.0039, -0.0118, -0.0465,  0.0059,  0.0158, -0.0405, -0.0187, -0.0087,\n",
      "         -0.0003, -0.0008,  0.0157, -0.0109,  0.0011, -0.0051, -0.0198, -0.0023,\n",
      "         -0.0258, -0.0086, -0.0196,  0.0319, -0.0293,  0.0340,  0.0042,  0.0239,\n",
      "         -0.0158,  0.0114, -0.0014,  0.0075, -0.0415,  0.0114, -0.0291,  0.0123,\n",
      "          0.0061, -0.0050,  0.0180,  0.0124,  0.0030,  0.0129, -0.0067, -0.0369,\n",
      "          0.0139, -0.0108,  0.0177, -0.0155, -0.0064,  0.0257,  0.0355, -0.0325]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0334, -0.0396,  0.0102,  ...,  0.0141, -0.0683, -0.0158],\n",
      "        [ 0.0018,  0.0308, -0.0570,  ..., -0.0175, -0.0237,  0.0026],\n",
      "        [-0.0154,  0.0033,  0.0066,  ...,  0.0013,  0.0202, -0.0188],\n",
      "        ...,\n",
      "        [-0.0060,  0.0087,  0.0093,  ..., -0.0142, -0.0252, -0.0125],\n",
      "        [ 0.0163,  0.0005,  0.0035,  ..., -0.0173, -0.0002, -0.0052],\n",
      "        [ 0.0041,  0.0150, -0.0404,  ..., -0.0239,  0.0171, -0.0104]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([1.0340, 1.0267, 1.0474, 1.0279, 1.0316, 1.0424, 1.0403, 1.0322, 1.0478,\n",
      "        1.0683, 1.0446, 1.0214, 1.0293, 1.0344, 1.0371, 1.0260, 1.0746, 1.0390,\n",
      "        1.0154, 1.0752, 1.0423, 1.0168, 1.0647, 1.0468, 1.0485, 1.0517, 1.1094,\n",
      "        1.0347, 1.0641, 1.0196, 1.0384, 1.0344, 1.0340, 1.0357, 1.0728, 1.0276,\n",
      "        1.0361, 1.0629, 1.0460, 1.0514, 1.0541, 1.0271, 1.0496, 1.0247, 1.0391,\n",
      "        1.0220, 1.0424, 1.0280, 1.0403, 1.1479, 1.0295, 1.0323, 1.0335, 1.0296,\n",
      "        1.0218, 1.0287, 1.0360, 1.0265, 1.0707, 1.0081, 1.0180, 1.0159, 1.0376,\n",
      "        1.0282, 1.0355, 1.0633, 1.0427, 1.0379, 1.0459, 1.0275, 1.0467, 1.0180,\n",
      "        1.0601, 1.0137, 1.0400, 1.0191, 1.0363, 1.0635, 1.0263, 1.0260, 1.0684,\n",
      "        1.0578, 1.0764, 1.0298, 1.0430, 1.0138, 1.0260, 1.0570, 1.0248, 1.0312,\n",
      "        1.0439, 1.0567, 1.0198, 1.0536, 1.0295, 1.0262, 1.0316, 1.0288, 1.0352,\n",
      "        1.0564, 1.0307, 1.0291, 1.0592, 1.0358, 1.0388, 1.0269, 1.0414, 1.0331,\n",
      "        1.0344, 1.0877, 1.0422, 1.0310, 1.0420, 1.0332, 1.0211, 1.0146, 1.0879,\n",
      "        1.0293, 1.0770, 1.0371, 1.0284, 1.0252, 1.0259, 1.0376, 1.0223, 1.0314,\n",
      "        1.0268, 1.0272], requires_grad=True), Parameter containing:\n",
      "tensor([-2.3320e-02,  2.6718e-02,  1.5753e-03, -1.2625e-02, -3.5602e-03,\n",
      "        -6.0205e-03,  9.8593e-03, -3.5675e-02, -1.8052e-02,  1.3856e-02,\n",
      "         1.6797e-02, -4.3473e-03,  6.6553e-03,  1.7660e-02, -1.2888e-02,\n",
      "        -6.9015e-04,  4.2470e-02,  9.8335e-03,  3.8140e-03, -2.8343e-02,\n",
      "        -3.4739e-02, -3.4886e-03, -1.0140e-02, -4.6705e-03,  1.5779e-02,\n",
      "         1.2116e-02, -5.3682e-02, -1.4045e-02,  1.5340e-02,  8.5406e-03,\n",
      "         2.1295e-02, -5.7604e-03,  1.1173e-02, -3.4487e-02,  4.0831e-02,\n",
      "         1.0621e-02,  1.0628e-02, -2.0808e-02, -2.0823e-02, -1.0825e-02,\n",
      "         2.3424e-02,  1.8225e-02, -5.9995e-04, -8.0236e-04,  6.6446e-03,\n",
      "         7.4081e-03, -2.2027e-02, -4.1023e-02, -1.6985e-02, -2.5726e-02,\n",
      "        -1.7211e-02,  3.6656e-03, -1.5030e-02,  7.7719e-03,  1.6845e-02,\n",
      "        -3.0868e-03, -2.1545e-04, -6.4639e-03, -2.3848e-02,  7.1417e-03,\n",
      "        -1.9494e-02,  1.7444e-02, -2.6323e-02,  6.5742e-03,  1.9085e-02,\n",
      "         8.5955e-03, -1.2392e-02, -2.9900e-02,  2.0144e-02,  1.2799e-02,\n",
      "         1.0406e-02,  2.9313e-05, -9.4291e-03,  1.2749e-03,  4.5381e-02,\n",
      "         1.3148e-02,  3.2094e-02,  1.2178e-02, -2.1263e-03, -1.4672e-02,\n",
      "         1.5670e-02, -2.3738e-02,  3.9471e-02, -1.1634e-02,  1.6915e-02,\n",
      "         4.7863e-03, -2.5395e-02,  2.3088e-02, -1.6686e-02,  1.2289e-02,\n",
      "         1.2858e-02, -2.2391e-02,  8.8471e-03, -9.2042e-03, -9.1178e-03,\n",
      "        -9.4159e-03,  7.1462e-05,  4.8382e-03,  6.1549e-03, -1.8921e-03,\n",
      "        -6.3817e-03,  1.0936e-02,  2.3114e-02,  1.2387e-02, -2.2366e-02,\n",
      "        -4.6169e-03, -4.1530e-03, -5.9053e-03, -7.9108e-03,  9.2537e-03,\n",
      "        -2.5432e-02,  6.1792e-03, -2.0551e-02,  1.3704e-02,  2.6591e-02,\n",
      "        -1.7811e-02,  1.3695e-02,  1.2756e-02,  1.9291e-02,  1.2954e-02,\n",
      "         5.1967e-03, -3.9824e-02,  3.2694e-02, -2.3329e-02,  1.2906e-02,\n",
      "        -1.0873e-02, -3.5687e-03,  2.1816e-02], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0330, -0.0233,  0.0166,  ..., -0.0163, -0.0412,  0.0311],\n",
      "        [-0.0194, -0.0006, -0.0077,  ..., -0.0018,  0.0238, -0.0190],\n",
      "        [ 0.0185, -0.0098,  0.0346,  ...,  0.0123, -0.0084, -0.0132],\n",
      "        ...,\n",
      "        [ 0.0066, -0.0121, -0.0311,  ...,  0.0107,  0.0289,  0.0234],\n",
      "        [-0.0174,  0.0370, -0.0322,  ..., -0.0147,  0.0618,  0.0250],\n",
      "        [-0.0404, -0.0023, -0.0058,  ..., -0.0265, -0.0129, -0.0128]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 5.7995e-03, -1.1497e-02,  1.3076e-02,  8.8696e-03,  1.0671e-02,\n",
      "         4.4902e-03, -3.1759e-03,  7.1511e-03, -1.6218e-03,  3.8262e-03,\n",
      "        -1.7531e-02, -1.0861e-02,  4.3249e-03, -1.6925e-02, -9.1178e-03,\n",
      "         4.9867e-03, -1.0420e-03,  8.3320e-03, -6.2048e-03, -1.2360e-02,\n",
      "         1.1610e-02, -2.2181e-03,  9.0779e-03, -4.1453e-03, -1.3319e-02,\n",
      "        -7.5456e-03,  1.0966e-04, -2.7527e-02, -1.6503e-02,  5.6521e-03,\n",
      "         1.2484e-03, -3.1877e-03, -1.2789e-02,  1.2587e-02, -1.5410e-03,\n",
      "         2.9008e-03, -1.2658e-02,  6.1261e-03, -1.8490e-04, -1.6069e-03,\n",
      "        -1.1304e-02, -4.7089e-03, -6.2202e-03,  1.1008e-02, -1.3225e-02,\n",
      "         6.3134e-03, -3.5590e-03, -8.2896e-03, -1.1642e-02,  7.3919e-03,\n",
      "         4.5178e-03, -7.4348e-03, -1.6798e-03, -3.7398e-03,  1.4892e-03,\n",
      "         3.9321e-03,  7.1849e-03,  1.2821e-02,  9.9500e-03, -4.5924e-03,\n",
      "         2.0235e-03,  7.8009e-03,  6.4393e-03,  1.9201e-02, -1.3809e-03,\n",
      "        -8.0268e-03,  6.1175e-03, -5.8785e-03, -1.8329e-03, -4.4042e-03,\n",
      "        -2.8727e-03, -2.8728e-03,  9.4871e-03, -7.3696e-03,  1.5817e-02,\n",
      "        -2.1517e-02, -9.3793e-03, -1.1557e-02,  7.3450e-03, -3.9959e-03,\n",
      "        -4.1370e-03, -8.4442e-03, -3.0880e-03, -1.6987e-02,  8.1837e-03,\n",
      "         4.6662e-03, -6.7629e-03, -2.1665e-03,  6.6218e-03,  1.2599e-02,\n",
      "         5.2302e-03,  6.4782e-03, -1.2989e-03,  7.2000e-03, -7.8070e-03,\n",
      "         9.4574e-04, -4.2769e-03,  1.3732e-02,  1.2151e-02, -7.4551e-04,\n",
      "         5.8478e-03,  2.7110e-03,  8.2730e-03, -7.8723e-03, -8.0012e-03,\n",
      "         1.5721e-03,  6.0933e-03, -5.1263e-03,  7.1184e-03, -9.3383e-03,\n",
      "        -3.1059e-03,  2.1018e-03, -6.7375e-03, -9.0892e-03, -3.0728e-03,\n",
      "         8.5424e-03, -4.2050e-03,  3.8147e-03,  9.1787e-03,  3.2644e-03,\n",
      "        -8.1284e-03, -5.7758e-04, -9.3419e-03, -4.7219e-03,  1.9041e-02,\n",
      "         4.5840e-03,  6.9437e-03, -1.3348e-03, -2.2806e-08,  2.6052e-08,\n",
      "        -1.8822e-08,  2.2630e-08, -3.6339e-08,  6.8686e-09,  3.5053e-08,\n",
      "        -8.0864e-09, -3.6395e-08, -5.0898e-09, -1.2189e-08,  1.0168e-08,\n",
      "         4.8445e-08,  2.1382e-09, -3.1657e-08,  5.4500e-08, -1.8475e-08,\n",
      "         5.8860e-09,  9.9473e-09,  2.8187e-09, -5.0806e-08, -3.1486e-08,\n",
      "         5.0603e-09, -3.2466e-09,  2.4293e-08,  3.3750e-08, -1.5142e-08,\n",
      "         6.2900e-09,  2.3538e-08, -2.5171e-08, -6.0498e-10, -6.2515e-08,\n",
      "         1.4345e-08,  2.4854e-08,  2.1520e-08, -4.6481e-08,  4.2959e-08,\n",
      "        -3.5966e-08, -2.2459e-08, -4.2829e-09, -1.1174e-08,  4.4583e-08,\n",
      "         5.4931e-08, -1.1708e-08, -7.6958e-09,  8.0108e-09, -3.4805e-08,\n",
      "         7.0854e-09,  2.7277e-08,  1.3833e-09, -2.2840e-08,  1.2582e-08,\n",
      "         6.2417e-08,  4.5241e-08,  1.4250e-08, -8.2447e-09,  3.9188e-08,\n",
      "         6.4853e-08, -1.0271e-08,  1.2857e-08, -5.5876e-09,  2.2956e-08,\n",
      "         3.0967e-10,  2.9108e-08, -3.6769e-08,  1.0460e-08,  2.5004e-08,\n",
      "        -6.9630e-09, -1.4151e-08, -4.8292e-08, -2.9658e-08,  8.1024e-09,\n",
      "        -1.6704e-08,  1.3707e-08,  1.2667e-08, -8.3377e-10,  4.0439e-08,\n",
      "         1.1837e-08, -2.7547e-08,  7.0319e-09,  3.7140e-08,  9.3464e-09,\n",
      "         6.5766e-08, -7.2995e-08, -4.4099e-09,  1.4047e-08,  2.0535e-08,\n",
      "        -4.0770e-09, -6.4116e-08,  1.8018e-08,  4.7085e-08,  5.1244e-08,\n",
      "        -4.2757e-08, -6.2834e-08,  4.5805e-08,  6.0055e-09, -6.4734e-08,\n",
      "        -6.0556e-09, -3.8203e-08, -4.8610e-08,  9.5684e-09,  7.6665e-08,\n",
      "        -3.3446e-08, -1.0466e-08, -1.8773e-08, -2.9810e-08, -3.1995e-08,\n",
      "         7.9117e-09, -7.7743e-09,  1.8677e-08, -3.9927e-08,  1.2521e-08,\n",
      "         8.9829e-09, -7.1173e-09,  3.6185e-08, -2.0278e-08,  1.0389e-08,\n",
      "         2.5418e-08,  1.3766e-08,  3.5655e-08,  1.0293e-08, -2.6619e-08,\n",
      "        -9.4667e-09,  2.1319e-08, -1.0298e-08, -4.6303e-08, -1.0921e-08,\n",
      "        -4.5843e-08,  5.3766e-03,  9.0822e-04,  3.9760e-03, -3.7198e-03,\n",
      "         8.5124e-03,  3.0388e-03, -3.3592e-03,  2.0662e-03, -4.3705e-03,\n",
      "        -1.8520e-03,  1.4429e-02,  9.6342e-04,  1.1470e-02, -7.0293e-03,\n",
      "         1.0937e-03,  1.1557e-02, -1.5898e-02,  5.7781e-03, -3.0678e-03,\n",
      "         4.4493e-03, -7.5994e-03, -1.6531e-03, -9.5995e-03,  1.8879e-03,\n",
      "        -7.0934e-03, -2.4469e-02, -8.6470e-03, -5.3570e-03, -7.0946e-03,\n",
      "         3.0378e-03,  6.4805e-03, -5.6707e-03,  1.1770e-02,  1.0077e-03,\n",
      "         7.8870e-03,  3.7771e-03, -2.5432e-02, -7.1834e-03,  1.4624e-02,\n",
      "        -1.5783e-02,  3.6907e-03,  1.1159e-02,  2.1720e-04,  2.5564e-03,\n",
      "         1.4118e-03, -2.7453e-02,  4.9138e-03, -1.6392e-02, -9.8454e-03,\n",
      "        -5.4087e-03,  1.1179e-03, -2.2670e-03,  1.4312e-02,  1.0501e-02,\n",
      "        -1.8188e-02, -5.7807e-03, -5.7491e-03, -2.6061e-03,  3.5754e-03,\n",
      "         6.8263e-03,  3.9905e-03, -4.6717e-03, -3.5730e-03,  2.4734e-03,\n",
      "        -2.6674e-05, -2.2047e-03, -2.9564e-02,  4.6575e-03, -2.3114e-03,\n",
      "        -1.0975e-02, -2.4866e-03, -5.5359e-03, -3.0741e-03, -1.3923e-03,\n",
      "        -1.7092e-02, -1.4098e-02,  8.7170e-05,  2.3561e-03, -2.0054e-02,\n",
      "         4.3077e-03,  2.9146e-03,  1.0715e-03, -8.0494e-03, -6.1075e-03,\n",
      "        -3.9887e-03,  3.8061e-03, -3.0538e-03,  9.7142e-04,  1.3579e-02,\n",
      "        -4.7350e-03, -1.0377e-02, -3.2647e-03,  1.0603e-02, -2.4814e-03,\n",
      "        -4.3272e-02,  2.6746e-02, -5.0929e-03,  3.2925e-02, -1.5827e-03,\n",
      "        -9.8901e-04, -4.5992e-03, -5.6028e-03, -4.5047e-03,  1.5470e-02,\n",
      "        -1.1700e-02,  3.3876e-02, -6.3645e-03, -5.3794e-03, -5.2761e-03,\n",
      "         9.0116e-03,  5.8657e-03,  3.9707e-03,  9.4489e-05,  2.4353e-03,\n",
      "        -1.2696e-02,  3.0584e-02, -3.5561e-03,  4.1785e-03, -1.1211e-02,\n",
      "         1.0982e-02, -2.1981e-03,  3.6953e-02, -3.0189e-04, -2.3479e-03,\n",
      "         1.8415e-02,  3.1739e-03, -4.1619e-03, -4.0390e-04],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0001, -0.0098, -0.0086,  ...,  0.0103, -0.0095,  0.0070],\n",
      "        [ 0.0155, -0.0082, -0.0002,  ...,  0.0212,  0.0090,  0.0164],\n",
      "        [-0.0078,  0.0049,  0.0078,  ..., -0.0199,  0.0048,  0.0088],\n",
      "        ...,\n",
      "        [ 0.0084, -0.0152, -0.0077,  ...,  0.0181,  0.0023, -0.0015],\n",
      "        [-0.0038,  0.0065,  0.0102,  ..., -0.0313,  0.0071, -0.0107],\n",
      "        [ 0.0017,  0.0117, -0.0228,  ..., -0.0368,  0.0242,  0.0089]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-3.8448e-03,  1.1096e-03, -1.0304e-03, -5.5583e-03, -1.0690e-03,\n",
      "        -1.9664e-03, -9.1417e-04, -1.3602e-02, -4.1706e-03,  2.3291e-03,\n",
      "         3.2893e-03,  1.2091e-03,  2.0002e-03, -2.2209e-03, -2.1480e-03,\n",
      "        -2.3244e-03,  2.5298e-03,  2.8468e-03, -2.5096e-04, -1.5494e-03,\n",
      "        -1.8252e-02, -3.7513e-03, -2.5751e-03,  8.0764e-03,  3.8278e-03,\n",
      "         3.2890e-03,  2.1726e-03, -1.0675e-03,  2.0445e-03,  2.6869e-03,\n",
      "        -3.0047e-03, -6.4233e-04,  2.8814e-03, -6.1396e-03,  7.8331e-03,\n",
      "         2.5659e-03,  5.7515e-03, -2.3764e-03,  3.2203e-04, -4.3200e-03,\n",
      "        -1.5974e-03,  7.1480e-03, -5.1897e-03,  5.0266e-03,  4.6756e-03,\n",
      "         6.4593e-04, -2.7648e-03,  6.0475e-04, -6.9545e-03, -6.1466e-03,\n",
      "        -3.0832e-03, -1.7976e-03,  8.4766e-04,  1.7559e-03,  2.0662e-03,\n",
      "        -2.2431e-03, -3.3869e-03, -1.2303e-03,  2.4344e-03, -6.3266e-04,\n",
      "        -3.7252e-03,  1.9088e-03, -3.5311e-03, -4.9543e-03,  3.6204e-03,\n",
      "         5.4593e-03, -3.5386e-03, -4.2386e-03,  1.7230e-03, -3.3668e-03,\n",
      "         3.2351e-03, -4.4868e-03,  1.7527e-03,  3.9470e-03, -6.8933e-04,\n",
      "         1.4463e-03,  8.6503e-05,  4.4714e-03, -6.3677e-03,  2.2635e-03,\n",
      "         4.0368e-03, -2.2293e-04,  1.0642e-02, -9.0474e-03,  2.6385e-03,\n",
      "         1.5998e-03, -2.0350e-03,  6.3514e-04, -4.4548e-03,  4.0352e-03,\n",
      "         2.6450e-04, -3.0490e-03,  1.2206e-03, -1.3582e-03, -4.7777e-03,\n",
      "         3.5335e-04, -4.6042e-03,  4.6223e-03, -2.2022e-03,  1.1078e-03,\n",
      "         5.3564e-03, -3.4485e-03,  2.4740e-03,  2.5865e-03, -2.2478e-03,\n",
      "         1.6659e-03, -4.4499e-03,  1.6105e-03,  9.9426e-04, -7.3194e-04,\n",
      "        -5.0343e-03, -1.9143e-03,  8.9242e-04, -1.2502e-03,  2.7510e-03,\n",
      "         2.0312e-03, -1.1426e-03, -1.4411e-03, -1.5227e-03,  2.8880e-03,\n",
      "        -3.1810e-03, -5.8883e-03,  2.7089e-03, -7.7396e-04,  1.9851e-03,\n",
      "         6.3298e-03, -1.4511e-03,  1.3105e-03], requires_grad=True), Parameter containing:\n",
      "tensor([1.0289, 1.0465, 1.0529, 1.0294, 1.0502, 1.1094, 1.0314, 1.0366, 1.0622,\n",
      "        1.0842, 1.0452, 1.0246, 1.0290, 1.0269, 1.0635, 1.0242, 1.0752, 1.0396,\n",
      "        1.0245, 1.0551, 1.1437, 1.0215, 1.0588, 1.2302, 1.0570, 1.0722, 1.0857,\n",
      "        1.0273, 1.0806, 1.0505, 1.0670, 1.0299, 1.0743, 1.0516, 1.0483, 1.0292,\n",
      "        1.0493, 1.0843, 1.0233, 1.0352, 1.1101, 1.0237, 1.0746, 1.1337, 1.0966,\n",
      "        1.0921, 1.0347, 1.0317, 1.0409, 1.1192, 1.0202, 1.0290, 1.0703, 1.0370,\n",
      "        1.0160, 1.0611, 1.0425, 1.0726, 1.0989, 1.0196, 1.0265, 1.0242, 1.0242,\n",
      "        1.0480, 1.0347, 1.0334, 1.0223, 1.0283, 1.0190, 1.0561, 1.0714, 1.0344,\n",
      "        1.0365, 1.0204, 1.0427, 1.0625, 1.0629, 1.0699, 1.0407, 1.0474, 1.1856,\n",
      "        1.0502, 1.0485, 1.0322, 1.0360, 1.0236, 1.0189, 1.0616, 1.0266, 1.0449,\n",
      "        1.0315, 1.1510, 1.0298, 1.0791, 1.0214, 1.0414, 1.0407, 1.0283, 1.0985,\n",
      "        1.0340, 1.0473, 1.0443, 1.0558, 1.0402, 1.0188, 1.0163, 1.0741, 1.0296,\n",
      "        1.1249, 1.0401, 1.0275, 1.0314, 1.0209, 1.0202, 1.1085, 1.0334, 1.1137,\n",
      "        1.0325, 1.0817, 1.0606, 1.0402, 1.0250, 1.0375, 1.1213, 1.0178, 1.2298,\n",
      "        1.0316, 1.0204], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0175, -0.0181,  0.0032,  0.0037, -0.0142, -0.0201, -0.0047,  0.0137,\n",
      "        -0.0400,  0.0018, -0.0191, -0.0100,  0.0062, -0.0457, -0.0245, -0.0070,\n",
      "        -0.0309,  0.0327,  0.0190, -0.0076, -0.0326, -0.0236, -0.0261,  0.0503,\n",
      "         0.0084,  0.0078,  0.0252,  0.0066,  0.0189,  0.0206,  0.0070,  0.0090,\n",
      "         0.0510, -0.0110,  0.0180, -0.0044,  0.0291, -0.0274,  0.0242,  0.0177,\n",
      "         0.0034, -0.0151,  0.0218,  0.0346,  0.0351,  0.0135,  0.0162,  0.0018,\n",
      "         0.0213,  0.0031,  0.0182,  0.0067, -0.0338, -0.0111, -0.0123, -0.0065,\n",
      "        -0.0318, -0.0116,  0.0336,  0.0189, -0.0016, -0.0010, -0.0177,  0.0413,\n",
      "         0.0110, -0.0217,  0.0002,  0.0061, -0.0083, -0.0123,  0.0231, -0.0316,\n",
      "         0.0287,  0.0284, -0.0164, -0.0081, -0.0039,  0.0119, -0.0218, -0.0133,\n",
      "        -0.0449,  0.0234,  0.0310, -0.0008,  0.0147,  0.0008,  0.0055, -0.0090,\n",
      "        -0.0175,  0.0158, -0.0143, -0.0309, -0.0088,  0.0055,  0.0200,  0.0133,\n",
      "        -0.0218,  0.0112, -0.0395, -0.0194, -0.0205, -0.0559,  0.0053,  0.0324,\n",
      "         0.0016,  0.0251, -0.0435, -0.0043,  0.0229, -0.0160, -0.0078, -0.0116,\n",
      "         0.0250, -0.0237,  0.0141,  0.0389, -0.0321, -0.0219, -0.0286,  0.0304,\n",
      "         0.0151, -0.0093,  0.0122,  0.0033, -0.0034,  0.0610, -0.0177, -0.0164],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0025, -0.0060,  0.0133,  ...,  0.0341, -0.0201,  0.0258],\n",
      "        [-0.0155, -0.0247, -0.0527,  ..., -0.0285,  0.0236, -0.0292],\n",
      "        [-0.0175, -0.0259,  0.0029,  ...,  0.0124, -0.0321, -0.0577],\n",
      "        ...,\n",
      "        [ 0.0565, -0.0333,  0.1621,  ..., -0.0185, -0.0502,  0.0620],\n",
      "        [ 0.0048, -0.0044, -0.0185,  ..., -0.0004,  0.0198,  0.0065],\n",
      "        [-0.0127, -0.0208, -0.0228,  ...,  0.0168,  0.0055, -0.0377]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 5.0296e-03,  8.2323e-03,  1.3627e-02,  1.6011e-02,  1.3753e-02,\n",
      "         1.0040e-02,  2.3737e-03,  7.9809e-03,  6.5229e-03,  1.2186e-02,\n",
      "         7.5377e-03,  1.2636e-02,  4.2037e-03,  1.6627e-03,  2.8476e-03,\n",
      "         8.0566e-03,  6.1065e-03,  1.5531e-02,  1.4254e-02,  4.9860e-03,\n",
      "         1.2518e-03,  1.8276e-02,  7.3854e-03,  9.5548e-03,  1.0223e-02,\n",
      "        -1.9270e-03,  1.7039e-02,  4.4976e-03,  8.6125e-03,  8.3045e-03,\n",
      "         9.8289e-03,  9.4106e-03,  1.5195e-02,  3.1309e-03,  8.2800e-03,\n",
      "         6.8945e-03,  7.6560e-03,  2.6234e-02,  1.0111e-02,  1.8133e-02,\n",
      "         9.3728e-03,  1.8254e-02,  5.5609e-03,  9.0675e-03,  2.4563e-02,\n",
      "         9.7584e-03,  1.0450e-02,  6.2454e-03,  1.1765e-02,  1.0167e-02,\n",
      "         1.7924e-02,  2.1215e-02,  4.0231e-03,  1.3409e-02,  2.2013e-02,\n",
      "         5.9913e-03,  9.6789e-03,  3.9341e-03,  1.6047e-02,  8.5607e-03,\n",
      "         1.7015e-02,  1.1987e-02, -5.6971e-04,  3.5293e-03, -4.8555e-03,\n",
      "         5.4257e-03,  1.3247e-02,  1.6501e-02,  1.0115e-02,  7.1410e-03,\n",
      "         9.5233e-03,  1.5633e-02,  1.3769e-02,  3.0084e-03, -6.6023e-04,\n",
      "         4.8835e-03,  1.1113e-02,  1.9855e-03,  9.0786e-03,  5.6822e-03,\n",
      "         1.6549e-02,  8.3610e-03,  1.0378e-02,  1.9266e-02,  1.4968e-02,\n",
      "         7.8348e-03,  1.3051e-02,  4.6191e-03,  6.9196e-03,  9.6350e-03,\n",
      "         1.0726e-02,  1.5879e-02,  3.0179e-03,  7.2825e-03,  5.7711e-03,\n",
      "         5.8632e-03,  7.2929e-03,  8.8388e-03,  4.8110e-03,  6.2890e-03,\n",
      "         5.0014e-03,  6.1739e-03,  1.3180e-02,  6.2917e-03,  1.2258e-02,\n",
      "         1.2815e-02,  7.8378e-03,  1.2748e-02,  1.7747e-02,  1.9462e-02,\n",
      "         1.2340e-02,  1.1657e-02,  1.2727e-02,  1.2041e-02, -1.1641e-02,\n",
      "         1.7336e-02,  6.6496e-03,  1.6568e-02,  2.7838e-03,  1.5982e-02,\n",
      "         7.4377e-03,  3.4179e-03,  1.8719e-02,  1.2185e-02,  5.4055e-03,\n",
      "         1.1895e-02,  1.7710e-02,  1.4911e-02,  7.3967e-03,  1.2452e-02,\n",
      "         1.3903e-02,  7.6536e-03,  8.9372e-03,  1.4881e-02,  1.5503e-02,\n",
      "         4.2572e-03,  6.9609e-03,  1.4534e-02,  2.2568e-02,  8.7758e-03,\n",
      "         4.1498e-03,  7.5105e-03,  1.0271e-03,  1.6563e-02,  1.0597e-02,\n",
      "         3.9158e-03,  6.6833e-03,  8.5954e-03,  1.2365e-02,  1.0529e-02,\n",
      "         1.5684e-02,  9.7540e-03,  1.7678e-02,  9.2787e-03,  9.1526e-03,\n",
      "        -2.2447e-03,  9.4237e-03,  1.1343e-02,  2.5623e-03,  9.8231e-03,\n",
      "         7.2327e-03,  5.6272e-03,  9.0415e-03,  7.4374e-03,  5.8124e-03,\n",
      "         6.5037e-03,  1.2919e-02,  2.3153e-02,  1.0348e-02,  5.0768e-03,\n",
      "         8.7918e-03, -3.5409e-03,  8.8453e-03, -1.9152e-02,  2.0646e-03,\n",
      "         1.0914e-02,  1.0675e-02,  3.5634e-03,  7.7845e-03,  9.5569e-03,\n",
      "         4.5212e-03,  1.2505e-02,  6.9393e-03,  1.2746e-03,  6.0784e-03,\n",
      "         1.1577e-03,  6.8455e-03,  1.1868e-02,  1.9302e-02,  7.5543e-03,\n",
      "         9.4715e-03,  3.9991e-03,  3.1345e-03,  1.1401e-02,  9.1991e-03,\n",
      "         4.3524e-03,  7.4460e-03,  6.0344e-03, -2.4126e-03,  1.6825e-02,\n",
      "         4.9191e-03,  6.7262e-03, -2.0362e-03,  1.2685e-02, -1.1757e-03,\n",
      "         1.0539e-02,  5.5874e-03, -1.1805e-02,  1.0017e-02,  2.2145e-02,\n",
      "         6.8414e-03,  7.4389e-03,  5.7461e-03,  1.0691e-02,  3.3439e-03,\n",
      "         5.8962e-03,  9.1845e-03,  1.1185e-02,  6.0206e-03,  6.6376e-03,\n",
      "         1.0668e-02,  4.7640e-03,  1.3772e-02,  1.4549e-02,  1.6278e-03,\n",
      "        -1.0868e-02,  3.4752e-03,  2.9492e-03,  4.4485e-03,  9.9833e-03,\n",
      "         2.2286e-03,  1.3255e-02,  2.3425e-02,  1.3223e-02,  1.1189e-02,\n",
      "         2.1321e-02,  8.7269e-03,  9.3128e-03,  1.7263e-02,  7.7093e-03,\n",
      "         1.1066e-02,  8.6599e-03,  6.7718e-03,  2.5550e-02,  8.8698e-03,\n",
      "         6.3745e-03,  7.1172e-03, -1.1521e-02,  6.2895e-03,  6.0922e-03,\n",
      "         1.0414e-02,  9.2001e-03, -3.1110e-03,  5.1078e-03,  4.4946e-04,\n",
      "         1.1908e-02,  2.2864e-02,  6.1729e-03,  4.1104e-03,  1.8170e-02,\n",
      "         8.2164e-03,  1.4130e-02,  6.9111e-03,  9.9716e-03,  4.5637e-03,\n",
      "         6.0423e-03,  1.1203e-02,  1.2331e-02,  8.7716e-03,  7.6513e-03,\n",
      "         3.6047e-03,  1.5134e-02,  7.3585e-03,  4.3625e-03, -1.4818e-03,\n",
      "         3.6603e-03,  6.4185e-03,  9.5129e-03,  7.9294e-03,  2.2155e-02,\n",
      "         1.2450e-02,  1.4287e-02,  1.2320e-02,  5.0873e-03,  5.5050e-03,\n",
      "         4.1475e-04,  1.1415e-02,  3.3966e-03,  2.9299e-03,  2.7016e-02,\n",
      "         2.2688e-03,  1.2606e-02,  8.1991e-03,  7.5480e-03,  2.7253e-02,\n",
      "         2.8582e-03,  4.8466e-03, -3.8526e-04,  6.2941e-03,  1.3643e-03,\n",
      "         6.9470e-03,  1.0111e-02,  8.3883e-03,  3.1115e-02,  1.0727e-02,\n",
      "         1.5936e-02,  5.3832e-03,  1.0901e-02,  6.1997e-03,  6.5117e-03,\n",
      "         1.0538e-02,  2.2184e-02,  4.5100e-03,  1.8222e-02,  1.7225e-03,\n",
      "         7.7208e-03,  7.4947e-03,  1.0022e-02,  1.3181e-02,  3.7434e-03,\n",
      "         1.2159e-02,  7.8289e-03,  1.0752e-02,  3.2127e-03,  4.1582e-03,\n",
      "         8.0815e-03,  5.8525e-03,  8.5351e-03,  1.9897e-03,  2.4121e-03,\n",
      "         1.0562e-02,  6.7405e-03,  5.7872e-03,  6.4850e-03,  7.0209e-03,\n",
      "         2.5305e-03,  9.3585e-03,  1.5306e-02,  5.9823e-03,  1.0917e-02,\n",
      "         1.0686e-02,  1.0809e-02, -1.0649e-02,  7.9738e-03,  2.1794e-02,\n",
      "         1.4274e-02,  6.5852e-03,  3.3232e-03, -4.1862e-03,  1.4391e-02,\n",
      "         1.9849e-02,  1.1811e-02,  9.8669e-03,  2.3070e-02,  1.9273e-02,\n",
      "         7.1268e-03,  3.6633e-03,  1.1915e-02,  1.2655e-02, -7.2937e-03,\n",
      "         7.4760e-03,  2.0265e-02,  1.3318e-02,  3.7830e-03,  2.1367e-02,\n",
      "         5.0722e-03,  1.6248e-02,  6.3708e-03, -6.4488e-03,  7.2646e-03,\n",
      "         5.3211e-03,  2.0694e-02,  7.0672e-03,  9.7320e-03,  8.4361e-03,\n",
      "         7.9191e-03,  8.8924e-03,  5.0569e-04,  4.0393e-03,  1.5008e-02,\n",
      "         3.7140e-03,  6.7491e-03,  7.0430e-03,  3.6264e-03,  9.0903e-04,\n",
      "        -1.2222e-02,  8.0920e-03,  7.2640e-03,  4.9342e-03,  3.9975e-03,\n",
      "         7.6750e-03,  9.2689e-03,  7.5226e-03,  5.5718e-03,  1.2740e-02,\n",
      "         2.4151e-02,  1.1323e-02, -7.2918e-03,  5.3917e-03,  1.2293e-02,\n",
      "         3.6310e-03, -1.9707e-03,  5.8933e-03,  2.1498e-02,  3.6107e-03,\n",
      "        -6.0570e-03,  6.0574e-03,  4.0122e-03,  2.0382e-03,  6.1037e-03,\n",
      "         8.2768e-03,  1.5695e-02,  5.7870e-03,  1.2108e-02,  6.0271e-03,\n",
      "         1.1744e-02,  9.5919e-03,  6.9007e-03,  1.6366e-02,  1.0969e-02,\n",
      "         1.2358e-02,  6.6606e-03,  9.2441e-03,  1.4971e-02,  1.0952e-02,\n",
      "         1.5664e-02,  5.7043e-03,  6.0633e-03,  4.7994e-03,  3.3953e-03,\n",
      "         7.3866e-03,  2.2545e-02,  1.7529e-02,  1.2833e-02,  4.4508e-03,\n",
      "        -8.4656e-03,  7.3681e-03,  3.8789e-03,  6.5965e-03,  1.6354e-03,\n",
      "         1.6951e-02,  6.5067e-03,  3.3525e-03,  1.0364e-02,  1.0641e-02,\n",
      "         1.4839e-02,  5.3064e-03,  1.0531e-02,  1.0662e-02,  1.4823e-02,\n",
      "         7.5130e-03, -2.7205e-04,  4.8538e-03,  1.6976e-02,  3.8831e-03,\n",
      "         6.6262e-03,  7.3971e-03,  1.6039e-03,  1.7053e-02,  1.6046e-02,\n",
      "         5.8955e-03,  3.5008e-03,  1.1179e-02,  8.0998e-03,  1.5004e-02,\n",
      "        -2.4556e-03,  1.2012e-02,  1.0169e-02,  1.4098e-02,  8.2107e-03,\n",
      "         5.4038e-03,  1.2993e-02,  1.2628e-02,  5.6449e-03,  1.2824e-02,\n",
      "         9.8375e-03,  1.0671e-02,  1.2098e-02,  1.1968e-02,  1.3238e-02,\n",
      "         2.1105e-02,  9.0338e-03,  4.4964e-03, -2.5989e-04,  9.0216e-03,\n",
      "         2.0884e-02,  7.0263e-03,  6.2588e-03,  1.1657e-02,  5.0038e-03,\n",
      "         2.3815e-03,  8.6406e-03,  8.9744e-03,  6.5481e-03,  3.6595e-03,\n",
      "         7.1486e-03,  2.9423e-03,  2.2490e-03,  2.1775e-02, -3.0709e-05,\n",
      "         1.1628e-02,  9.8271e-03,  1.2688e-02,  1.1497e-02,  1.4062e-02,\n",
      "         2.3052e-03,  8.4336e-03,  5.1244e-04, -5.5036e-03,  1.0197e-02,\n",
      "         1.1839e-02,  8.2404e-03], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0138,  0.0122, -0.0062,  ..., -0.0007,  0.0001,  0.0135],\n",
      "        [ 0.0148, -0.0186, -0.0003,  ...,  0.0234,  0.0129, -0.0016],\n",
      "        [-0.0002,  0.0068,  0.0185,  ..., -0.0033, -0.0030,  0.0031],\n",
      "        ...,\n",
      "        [ 0.0076,  0.0038,  0.0013,  ...,  0.0264, -0.0048,  0.0045],\n",
      "        [ 0.0004,  0.0215, -0.0078,  ..., -0.0113, -0.0159,  0.0110],\n",
      "        [ 0.0077,  0.0086,  0.0082,  ...,  0.0100,  0.0010,  0.0148]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 1.7297e-03,  1.8331e-04, -1.1236e-03, -2.3647e-03, -1.6556e-03,\n",
      "        -2.4378e-03, -1.2958e-03, -5.5296e-03, -3.5114e-03,  1.6204e-03,\n",
      "        -1.6123e-03, -4.7052e-04,  2.2385e-03, -2.0982e-03, -5.9209e-04,\n",
      "        -2.4994e-03,  3.0457e-04,  2.3269e-03,  2.9239e-03, -1.6697e-04,\n",
      "        -1.0442e-02, -2.7670e-03, -2.5857e-03,  4.9175e-03,  2.3741e-03,\n",
      "         3.8834e-03,  1.0441e-03, -1.3742e-03,  2.8401e-03,  1.8027e-03,\n",
      "         1.1656e-02, -5.7452e-04,  2.4562e-03, -4.3621e-03,  7.0868e-03,\n",
      "         2.6518e-03,  3.7346e-03, -2.3644e-03,  7.9217e-04, -2.6372e-03,\n",
      "        -6.6845e-04,  3.0940e-03,  2.9390e-03,  2.5292e-03,  3.4090e-03,\n",
      "         7.6884e-04, -2.1151e-03,  7.4023e-04,  1.3421e-03, -3.8216e-03,\n",
      "        -7.2566e-04, -1.1263e-03, -6.9989e-04, -5.5997e-04,  1.5222e-03,\n",
      "        -1.6914e-03, -2.6559e-03, -4.4795e-03,  1.5949e-03, -1.8472e-04,\n",
      "        -2.8635e-03,  1.6937e-03, -3.1811e-03,  2.2505e-03,  2.4466e-03,\n",
      "         2.3748e-04, -2.8364e-03, -9.1419e-04,  1.6155e-03, -4.1572e-03,\n",
      "         3.5251e-03, -2.5775e-03,  1.4644e-03,  4.5815e-03, -1.1903e-03,\n",
      "        -1.8124e-03, -1.4111e-03,  2.8111e-03, -4.7989e-03,  3.2876e-04,\n",
      "        -2.0634e-05, -1.1334e-03,  3.8209e-03, -4.7718e-03,  2.0121e-03,\n",
      "         1.4153e-03, -1.3386e-03,  1.9364e-03, -2.9467e-03,  4.0138e-03,\n",
      "        -5.5027e-04, -2.9389e-03, -1.6087e-06, -2.3518e-03, -3.5623e-03,\n",
      "         2.8453e-03, -9.4261e-03,  3.3009e-03, -1.6012e-03, -2.4494e-03,\n",
      "         1.5380e-03, -3.6041e-03,  2.3971e-03,  2.4329e-03,  1.8736e-04,\n",
      "         1.6743e-03, -2.8131e-03, -1.5700e-03,  1.9598e-03, -1.9849e-03,\n",
      "        -2.6470e-03, -8.0510e-04,  1.4297e-03, -1.6990e-03,  2.3127e-03,\n",
      "         5.0686e-04, -8.9606e-04, -1.5354e-03, -1.6570e-03,  2.6997e-03,\n",
      "         1.4488e-03, -3.7801e-03,  2.5279e-03, -2.0785e-03,  1.6349e-03,\n",
      "        -8.0579e-05, -3.2137e-03,  2.8340e-04], requires_grad=True), Parameter containing:\n",
      "tensor([1.0416, 1.0444, 1.1433, 1.0516, 1.0653, 1.0290, 1.0408, 1.1152, 1.0489,\n",
      "        1.0999, 1.0823, 1.0274, 1.0277, 1.0693, 1.0552, 1.0466, 1.0508, 1.0432,\n",
      "        1.0200, 1.0770, 1.0555, 1.0751, 1.0593, 1.0842, 1.1163, 1.0712, 1.1661,\n",
      "        1.0472, 1.0668, 1.0326, 1.0649, 1.0321, 1.0298, 1.0492, 1.1076, 1.0251,\n",
      "        1.0693, 1.1247, 1.0438, 1.0890, 1.1077, 1.0710, 1.0493, 1.0517, 1.0506,\n",
      "        1.0696, 1.0457, 1.0423, 1.0613, 1.1435, 1.0732, 1.0541, 1.0534, 1.0465,\n",
      "        1.0338, 1.0265, 1.0605, 1.0383, 1.0732, 1.0405, 1.0226, 1.0371, 1.0688,\n",
      "        1.0209, 1.0420, 1.0633, 1.0423, 1.0474, 1.0529, 1.0481, 1.0996, 1.0701,\n",
      "        1.1263, 1.0355, 1.0391, 1.0628, 1.0678, 1.0866, 1.0526, 1.0300, 1.1962,\n",
      "        1.1163, 1.1129, 1.0828, 1.0539, 1.0613, 1.0335, 1.0649, 1.0403, 1.0287,\n",
      "        1.0908, 1.0414, 1.0500, 1.0353, 1.0601, 1.0500, 1.0402, 1.0461, 1.0313,\n",
      "        1.0757, 1.0799, 1.0342, 1.0452, 1.0360, 1.0581, 1.0264, 1.0222, 1.0528,\n",
      "        1.0478, 1.1469, 1.0872, 1.0401, 1.0113, 1.0346, 1.0626, 1.0387, 1.1310,\n",
      "        1.0159, 1.1185, 1.0555, 1.0295, 1.0737, 1.0531, 1.0394, 1.0323, 1.0647,\n",
      "        1.0229, 1.0438], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0255, -0.0314,  0.0209, -0.0331,  0.0145, -0.0252, -0.0117, -0.0729,\n",
      "        -0.0309,  0.0481,  0.0260, -0.0130,  0.0176, -0.0219, -0.0212, -0.0129,\n",
      "        -0.0056,  0.0271,  0.0124, -0.0268, -0.0399, -0.0290, -0.0384, -0.0057,\n",
      "         0.0421,  0.0218, -0.0343, -0.0190,  0.0364,  0.0280,  0.0710, -0.0376,\n",
      "         0.0215, -0.0344,  0.0255,  0.0215,  0.0385, -0.0473,  0.0123, -0.0293,\n",
      "         0.0439,  0.0424,  0.0209, -0.0023,  0.0297, -0.0072, -0.0152,  0.0230,\n",
      "        -0.0288, -0.0290, -0.0261,  0.0105, -0.0292, -0.0189,  0.0335, -0.0154,\n",
      "        -0.0135, -0.0164, -0.0342,  0.0168, -0.0201,  0.0313, -0.0356,  0.0135,\n",
      "         0.0340,  0.0187, -0.0356, -0.0165,  0.0351, -0.0237,  0.0400, -0.0370,\n",
      "        -0.0423,  0.0125,  0.0046, -0.0193,  0.0154,  0.0373, -0.0270, -0.0124,\n",
      "         0.0507, -0.0328,  0.0511, -0.0531,  0.0170,  0.0131, -0.0497,  0.0253,\n",
      "        -0.0368,  0.0268,  0.0335, -0.0249,  0.0654, -0.0244, -0.0527,  0.0085,\n",
      "        -0.0052, -0.0069,  0.0106, -0.0087,  0.0244,  0.0182,  0.0233,  0.0256,\n",
      "        -0.0408,  0.0127,  0.0162, -0.0120, -0.0075,  0.0090, -0.0344, -0.0114,\n",
      "        -0.0083,  0.0232,  0.0371, -0.0103,  0.0354,  0.0121,  0.0253,  0.0391,\n",
      "         0.0163, -0.0455,  0.0283, -0.0260, -0.0089,  0.0110, -0.0116,  0.0283],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-4.7640e-02,  3.7815e-02,  1.9834e-02,  ...,  4.8286e-03,\n",
      "         -1.7752e-02,  1.3293e-03],\n",
      "        [-8.2401e-03,  1.3867e-02, -1.9289e-05,  ...,  2.6750e-02,\n",
      "          1.5766e-02, -1.1261e-02],\n",
      "        [ 7.6146e-02, -4.0139e-02, -7.9160e-02,  ..., -3.2167e-02,\n",
      "          2.5165e-02, -5.0030e-02],\n",
      "        ...,\n",
      "        [-7.6820e-02,  5.5224e-02,  4.0576e-02,  ...,  1.6240e-02,\n",
      "         -3.9727e-02,  1.7360e-02],\n",
      "        [-3.6365e-02, -1.8336e-02, -2.2882e-02,  ...,  1.7740e-02,\n",
      "         -1.8673e-02,  5.5329e-02],\n",
      "        [-3.9169e-03,  2.1735e-02, -1.5234e-02,  ..., -1.0399e-02,\n",
      "          1.5982e-02, -3.3498e-03]], requires_grad=True), Parameter containing:\n",
      "tensor([-1.5610e-02,  7.9010e-03,  1.1601e-02, -1.6070e-02,  1.6219e-02,\n",
      "         1.4543e-02,  1.1291e-02,  3.7527e-03,  7.1057e-03,  1.7678e-02,\n",
      "         4.4636e-03, -9.1158e-03, -9.5226e-03, -1.9417e-02, -1.9223e-02,\n",
      "         2.8307e-03,  1.3795e-02, -1.8432e-02, -9.0015e-03, -1.6695e-02,\n",
      "        -1.3866e-02,  1.2671e-02,  1.2253e-02, -2.0209e-02,  1.2983e-02,\n",
      "        -1.1967e-02, -1.8561e-02,  1.9543e-02,  1.0410e-02,  8.7925e-03,\n",
      "         2.2693e-02, -1.6009e-02,  1.4067e-02, -1.6345e-02, -9.9147e-03,\n",
      "         1.1294e-02, -2.4677e-02, -7.9723e-03, -2.0534e-02, -1.8424e-02,\n",
      "         9.7272e-03,  2.0306e-02,  1.1347e-02,  5.6326e-03,  7.4394e-03,\n",
      "         5.3023e-03, -1.7162e-02,  8.4229e-03,  1.1496e-02, -1.4718e-02,\n",
      "         1.1838e-02, -1.1027e-02,  2.6656e-03, -2.8434e-02,  7.1570e-03,\n",
      "         7.2151e-03, -1.2701e-02, -1.5596e-02,  1.9675e-02, -1.1967e-02,\n",
      "         1.0194e-02, -1.0588e-02,  1.2531e-02,  9.3302e-03, -2.0797e-02,\n",
      "        -1.4704e-02,  2.2561e-02, -1.6391e-02,  1.6071e-02, -1.9332e-02,\n",
      "        -2.5380e-02,  7.1903e-03, -4.3778e-03, -1.1820e-02,  2.0873e-02,\n",
      "        -1.1924e-02, -1.2011e-02,  8.4509e-04, -2.1438e-02, -1.2540e-02,\n",
      "        -2.4352e-02,  9.2091e-03, -9.3518e-03,  1.1997e-03, -1.9100e-02,\n",
      "        -1.2889e-02,  1.5643e-02,  2.5174e-02,  1.4916e-02,  4.4102e-03,\n",
      "        -1.6847e-02,  1.1031e-02, -7.2266e-03, -1.0998e-02, -1.4691e-02,\n",
      "        -1.0078e-02, -1.7338e-02,  1.2655e-02, -1.0661e-02, -1.3257e-02,\n",
      "         2.3473e-02, -1.4656e-02, -1.2396e-02, -1.5497e-02, -1.2088e-02,\n",
      "        -2.6079e-02, -2.2014e-02, -1.1023e-02,  1.3239e-02, -3.6641e-03,\n",
      "         1.4376e-02, -9.7014e-03, -1.2671e-02,  1.2850e-02,  2.1178e-02,\n",
      "        -5.7056e-03, -7.8870e-03,  1.8914e-02, -1.1343e-02, -1.2308e-02,\n",
      "        -1.7094e-02,  9.5378e-03,  4.1023e-03, -1.4983e-02,  1.5952e-02,\n",
      "         4.5864e-03, -8.2136e-03,  9.6756e-03,  6.6293e-09,  7.4448e-09,\n",
      "         1.6677e-08, -4.2304e-08,  5.7818e-09,  2.1089e-08,  3.6885e-08,\n",
      "         5.8385e-09, -1.0787e-08,  2.4591e-08, -1.0547e-08, -1.4444e-08,\n",
      "        -4.6468e-08, -1.7654e-08, -7.6162e-09, -2.0969e-08,  1.9229e-08,\n",
      "        -4.5169e-08, -5.8347e-09, -1.0303e-08,  5.6092e-09, -2.5864e-10,\n",
      "         2.7436e-08, -2.3233e-08,  1.9554e-08, -7.2582e-09, -5.4220e-09,\n",
      "        -2.0661e-09,  2.3842e-08,  2.3923e-09, -1.3805e-08, -1.6866e-08,\n",
      "        -8.9373e-09, -1.3711e-08, -4.7655e-08,  3.3713e-08, -2.4873e-08,\n",
      "        -5.3745e-08, -7.6776e-08, -2.8666e-08,  1.8771e-08, -3.5535e-09,\n",
      "         2.2927e-08,  6.0425e-09, -1.7519e-08, -2.0778e-08,  6.7599e-09,\n",
      "         2.7987e-08,  8.7415e-09, -3.3207e-08,  3.7414e-09, -2.4058e-08,\n",
      "        -1.5798e-08, -2.2329e-08,  4.5349e-08,  6.7526e-09, -2.6822e-08,\n",
      "        -3.2398e-08,  5.2580e-08,  1.5292e-08,  1.4133e-08, -4.0391e-08,\n",
      "         2.7595e-08,  1.9960e-08, -6.8643e-08,  3.7115e-10,  2.0646e-08,\n",
      "        -2.3104e-08,  2.3355e-08, -8.7697e-09, -2.8824e-09, -4.6150e-10,\n",
      "        -2.1032e-08, -2.4171e-08,  1.4356e-08,  8.6003e-10, -5.0966e-09,\n",
      "        -3.5049e-08, -2.1985e-08,  1.3193e-09, -2.2703e-08,  4.5889e-08,\n",
      "        -2.6094e-08,  2.6082e-08, -3.9929e-08, -8.3025e-09,  1.7083e-08,\n",
      "        -3.8574e-10,  4.6176e-08,  2.4775e-08, -2.0982e-08,  5.7274e-11,\n",
      "         1.0745e-08, -3.4242e-08,  1.1731e-08,  6.1953e-09, -8.2234e-09,\n",
      "         1.0478e-08, -1.5612e-08, -1.3503e-08,  4.5186e-08, -1.1599e-08,\n",
      "        -4.5520e-08, -3.3367e-08, -1.2052e-08, -1.8204e-08, -5.5572e-08,\n",
      "        -4.0535e-10,  3.4490e-08, -1.6483e-08,  2.9195e-08, -2.2484e-08,\n",
      "        -2.1837e-08,  2.9939e-08,  7.1912e-09,  5.3219e-08, -2.7711e-08,\n",
      "         1.5774e-08, -1.5047e-08, -6.2132e-09,  4.2240e-10,  1.5975e-08,\n",
      "         2.5168e-08, -1.7161e-08,  9.8219e-09, -5.4243e-08, -8.2844e-09,\n",
      "         2.7790e-08, -1.1252e-02, -2.3607e-03, -7.5213e-03,  7.0469e-03,\n",
      "         4.2285e-03,  1.8562e-02, -5.1277e-03,  2.2498e-02, -1.2273e-02,\n",
      "        -4.4162e-03,  1.2773e-02, -7.5234e-03, -7.7894e-03, -6.1193e-03,\n",
      "         2.0810e-02, -1.4467e-02,  6.0210e-03, -8.2415e-03, -1.2104e-02,\n",
      "         1.5227e-02,  9.1590e-03, -3.1529e-03,  4.7302e-03,  6.1236e-03,\n",
      "        -5.6204e-03,  6.4754e-03, -5.5787e-03, -2.4838e-03,  3.7740e-02,\n",
      "         3.0366e-02, -8.1066e-03, -1.3338e-03,  9.9319e-03,  5.4600e-03,\n",
      "        -1.6459e-02,  9.4452e-03, -1.7819e-02,  8.5015e-03,  8.4816e-03,\n",
      "        -9.8605e-03, -4.3518e-03, -4.5843e-03, -6.7858e-03,  1.3683e-02,\n",
      "        -1.0335e-02,  9.3404e-03,  7.2929e-03, -5.8618e-03,  6.2239e-03,\n",
      "         9.0587e-03, -8.6205e-03,  1.1567e-02, -9.6027e-03,  1.0251e-02,\n",
      "         8.3969e-03, -3.7540e-03, -5.4995e-03,  1.9491e-03,  9.2004e-03,\n",
      "        -4.5103e-03, -1.5158e-03,  7.0410e-03, -2.9527e-02, -1.4996e-02,\n",
      "        -2.0426e-02, -4.2611e-03,  9.6733e-03,  3.8742e-03,  6.9904e-03,\n",
      "         4.8699e-03,  2.9779e-03, -5.2101e-03, -1.6396e-02,  6.1839e-03,\n",
      "         3.5724e-03, -3.6678e-03,  5.4219e-03,  1.6793e-02,  1.0097e-02,\n",
      "         2.1646e-02, -2.5048e-02,  1.0617e-02,  1.4834e-02,  1.0026e-02,\n",
      "        -4.0096e-03, -6.8950e-03,  7.4547e-03, -1.0935e-02,  6.4552e-03,\n",
      "        -2.2505e-03, -2.2494e-02,  8.4048e-03,  9.8022e-03,  1.4068e-02,\n",
      "        -4.6802e-03,  7.1463e-03,  1.0488e-02,  1.1831e-02, -2.3950e-02,\n",
      "        -2.0438e-02, -7.3232e-03, -2.1842e-02,  8.9327e-03,  8.6231e-03,\n",
      "        -1.5943e-02, -5.7071e-03,  4.6909e-03, -8.4417e-03, -8.3912e-03,\n",
      "        -7.1822e-03, -5.6870e-03,  2.2577e-02,  2.6811e-02, -1.6416e-02,\n",
      "         8.5541e-03, -8.2983e-03,  1.2349e-02,  1.3905e-02,  7.6027e-03,\n",
      "        -8.2145e-03,  8.8757e-03,  2.0731e-02, -1.6176e-02, -2.3745e-02,\n",
      "        -9.3996e-03, -1.6403e-02,  9.3051e-03, -5.2946e-03],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-1.2868e-03, -1.0333e-03, -3.7003e-03,  ..., -1.6534e-02,\n",
      "         -2.2077e-04, -1.3588e-02],\n",
      "        [ 7.2622e-03, -7.2379e-03, -1.3617e-02,  ...,  2.7622e-02,\n",
      "          6.1443e-05, -1.5167e-04],\n",
      "        [-1.3858e-02,  9.3117e-03,  1.5385e-02,  ..., -2.0061e-02,\n",
      "         -7.2774e-03,  4.7071e-03],\n",
      "        ...,\n",
      "        [ 1.9468e-02,  4.6778e-03, -5.0553e-03,  ..., -1.5384e-03,\n",
      "          1.2264e-02, -2.3843e-03],\n",
      "        [-9.0188e-03,  1.0103e-02, -1.6081e-03,  ..., -8.1796e-03,\n",
      "         -5.9239e-03, -1.8551e-03],\n",
      "        [-1.2066e-02, -9.6267e-03, -2.3750e-03,  ..., -2.9126e-02,\n",
      "          1.4327e-02, -1.1387e-02]], requires_grad=True), Parameter containing:\n",
      "tensor([-2.0267e-03,  1.1610e-03, -4.2441e-04,  6.8566e-04, -1.4327e-03,\n",
      "        -5.0363e-03, -2.0618e-03, -9.6653e-03, -4.4955e-03,  2.2080e-03,\n",
      "        -1.0087e-03, -6.7818e-04,  2.1045e-03, -1.9412e-03, -3.0112e-03,\n",
      "        -3.2254e-03, -1.0469e-04,  2.7020e-03, -5.2788e-04,  2.7543e-03,\n",
      "        -1.2365e-02, -2.6762e-03, -2.7593e-03,  5.6446e-03,  3.3561e-03,\n",
      "         2.2248e-03,  2.9302e-03,  3.0024e-03,  2.6903e-03,  2.0133e-03,\n",
      "         1.7290e-02,  4.3466e-04,  1.7753e-03, -1.7237e-03,  1.6894e-04,\n",
      "         2.6269e-03,  4.5661e-03, -1.1797e-03,  1.0724e-03, -2.2331e-03,\n",
      "        -2.6259e-03,  4.9482e-03, -4.9248e-03,  3.9467e-03,  4.0406e-03,\n",
      "         2.0901e-03, -1.4174e-03,  2.0269e-03, -1.4743e-03, -2.9958e-03,\n",
      "        -3.4223e-04, -1.9956e-03,  2.0132e-03, -5.7458e-04,  1.9611e-03,\n",
      "        -2.7038e-03, -3.7121e-03, -1.2285e-03,  2.9012e-03, -8.7401e-04,\n",
      "        -3.2899e-03,  1.3719e-03, -2.2905e-03, -9.1265e-04,  3.2403e-03,\n",
      "         5.7938e-03, -3.5536e-03, -2.9728e-04,  1.4041e-03, -7.4273e-03,\n",
      "         3.7349e-03, -4.7122e-03,  2.7092e-03,  3.8359e-03, -3.6331e-03,\n",
      "        -7.5697e-04, -2.1458e-03,  3.7576e-03, -5.9437e-03,  1.4324e-03,\n",
      "         2.1816e-03,  9.8672e-04,  7.9820e-03,  7.7945e-04,  1.7604e-03,\n",
      "         6.0876e-04, -1.8456e-03, -8.3447e-05, -4.4373e-03,  3.3008e-03,\n",
      "        -4.7501e-04, -2.8015e-03, -3.8805e-06, -3.5095e-03, -2.5696e-03,\n",
      "         4.8444e-04, -9.9451e-03,  4.6467e-03, -2.1581e-03, -1.6392e-03,\n",
      "         5.1687e-03, -5.3782e-03,  2.1783e-03,  2.5255e-03,  4.0928e-04,\n",
      "         1.5242e-03, -4.2104e-03, -1.7058e-04,  1.2776e-03,  1.4537e-03,\n",
      "        -2.2508e-03, -1.8799e-03,  2.3684e-03, -2.2061e-03,  1.9875e-03,\n",
      "         1.5595e-04, -4.8951e-03, -1.9220e-03, -1.7868e-03,  2.7093e-03,\n",
      "         1.3584e-03, -5.2046e-03,  1.8490e-03, -7.1005e-04,  2.5247e-03,\n",
      "         1.8147e-04, -2.8689e-03, -4.9906e-05], requires_grad=True), Parameter containing:\n",
      "tensor([1.0188, 1.0640, 1.0280, 1.0148, 1.0325, 1.1328, 1.0150, 1.0173, 1.0897,\n",
      "        1.0185, 1.0327, 1.0102, 1.0488, 1.0236, 1.0110, 1.0096, 1.0838, 1.0577,\n",
      "        1.0126, 1.0235, 1.2146, 1.0134, 1.0565, 1.2858, 1.0527, 1.0374, 1.0556,\n",
      "        1.0183, 1.1063, 1.0227, 1.1489, 1.0089, 1.1166, 1.0178, 1.0184, 1.0091,\n",
      "        1.0606, 1.0868, 1.0126, 1.0124, 1.1025, 1.0163, 1.0988, 1.0400, 1.1175,\n",
      "        1.0733, 1.0222, 1.0133, 1.0523, 1.0902, 1.0111, 1.0187, 1.0768, 1.0201,\n",
      "        1.0079, 1.0297, 1.0539, 1.0264, 1.0383, 1.0093, 1.0119, 1.0105, 1.0232,\n",
      "        1.0539, 1.0208, 1.0584, 1.0163, 1.0093, 1.0138, 1.0152, 1.0917, 1.0318,\n",
      "        1.0381, 1.0185, 1.0170, 1.0430, 1.0307, 1.0522, 1.0318, 1.0353, 1.1587,\n",
      "        1.0186, 1.0716, 1.0140, 1.0155, 1.0079, 1.0072, 1.0165, 1.0173, 1.0285,\n",
      "        1.0135, 1.0903, 1.0118, 1.0792, 1.0133, 1.0340, 1.1196, 1.0322, 1.1386,\n",
      "        1.0296, 1.0159, 1.0606, 1.0088, 1.0726, 1.0081, 1.0121, 1.0743, 1.0175,\n",
      "        1.0925, 1.0364, 1.0206, 1.0132, 1.0178, 1.0182, 1.1324, 1.0229, 1.0772,\n",
      "        1.0252, 1.0575, 1.0563, 1.0230, 1.0145, 1.0141, 1.0759, 1.0106, 1.2443,\n",
      "        1.0295, 1.0087], requires_grad=True), Parameter containing:\n",
      "tensor([-5.5820e-03, -6.0848e-02, -3.1212e-02, -1.5919e-02, -3.6997e-02,\n",
      "        -3.7067e-02,  1.1255e-02, -2.3970e-02, -5.4892e-02,  3.4499e-02,\n",
      "         1.7021e-02,  9.3707e-03,  2.5288e-02, -2.0555e-02, -1.8767e-02,\n",
      "        -6.7231e-03, -2.5004e-02,  3.5449e-02,  1.1527e-02,  1.2164e-02,\n",
      "        -7.3547e-02, -1.9516e-02, -3.5061e-02,  1.1471e-01,  4.4962e-02,\n",
      "         6.9370e-03,  9.2263e-03,  4.2634e-03,  6.0348e-02,  4.7577e-02,\n",
      "         5.5452e-02, -1.0665e-02,  5.8824e-02, -2.8026e-02,  2.6676e-02,\n",
      "        -2.9933e-03,  6.5838e-02, -6.1464e-02, -1.0916e-03, -1.4316e-02,\n",
      "        -5.0981e-02,  7.8164e-03, -4.0238e-04,  6.2873e-02,  5.2908e-02,\n",
      "         4.4244e-02,  1.5027e-02,  5.4814e-05,  5.2283e-02,  3.9417e-03,\n",
      "         3.8642e-03, -4.9514e-02, -3.3754e-02, -2.8686e-03,  2.0456e-02,\n",
      "        -3.3521e-02, -6.3124e-02,  6.8929e-03,  5.4131e-02, -2.3952e-03,\n",
      "        -2.0560e-02,  2.1261e-02, -3.6326e-02,  2.7440e-02,  3.4687e-02,\n",
      "        -1.3796e-02, -2.6646e-02, -9.1805e-04,  2.0260e-02, -1.5489e-02,\n",
      "         5.3806e-02, -3.3452e-02,  2.7953e-02,  1.4003e-02, -1.3435e-02,\n",
      "         2.3786e-02, -1.8047e-02,  3.1510e-02, -4.7761e-02, -2.3911e-02,\n",
      "        -4.9540e-02,  9.9946e-03,  5.5100e-02, -3.1905e-02,  1.2872e-02,\n",
      "         8.4389e-03, -2.4262e-02,  7.4773e-03, -3.5232e-02,  1.5879e-02,\n",
      "        -2.8477e-03, -4.0093e-02,  7.2921e-03, -5.7116e-02,  7.0044e-04,\n",
      "        -1.9662e-03, -7.3159e-02,  3.2967e-02, -4.5662e-02,  1.4091e-02,\n",
      "         9.8328e-03, -6.3552e-02,  2.4759e-02,  4.4600e-02, -2.0267e-02,\n",
      "        -4.7141e-03, -5.1818e-02,  7.9065e-03,  5.8930e-02, -2.1253e-02,\n",
      "        -2.7955e-02, -1.6287e-02,  3.2154e-03, -6.7741e-03,  5.8886e-02,\n",
      "         3.1617e-03, -7.1523e-02, -3.9161e-02, -2.0300e-02,  4.2733e-02,\n",
      "         1.6172e-02, -3.6174e-02,  4.2569e-02, -1.6187e-02,  3.9644e-02,\n",
      "         6.2578e-02, -4.0938e-03, -4.3417e-03], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0320, -0.0255,  0.0114,  ...,  0.0018,  0.0162, -0.0482],\n",
      "        [-0.0424,  0.0027, -0.0293,  ..., -0.0233,  0.0169,  0.0075],\n",
      "        [-0.0093, -0.0072, -0.0066,  ...,  0.0065, -0.0210,  0.0234],\n",
      "        ...,\n",
      "        [ 0.0329,  0.0904,  0.0542,  ...,  0.0762, -0.0114, -0.0075],\n",
      "        [-0.0379,  0.0062, -0.0125,  ..., -0.0046, -0.0219, -0.0012],\n",
      "        [-0.0059,  0.0348, -0.0227,  ..., -0.0012,  0.0202,  0.0025]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 3.5546e-03,  2.7453e-02,  1.2487e-02,  1.2279e-02,  4.1405e-03,\n",
      "         7.0195e-03,  4.3758e-03,  1.5009e-02,  1.6413e-02,  1.2546e-03,\n",
      "         7.1178e-03,  1.0787e-02,  9.4448e-03,  3.5275e-02,  1.0728e-02,\n",
      "         6.9348e-03,  1.0705e-02,  8.9464e-03,  2.9427e-03,  4.3254e-03,\n",
      "         1.3308e-02,  1.4821e-02, -2.7077e-04,  3.8331e-03,  1.5169e-02,\n",
      "         9.5569e-03,  6.7000e-03,  1.0926e-03, -4.3601e-05,  9.9982e-03,\n",
      "         1.3518e-02,  1.2333e-02,  7.6810e-03,  4.8606e-03,  2.3980e-02,\n",
      "         1.2941e-02,  1.0284e-02,  1.6277e-02,  7.8285e-03,  1.1856e-02,\n",
      "         4.1434e-03,  9.5960e-03,  6.5478e-03,  5.6827e-03,  1.0355e-02,\n",
      "         1.7282e-02,  1.4987e-02,  2.2948e-02,  7.4863e-03,  1.2198e-03,\n",
      "         7.8539e-03,  2.9268e-02,  1.7857e-02,  2.6829e-02,  2.8695e-03,\n",
      "         4.0323e-02,  3.8897e-03,  9.7061e-03,  2.2847e-02,  5.6605e-03,\n",
      "         4.4998e-02,  9.4434e-03,  9.0999e-03,  1.3103e-02,  7.7476e-03,\n",
      "         3.5807e-03,  1.2179e-02,  2.8046e-03,  8.8368e-03,  4.2048e-03,\n",
      "         1.7846e-02,  8.1430e-03,  1.5552e-02,  1.4017e-02,  1.0212e-02,\n",
      "         1.0541e-02,  1.0732e-02,  4.0553e-03, -2.6891e-04,  8.4119e-03,\n",
      "         5.6974e-03,  3.7463e-03,  7.9769e-03,  9.3981e-03,  1.3182e-02,\n",
      "         9.0605e-03,  1.7980e-02,  2.0469e-02,  8.8573e-03,  4.8477e-03,\n",
      "         8.4854e-03, -1.6608e-03,  5.7535e-03,  7.6973e-03,  1.2671e-02,\n",
      "         1.7228e-02,  1.2573e-02,  1.4362e-02,  8.0685e-03,  9.1299e-03,\n",
      "         1.4865e-02,  5.8660e-03,  8.6526e-03,  4.2125e-03,  1.2038e-02,\n",
      "         6.8672e-03,  8.0082e-03,  3.2948e-03,  4.3602e-03,  9.0881e-03,\n",
      "         1.1559e-04,  4.0149e-03,  5.0299e-03,  5.5265e-03,  4.6231e-03,\n",
      "         5.1774e-03,  8.8644e-03,  8.8045e-03,  1.0371e-02,  5.5196e-03,\n",
      "         1.1476e-02,  1.2398e-02,  2.0849e-02,  1.2242e-03,  9.3998e-03,\n",
      "         4.2325e-03, -1.4692e-03,  1.1717e-02,  4.8326e-03,  1.1442e-02,\n",
      "         1.4227e-02,  9.1023e-03,  1.9698e-02,  1.4758e-02,  1.9960e-03,\n",
      "         8.5420e-03,  1.6891e-02,  1.3306e-02,  1.4319e-02,  6.1925e-03,\n",
      "         7.2225e-03,  9.6398e-03,  1.2277e-02, -6.8198e-04,  7.2628e-03,\n",
      "         7.4560e-03,  8.9241e-03,  1.0801e-02,  4.4115e-03,  7.3959e-03,\n",
      "         4.3612e-03,  6.9406e-03,  9.3852e-03,  8.6693e-03,  1.0232e-02,\n",
      "         6.8626e-03,  7.8039e-03,  1.8576e-02,  5.9640e-03,  3.8844e-03,\n",
      "         7.9879e-03,  6.0147e-03,  6.1771e-03,  3.0947e-02,  1.2329e-02,\n",
      "         1.0924e-02,  6.7576e-03,  1.1223e-02,  4.6683e-03,  6.9391e-04,\n",
      "         5.6317e-03,  1.5732e-02,  9.6621e-03,  9.4582e-03,  1.2304e-02,\n",
      "         1.4849e-02,  7.5686e-03,  3.5224e-03,  4.4963e-03,  6.8006e-03,\n",
      "         1.0552e-02,  4.5755e-03,  9.9921e-03,  4.4067e-03,  4.3788e-03,\n",
      "         7.1116e-03,  1.1277e-02,  8.9814e-03,  8.3238e-03,  1.4682e-02,\n",
      "         8.0262e-03,  1.9110e-03,  7.9325e-03,  3.8160e-03,  8.4860e-03,\n",
      "         5.4006e-04,  7.7725e-03,  1.1686e-02,  7.9048e-03,  2.7339e-03,\n",
      "         1.4262e-02,  6.6383e-03,  2.2052e-02,  9.0408e-03,  1.2216e-03,\n",
      "         8.2326e-03,  5.7755e-03,  1.3229e-02,  1.2937e-02,  1.4564e-02,\n",
      "         1.0805e-02,  4.5737e-03,  6.7996e-03,  6.1147e-03,  4.6665e-03,\n",
      "         1.4014e-02,  7.8905e-03,  9.9147e-03,  8.1778e-03,  7.8505e-03,\n",
      "         6.5209e-03,  1.3310e-02,  9.5308e-03,  8.2627e-03,  1.4897e-02,\n",
      "         5.3955e-03,  1.5435e-02,  1.4995e-02,  1.2585e-02,  1.9513e-03,\n",
      "         6.5633e-03,  1.2699e-02,  7.0645e-03,  1.7478e-02,  1.1219e-02,\n",
      "         3.6437e-03,  8.4039e-03,  6.1624e-03,  1.2441e-02,  1.4080e-04,\n",
      "         8.6202e-03,  8.8443e-03,  1.2883e-02,  6.0774e-03,  6.8772e-03,\n",
      "         6.7507e-03,  5.0918e-04,  4.8886e-03,  6.4532e-02,  7.7623e-03,\n",
      "         1.1878e-02,  3.1062e-02,  6.1247e-03,  4.4382e-05,  5.3173e-05,\n",
      "         2.9605e-05,  2.1496e-02,  7.2182e-03,  1.4987e-02,  2.3260e-02,\n",
      "         2.2465e-03,  4.1182e-03,  7.3906e-03,  4.4491e-03,  4.4051e-03,\n",
      "         4.7011e-03,  1.0310e-02,  1.8854e-03,  5.9146e-03,  1.0873e-02,\n",
      "         1.2161e-02,  8.7186e-03,  3.6320e-03,  1.0754e-02,  4.8151e-03,\n",
      "         1.3297e-03,  1.1153e-02,  1.7660e-02,  1.1080e-02,  2.7210e-02,\n",
      "         3.8590e-03,  8.1816e-03,  2.6131e-02,  8.1469e-03,  1.8474e-02,\n",
      "         1.2751e-02,  6.5904e-03,  1.2543e-02,  7.3950e-03,  1.6968e-02,\n",
      "         9.2336e-03,  1.9740e-02,  8.2235e-03,  1.1467e-02,  6.1242e-03,\n",
      "         2.1413e-03,  9.4876e-03,  1.5855e-02,  1.4928e-02,  5.8932e-03,\n",
      "         7.7570e-03,  1.3357e-02,  7.9271e-03,  9.7199e-03,  7.4507e-03,\n",
      "         5.9972e-03,  1.6769e-02,  7.6886e-03,  8.0442e-03,  9.1403e-03,\n",
      "         1.2359e-02,  4.1889e-03,  3.5000e-03,  9.2656e-03,  9.8888e-03,\n",
      "         4.7080e-03,  6.4557e-03,  1.8688e-02,  4.2613e-03,  1.2517e-02,\n",
      "         1.0581e-02,  7.9872e-03,  1.1423e-02,  1.4919e-02,  1.3817e-02,\n",
      "         6.9429e-03,  4.2743e-03,  2.9819e-02,  4.2129e-03,  6.7509e-03,\n",
      "         1.1484e-02,  1.4989e-02,  3.3845e-03,  8.0058e-03,  8.8346e-03,\n",
      "         1.8062e-02,  3.3715e-03,  7.6235e-03,  1.2047e-03,  1.7699e-02,\n",
      "         7.8496e-03,  4.4839e-03,  5.1104e-03,  5.4041e-03,  1.5987e-02,\n",
      "         5.4582e-03,  1.5485e-02,  7.1454e-03,  7.8779e-03,  7.3823e-03,\n",
      "         8.7847e-03,  6.0505e-03,  6.6291e-03,  1.3702e-02,  1.0588e-02,\n",
      "         3.7570e-03,  7.1368e-03,  5.7003e-03,  8.4647e-03,  6.2815e-03,\n",
      "         1.2146e-02,  6.3161e-03,  7.1731e-03,  5.4286e-03,  2.0359e-02,\n",
      "         1.1696e-02,  3.1649e-03,  9.2234e-03,  7.0440e-03,  7.9482e-03,\n",
      "         4.8543e-03,  8.1139e-03,  4.7597e-03,  4.5522e-03,  1.3969e-02,\n",
      "         8.0023e-03,  5.5173e-03,  1.5640e-02,  6.6634e-03,  6.2604e-03,\n",
      "         6.5559e-03,  1.4055e-02,  8.9696e-03,  3.2835e-02,  1.0689e-02,\n",
      "         9.2551e-03,  7.8985e-03,  1.0942e-02,  1.7804e-03,  6.3097e-03,\n",
      "         1.1415e-02,  4.1065e-03,  1.4584e-02,  1.2043e-02,  6.0422e-03,\n",
      "         8.6797e-03,  1.5274e-02,  3.8750e-03,  7.2633e-03,  5.6237e-03,\n",
      "         4.1426e-03,  1.2714e-02, -6.6942e-04,  6.8158e-03,  1.0324e-02,\n",
      "         1.0045e-02,  1.9783e-02,  1.0548e-02,  6.5325e-03,  4.6256e-03,\n",
      "         1.2684e-02,  1.3867e-02,  3.3884e-03,  1.4519e-02,  2.0496e-03,\n",
      "         1.2059e-02,  1.1487e-02,  7.7700e-03,  2.1333e-03,  7.4092e-03,\n",
      "         1.5524e-02,  3.7956e-03,  1.0048e-02,  5.9196e-03,  7.6548e-03,\n",
      "         1.2237e-02,  6.4152e-03,  4.3264e-03,  1.1910e-02,  1.5792e-02,\n",
      "         8.5938e-03,  6.2337e-03,  6.9809e-03,  5.6240e-03,  3.4317e-03,\n",
      "         8.3573e-03,  6.3196e-03,  3.7367e-03,  1.3734e-02,  1.0503e-02,\n",
      "        -1.2946e-03,  5.7451e-04,  1.1845e-02,  1.1651e-03,  7.5683e-03,\n",
      "         6.7359e-03,  1.0607e-02,  5.4383e-03,  1.6034e-02,  4.6896e-03,\n",
      "        -8.4532e-04,  6.9669e-03,  1.1260e-02,  7.0015e-03,  3.6689e-03,\n",
      "         5.5831e-03,  4.3452e-03,  6.5390e-03,  6.5273e-03,  7.3886e-03,\n",
      "         6.3514e-03,  8.8093e-03,  2.4986e-03,  2.0734e-02,  1.2590e-02,\n",
      "         1.8236e-02,  1.0453e-02,  5.4965e-03,  1.8311e-02,  1.0682e-02,\n",
      "         7.9109e-03,  6.1710e-03,  2.5214e-03,  5.1916e-03,  1.1877e-02,\n",
      "        -1.6849e-05,  6.1461e-03,  1.3214e-02,  7.4369e-03,  3.4071e-03,\n",
      "         4.6039e-03,  4.5468e-03,  1.2101e-02,  1.1739e-02,  1.6752e-02,\n",
      "         1.0702e-02,  4.2790e-03,  3.3732e-03,  1.4726e-02,  6.2200e-03,\n",
      "         1.0910e-02,  1.6841e-02,  1.6397e-02,  1.1101e-02,  1.9465e-03,\n",
      "         1.6951e-02,  7.2696e-03,  1.1369e-02,  1.4450e-02,  5.1483e-03,\n",
      "         1.2454e-02,  8.0163e-03,  4.9464e-03,  7.9129e-03,  2.5703e-02,\n",
      "         1.4911e-02,  8.3835e-03,  8.7455e-03,  1.6674e-02,  1.1336e-02,\n",
      "         3.8454e-03,  2.2309e-03], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0005, -0.0019, -0.0029,  ...,  0.0033,  0.0089,  0.0040],\n",
      "        [ 0.0036,  0.0057, -0.0013,  ..., -0.0725,  0.0078, -0.0016],\n",
      "        [-0.0079,  0.0020,  0.0153,  ...,  0.0030,  0.0005,  0.0129],\n",
      "        ...,\n",
      "        [ 0.0086, -0.0041, -0.0143,  ...,  0.0099, -0.0044, -0.0155],\n",
      "        [ 0.0069, -0.0132,  0.0089,  ...,  0.0232,  0.0030,  0.0034],\n",
      "        [-0.0022, -0.0088,  0.0066,  ...,  0.0008,  0.0035,  0.0126]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-1.0967e-03,  1.1790e-05, -8.4739e-04, -1.8736e-03, -2.0955e-03,\n",
      "        -1.8527e-03, -1.4152e-03, -6.4318e-03, -2.6761e-03,  1.8690e-03,\n",
      "        -1.2305e-03, -4.0087e-04,  2.1640e-03, -1.6128e-03, -4.8791e-04,\n",
      "        -1.2242e-03, -3.9735e-04,  2.5213e-03,  5.0346e-04,  1.2342e-03,\n",
      "        -1.4439e-02, -2.3935e-03, -1.9734e-03,  4.9476e-03,  2.7950e-03,\n",
      "         9.8489e-04,  1.1901e-03,  1.4313e-03,  2.3890e-03,  1.5459e-03,\n",
      "         1.8797e-02,  2.9011e-03,  1.5792e-03, -3.4283e-03,  4.4234e-03,\n",
      "         1.8682e-03,  3.8064e-03, -1.8269e-03,  1.4598e-03, -1.0343e-03,\n",
      "        -1.1960e-03,  2.8220e-03,  3.9875e-04,  3.5402e-03,  3.2411e-03,\n",
      "         1.6216e-03, -8.2295e-04,  1.7840e-03,  1.2404e-03, -1.7946e-03,\n",
      "         2.5678e-04, -1.3888e-03,  3.1004e-04, -1.2255e-04,  1.6954e-03,\n",
      "        -1.7335e-03, -2.9647e-03, -1.5008e-03,  1.8925e-03, -3.4890e-04,\n",
      "        -2.7600e-03,  1.4232e-03, -2.7309e-03,  1.7521e-04,  2.2296e-03,\n",
      "         1.1521e-03, -3.8574e-03,  4.9359e-04,  1.4435e-03, -2.5603e-03,\n",
      "         2.7596e-03, -3.3973e-03,  1.4064e-03,  3.5771e-03, -1.7877e-03,\n",
      "        -7.1408e-04, -1.7126e-03,  1.3889e-03, -4.0037e-03,  7.1712e-04,\n",
      "        -8.7416e-04, -1.6252e-03,  3.2436e-03, -3.4120e-03,  2.3374e-03,\n",
      "         1.3284e-03, -1.4732e-03,  1.4336e-03, -3.1179e-03,  3.0760e-03,\n",
      "        -8.3383e-04, -2.6248e-03, -8.9563e-04, -2.2336e-03, -2.3566e-03,\n",
      "         5.8083e-04, -1.1654e-02,  3.4028e-03, -2.8000e-03, -2.0008e-03,\n",
      "         1.7445e-03, -3.3082e-03,  1.7075e-03,  2.2759e-03, -1.3255e-03,\n",
      "         1.0804e-03, -3.0744e-03, -1.9711e-04,  1.9370e-03,  1.7200e-05,\n",
      "        -9.0953e-04, -1.0565e-03,  1.7652e-03, -1.4502e-03,  1.7562e-03,\n",
      "         1.0177e-03, -1.8595e-03, -1.8760e-03, -1.4593e-03,  2.2538e-03,\n",
      "         1.0953e-03, -4.2579e-03,  1.6881e-03, -1.3750e-03,  1.9808e-03,\n",
      "        -1.8847e-03, -2.1340e-03, -3.0780e-04], requires_grad=True), Parameter containing:\n",
      "tensor([1.0300, 1.0491, 1.0595, 1.0591, 1.0275, 1.0322, 1.0246, 1.1310, 1.0412,\n",
      "        1.0789, 1.0719, 1.0377, 1.0238, 1.0466, 1.0369, 1.0445, 1.0320, 1.0258,\n",
      "        1.0227, 1.0975, 1.0946, 1.0483, 1.0530, 1.1090, 1.1059, 1.0464, 1.0852,\n",
      "        1.0567, 1.0424, 1.0561, 1.1163, 1.0329, 1.0286, 1.0383, 1.0770, 1.0220,\n",
      "        1.0866, 1.0736, 1.0279, 1.0589, 1.0835, 1.0601, 1.0479, 1.0280, 1.0465,\n",
      "        1.0531, 1.0484, 1.0463, 1.0624, 1.0881, 1.0375, 1.0173, 1.0397, 1.0290,\n",
      "        1.0284, 1.0205, 1.0573, 1.0235, 1.0407, 1.0382, 1.0404, 1.0207, 1.0453,\n",
      "        1.0170, 1.0369, 1.0499, 1.0538, 1.0274, 1.0430, 1.0324, 1.0694, 1.0340,\n",
      "        1.1174, 1.0356, 1.0262, 1.0446, 1.0365, 1.0824, 1.0268, 1.0255, 1.1565,\n",
      "        1.0646, 1.0640, 1.0847, 1.0332, 1.0386, 1.0461, 1.0452, 1.0416, 1.0322,\n",
      "        1.0846, 1.0466, 1.0636, 1.0450, 1.0557, 1.0350, 1.0886, 1.0261, 1.0769,\n",
      "        1.0240, 1.0294, 1.0280, 1.0332, 1.0260, 1.0549, 1.0144, 1.0543, 1.0258,\n",
      "        1.0317, 1.0250, 1.0874, 1.0309, 1.0215, 1.0292, 1.0485, 1.0360, 1.1046,\n",
      "        1.0207, 1.0811, 1.0276, 1.0237, 1.0773, 1.0648, 1.0283, 1.0133, 1.0807,\n",
      "        1.0244, 1.0448], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0065, -0.0204,  0.0145, -0.0405,  0.0066, -0.0269, -0.0183, -0.0511,\n",
      "        -0.0338,  0.0369,  0.0322, -0.0391,  0.0199, -0.0402, -0.0234, -0.0338,\n",
      "        -0.0115,  0.0193,  0.0177, -0.0371, -0.0407, -0.0191, -0.0442,  0.0497,\n",
      "         0.0559,  0.0295, -0.0096, -0.0142,  0.0273,  0.0469,  0.0616, -0.0297,\n",
      "         0.0217, -0.0348,  0.0240,  0.0221,  0.0496, -0.0448,  0.0226, -0.0333,\n",
      "        -0.0098,  0.0375,  0.0120,  0.0139,  0.0287,  0.0078, -0.0265,  0.0204,\n",
      "        -0.0254, -0.0231, -0.0162,  0.0067, -0.0335, -0.0194,  0.0263, -0.0184,\n",
      "        -0.0426, -0.0218, -0.0142,  0.0208, -0.0349,  0.0137, -0.0223,  0.0145,\n",
      "         0.0262, -0.0091, -0.0296,  0.0003,  0.0406, -0.0169,  0.0453, -0.0188,\n",
      "        -0.0150,  0.0342, -0.0075, -0.0050, -0.0280,  0.0232, -0.0158, -0.0167,\n",
      "         0.0507, -0.0262,  0.0382, -0.0423,  0.0193,  0.0197, -0.0295,  0.0207,\n",
      "        -0.0251,  0.0287,  0.0143, -0.0354,  0.0354, -0.0266, -0.0389,  0.0064,\n",
      "        -0.0385, -0.0044, -0.0734, -0.0149,  0.0175,  0.0047,  0.0279,  0.0208,\n",
      "        -0.0187,  0.0119, -0.0427, -0.0091, -0.0122,  0.0071, -0.0502, -0.0155,\n",
      "         0.0102,  0.0053,  0.0376,  0.0227,  0.0290,  0.0098,  0.0054,  0.0250,\n",
      "         0.0123, -0.0083,  0.0398, -0.0263, -0.0035,  0.0504, -0.0239,  0.0336],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0061,  0.0052, -0.0131,  ..., -0.0192, -0.0269, -0.0126],\n",
      "        [ 0.0168,  0.0469, -0.0453,  ...,  0.0293,  0.0371,  0.0112],\n",
      "        [ 0.0124,  0.0296,  0.0051,  ...,  0.0238,  0.0112, -0.0062],\n",
      "        ...,\n",
      "        [-0.0367, -0.0490,  0.0321,  ...,  0.0007,  0.0258, -0.0289],\n",
      "        [ 0.0123,  0.0012, -0.0312,  ...,  0.0386,  0.0041, -0.0108],\n",
      "        [-0.0138, -0.0023,  0.0011,  ..., -0.0242,  0.0485, -0.0262]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-1.6055e-04, -1.2354e-02,  1.0456e-02,  1.3567e-03, -9.9854e-03,\n",
      "         1.1234e-02,  3.5711e-03,  8.5661e-03, -7.9864e-03, -2.8258e-02,\n",
      "        -6.0141e-03,  1.2541e-02,  2.8882e-03,  7.3477e-03,  2.5714e-03,\n",
      "        -9.3096e-03,  7.7829e-03,  6.3353e-03, -1.7681e-02,  3.6016e-03,\n",
      "        -3.8391e-02, -1.6010e-02, -5.0166e-03, -1.2996e-02, -1.1346e-02,\n",
      "         7.3704e-04,  8.9683e-03, -8.3706e-03, -3.4158e-03,  6.8968e-03,\n",
      "        -6.0553e-03, -8.5740e-03, -1.4486e-02, -3.3058e-03, -8.3112e-03,\n",
      "         5.3481e-03,  1.3834e-02, -1.0624e-04,  7.0960e-03,  4.8700e-03,\n",
      "        -2.8784e-02,  6.9073e-03, -8.5987e-03, -2.7642e-02, -7.1691e-04,\n",
      "        -1.0721e-02,  1.6806e-02, -4.6228e-03,  7.7502e-03,  2.7456e-02,\n",
      "         7.7771e-03, -5.5657e-03,  2.9791e-03, -2.4690e-03,  6.6719e-04,\n",
      "         6.7573e-03, -1.5928e-02,  1.3562e-02,  9.4006e-03,  3.3086e-02,\n",
      "         4.3131e-04,  1.5395e-02, -9.5668e-04,  1.1315e-02, -2.1402e-02,\n",
      "        -8.1454e-03, -2.1209e-04, -5.0698e-03,  6.9928e-03, -1.5682e-02,\n",
      "         3.6015e-03,  4.7368e-03, -2.1252e-04, -3.4293e-03, -6.4688e-03,\n",
      "         1.0499e-05, -1.7505e-02,  1.0661e-02, -2.5552e-02, -1.0076e-02,\n",
      "        -1.1056e-03,  1.2118e-02,  8.8567e-03,  2.7595e-02, -6.6254e-03,\n",
      "        -1.9483e-02,  7.7061e-03,  2.5947e-02,  5.0091e-03,  3.6606e-02,\n",
      "        -2.0577e-02, -3.6051e-04, -6.8467e-03,  1.1227e-02,  8.8928e-03,\n",
      "        -5.0039e-03,  1.9735e-02,  2.4043e-02,  1.0211e-02,  3.6714e-05,\n",
      "         2.0443e-03,  1.9973e-02,  9.5698e-03,  6.3902e-03,  1.5275e-03,\n",
      "         1.3503e-02,  6.2416e-03, -1.0149e-02, -3.6103e-03,  1.1018e-02,\n",
      "        -1.1583e-02, -3.3164e-02, -2.8743e-03,  9.7097e-03,  5.9020e-03,\n",
      "         6.1677e-03, -1.5980e-02,  1.2298e-02,  2.4025e-04,  1.1829e-02,\n",
      "        -1.3339e-02,  3.9998e-03,  6.1684e-03,  1.5054e-03,  4.8319e-03,\n",
      "         7.8090e-03, -8.1786e-03, -1.6886e-02, -8.0422e-09, -7.5652e-10,\n",
      "         5.5686e-09,  3.4104e-10, -3.2710e-09,  3.4988e-09,  1.3349e-09,\n",
      "         3.2780e-11, -5.0801e-10, -5.8678e-09, -8.2370e-09,  1.1966e-08,\n",
      "        -4.2664e-09,  1.7792e-09,  6.7034e-12, -4.0095e-09, -4.1152e-09,\n",
      "         1.2840e-08, -1.0072e-08, -9.7668e-09, -9.6953e-09, -8.7147e-09,\n",
      "        -3.0171e-09, -2.0711e-09, -5.2691e-09,  1.5822e-09,  8.3310e-09,\n",
      "        -7.1564e-13, -4.6229e-09,  2.6485e-08,  2.4682e-09, -6.9932e-10,\n",
      "        -1.2086e-08, -3.3001e-09, -3.4568e-09,  3.1545e-09,  5.6706e-09,\n",
      "         8.3611e-09,  1.4746e-09, -2.9196e-09, -1.2085e-08,  5.3526e-09,\n",
      "        -6.9503e-09, -1.6172e-08,  2.5936e-09, -1.0939e-08, -5.0241e-09,\n",
      "         3.3118e-09,  1.0146e-09,  1.0009e-08,  7.9122e-09, -4.0489e-09,\n",
      "         5.4898e-09, -1.0585e-08, -1.4851e-08, -1.0966e-09, -5.9015e-09,\n",
      "         1.8911e-09,  1.5780e-09,  2.2975e-08,  2.1431e-09,  1.1870e-08,\n",
      "         1.8226e-09,  4.2988e-09, -5.0937e-09, -9.4499e-10,  5.4399e-09,\n",
      "         1.1589e-09,  8.8264e-10, -8.4977e-09, -3.1413e-09, -4.7499e-09,\n",
      "         1.3015e-09, -3.5007e-09,  3.0650e-09,  2.0779e-09, -6.1788e-09,\n",
      "         1.2870e-08, -5.0549e-09, -5.6591e-09, -7.0399e-10,  1.0727e-08,\n",
      "        -6.1575e-09,  1.2777e-09, -8.8651e-10, -5.7471e-09, -1.2297e-09,\n",
      "         1.1140e-08,  7.5914e-09,  1.4042e-08, -5.4688e-09,  9.9266e-09,\n",
      "        -3.0739e-09, -8.8510e-11,  2.8471e-09, -8.7138e-09,  2.0801e-09,\n",
      "         4.3682e-09, -2.0412e-09,  4.4550e-09,  2.2811e-10,  7.9016e-09,\n",
      "        -4.9083e-09,  2.8374e-09,  2.7949e-09, -3.8795e-09, -2.2640e-09,\n",
      "        -6.9753e-10,  4.5869e-09, -2.4472e-09, -2.0153e-10, -9.7105e-09,\n",
      "         5.8548e-09, -1.5963e-09,  1.2548e-08, -8.7310e-10, -3.9540e-09,\n",
      "         1.2124e-08, -4.5429e-09,  9.2561e-09, -6.4797e-09, -1.2514e-08,\n",
      "        -6.4340e-10,  1.8996e-09,  1.8102e-09,  3.2450e-09, -2.9270e-09,\n",
      "         7.1328e-09, -7.7571e-03,  7.9186e-03, -9.1934e-03, -1.1278e-02,\n",
      "         8.7903e-03, -1.0371e-02,  1.8102e-02, -1.3003e-02,  1.0653e-02,\n",
      "         9.1276e-03,  5.0765e-03, -1.5060e-02,  1.7528e-02, -7.7117e-03,\n",
      "        -2.1360e-02,  8.6140e-03,  1.1967e-02, -6.3444e-03, -7.1614e-03,\n",
      "        -1.2657e-02, -1.4802e-02, -2.1724e-03, -2.9689e-02,  3.9219e-03,\n",
      "        -4.1639e-04,  1.9554e-02, -9.9878e-03,  1.1886e-02,  6.8985e-03,\n",
      "         4.3128e-03, -5.4956e-03, -1.2012e-02, -1.0828e-02, -5.1887e-03,\n",
      "        -6.6524e-03, -6.2112e-02, -1.7847e-02,  1.0342e-02,  1.7475e-02,\n",
      "         1.2720e-02,  1.4700e-02,  5.2566e-03,  9.0688e-03, -4.7783e-03,\n",
      "        -1.0759e-02, -1.0585e-02, -1.3485e-02, -5.4567e-03,  1.0836e-02,\n",
      "         9.2478e-03, -8.5610e-03, -2.0948e-03, -7.6482e-03, -6.4435e-03,\n",
      "        -1.0481e-02, -2.1430e-02,  6.6200e-03,  4.4139e-03, -1.4831e-02,\n",
      "        -5.0793e-03,  1.0501e-02,  2.4073e-03, -4.1320e-03, -8.0721e-03,\n",
      "         5.2697e-03,  1.0169e-02,  4.8346e-03,  3.7087e-03,  8.0449e-03,\n",
      "        -1.8381e-02,  7.1754e-03, -6.0933e-03,  1.0077e-02,  5.7074e-03,\n",
      "        -8.7657e-03, -6.1094e-03, -5.7338e-03, -2.1227e-02,  9.6288e-03,\n",
      "         4.3966e-03,  8.1912e-03, -2.4933e-02, -8.6430e-03,  3.9857e-03,\n",
      "        -5.8461e-03,  4.7848e-03, -4.8135e-03,  1.9255e-02, -1.8047e-02,\n",
      "         7.7610e-03,  7.9815e-03,  4.2909e-03, -7.6823e-03,  1.3391e-02,\n",
      "         2.0956e-02, -9.1929e-03,  7.3262e-03, -6.1246e-03,  1.0834e-02,\n",
      "        -8.1918e-03, -6.3038e-03, -6.9684e-03, -5.8247e-03, -8.3618e-03,\n",
      "         5.2536e-03, -2.1512e-02, -1.3373e-02,  1.4862e-02,  3.0882e-03,\n",
      "        -4.5407e-03,  4.5121e-03, -1.2026e-02,  8.9210e-03,  8.7904e-03,\n",
      "        -1.8249e-02, -5.4566e-03, -8.2954e-03, -8.4237e-03,  6.4888e-03,\n",
      "        -8.8471e-03,  1.6479e-02,  1.8951e-02,  5.8699e-03, -3.7423e-02,\n",
      "         8.2305e-03,  6.7256e-03,  6.7159e-03, -8.3587e-03],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0060, -0.0048, -0.0026,  ..., -0.0055,  0.0127, -0.0020],\n",
      "        [-0.0021,  0.0052, -0.0062,  ...,  0.0270,  0.0098,  0.0075],\n",
      "        [-0.0052,  0.0150,  0.0055,  ...,  0.0098,  0.0060,  0.0035],\n",
      "        ...,\n",
      "        [ 0.0140, -0.0031,  0.0139,  ...,  0.0081,  0.0007,  0.0243],\n",
      "        [-0.0018,  0.0099, -0.0114,  ...,  0.0032, -0.0096,  0.0111],\n",
      "        [ 0.0248, -0.0006, -0.0038,  ..., -0.0184, -0.0092, -0.0013]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-4.9082e-03,  3.1176e-04, -3.2919e-04,  2.8362e-05, -1.9417e-03,\n",
      "        -3.0090e-03, -2.6534e-03, -8.0909e-03, -3.5980e-03,  2.0790e-03,\n",
      "        -8.1846e-04,  1.6337e-05,  2.5154e-03, -1.4523e-03, -1.5086e-05,\n",
      "        -2.0735e-03, -8.3525e-04,  2.2902e-03,  4.2564e-04,  2.4891e-03,\n",
      "        -1.4964e-02, -2.5733e-03, -2.8130e-03,  4.4116e-03,  3.8324e-03,\n",
      "         1.2462e-03,  2.4635e-03,  3.1296e-03,  2.7848e-03,  2.2270e-03,\n",
      "         1.9327e-02,  2.2972e-03,  1.9854e-03, -3.0669e-03, -5.9772e-04,\n",
      "         2.3705e-03,  4.0496e-03, -1.8623e-03,  1.1914e-03, -1.4384e-03,\n",
      "        -1.8804e-03,  4.3415e-03, -2.3925e-03,  3.5073e-03,  2.1328e-03,\n",
      "         2.1183e-03, -9.6810e-04,  1.8106e-03,  7.2912e-04, -8.2252e-04,\n",
      "         4.5656e-04, -1.5709e-03,  1.3431e-03,  3.1179e-04,  2.2415e-03,\n",
      "        -2.2159e-03, -3.3950e-03, -1.0926e-04,  3.1587e-03, -8.3179e-04,\n",
      "        -3.6843e-03,  1.5430e-03, -2.1363e-03, -1.6863e-03,  2.9039e-03,\n",
      "         2.9194e-03, -4.2737e-03,  3.2294e-03,  1.6598e-03, -2.0783e-03,\n",
      "         3.5107e-03, -3.9334e-03,  2.2122e-03,  3.3054e-03, -2.8065e-03,\n",
      "        -7.8643e-04, -1.9437e-03,  2.0919e-03, -4.7211e-03,  1.5172e-03,\n",
      "         5.1939e-04, -9.2654e-05,  7.8253e-03, -6.0467e-04,  2.8009e-03,\n",
      "         1.0765e-03, -1.7807e-03,  3.4977e-04, -4.1417e-03,  1.5206e-03,\n",
      "        -7.1628e-04, -2.8606e-03, -6.9594e-04, -2.8201e-03, -2.9440e-03,\n",
      "         1.2097e-03, -1.0932e-02,  4.4991e-03, -2.1959e-03, -1.6026e-03,\n",
      "         4.5092e-03, -4.1523e-03,  1.6864e-03,  2.2815e-03, -6.8299e-04,\n",
      "         9.6466e-04, -3.8877e-03, -1.0527e-03,  2.2401e-03,  1.3104e-03,\n",
      "        -9.5881e-04, -1.9952e-03,  1.7647e-03, -1.8415e-03,  1.1683e-03,\n",
      "         5.2318e-04, -3.8715e-03, -2.1948e-03, -1.6784e-03,  2.9793e-03,\n",
      "         8.2550e-04, -5.0039e-03,  1.8799e-03, -1.5122e-03,  2.4672e-03,\n",
      "        -2.0950e-03, -3.2469e-03, -3.3979e-04], requires_grad=True), Parameter containing:\n",
      "tensor([1.0272, 1.0419, 1.0226, 1.0111, 1.0290, 1.0872, 1.0193, 1.0247, 1.0977,\n",
      "        1.0171, 1.0282, 1.0107, 1.0401, 1.0391, 1.0155, 1.0107, 1.1323, 1.0520,\n",
      "        1.0159, 1.0161, 1.2197, 1.0171, 1.0555, 1.2485, 1.0585, 1.0238, 1.0401,\n",
      "        1.0115, 1.0483, 1.0180, 1.0944, 1.0072, 1.1204, 1.0176, 1.0144, 1.0085,\n",
      "        1.0547, 1.0559, 1.0122, 1.0132, 1.0375, 1.0185, 1.1231, 1.0412, 1.0850,\n",
      "        1.0507, 1.0190, 1.0172, 1.0327, 1.0500, 1.0127, 1.0145, 1.0964, 1.0192,\n",
      "        1.0082, 1.0298, 1.0385, 1.0185, 1.0347, 1.0115, 1.0141, 1.0082, 1.0216,\n",
      "        1.0369, 1.0231, 1.0458, 1.0127, 1.0114, 1.0120, 1.0177, 1.0721, 1.0383,\n",
      "        1.0164, 1.0157, 1.0167, 1.0257, 1.0409, 1.0277, 1.0172, 1.0361, 1.1721,\n",
      "        1.0114, 1.0684, 1.0120, 1.0086, 1.0116, 1.0078, 1.0124, 1.0227, 1.0148,\n",
      "        1.0236, 1.0955, 1.0161, 1.0730, 1.0126, 1.0299, 1.1112, 1.0185, 1.1388,\n",
      "        1.0195, 1.0262, 1.0438, 1.0211, 1.0555, 1.0100, 1.0110, 1.0950, 1.0169,\n",
      "        1.0596, 1.0226, 1.0236, 1.0173, 1.0222, 1.0152, 1.0733, 1.0416, 1.0306,\n",
      "        1.0216, 1.0333, 1.0327, 1.0255, 1.0143, 1.0107, 1.0604, 1.0088, 1.1717,\n",
      "        1.0193, 1.0076], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0011, -0.0189, -0.0142, -0.0209, -0.0460, -0.0378, -0.0033, -0.0504,\n",
      "        -0.0270,  0.0435, -0.0034, -0.0024,  0.0283, -0.0303, -0.0248,  0.0017,\n",
      "        -0.0294,  0.0318, -0.0045,  0.0013, -0.0808, -0.0201, -0.0337,  0.0704,\n",
      "         0.0561,  0.0047,  0.0336,  0.0119,  0.0263,  0.0245,  0.0697, -0.0060,\n",
      "         0.0590, -0.0340,  0.0406,  0.0062,  0.0369, -0.0680, -0.0117,  0.0019,\n",
      "        -0.0277,  0.0274,  0.0006,  0.0407,  0.0344,  0.0517,  0.0159,  0.0082,\n",
      "         0.0132, -0.0227, -0.0013, -0.0387, -0.0391,  0.0070,  0.0222, -0.0255,\n",
      "        -0.0269,  0.0006,  0.0346, -0.0038, -0.0222,  0.0109, -0.0302,  0.0035,\n",
      "         0.0446, -0.0115, -0.0303, -0.0043,  0.0208, -0.0279,  0.0302, -0.0437,\n",
      "         0.0114,  0.0149,  0.0003, -0.0078, -0.0414,  0.0237, -0.0200, -0.0137,\n",
      "        -0.0124,  0.0110,  0.0378, -0.0293, -0.0089,  0.0195, -0.0030, -0.0208,\n",
      "        -0.0331,  0.0462, -0.0059, -0.0538,  0.0031, -0.0626, -0.0121, -0.0333,\n",
      "        -0.0633,  0.0468, -0.0339,  0.0113,  0.0292, -0.0544,  0.0242,  0.0355,\n",
      "        -0.0099,  0.0082, -0.0252, -0.0040,  0.0248, -0.0045, -0.0391, -0.0034,\n",
      "        -0.0017, -0.0159,  0.0516,  0.0116, -0.0438, -0.0102, -0.0244,  0.0252,\n",
      "         0.0146, -0.0455,  0.0216, -0.0202,  0.0129,  0.0572, -0.0087,  0.0197],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0304, -0.0042,  0.0163,  ..., -0.0051,  0.0447,  0.0138],\n",
      "        [ 0.0046,  0.0033,  0.0176,  ..., -0.0190, -0.0197, -0.0079],\n",
      "        [ 0.0108, -0.0185, -0.0173,  ..., -0.0272, -0.0028,  0.0011],\n",
      "        ...,\n",
      "        [ 0.0901,  0.0235,  0.0503,  ...,  0.0284,  0.0382,  0.1003],\n",
      "        [ 0.0183,  0.0147,  0.0362,  ...,  0.0383, -0.0195, -0.0066],\n",
      "        [ 0.0427,  0.0109, -0.0236,  ...,  0.0283, -0.0320, -0.0080]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 2.7770e-02,  1.2664e-02,  1.0466e-02,  6.7339e-03,  1.2053e-03,\n",
      "         1.3900e-02,  5.3821e-03,  9.3936e-03, -1.8620e-04,  6.1778e-03,\n",
      "         9.2649e-03,  1.9677e-02,  3.1125e-03,  7.5431e-03,  7.6426e-03,\n",
      "         7.0436e-03,  4.1375e-03,  1.1591e-02,  8.6228e-03,  4.0422e-03,\n",
      "         1.4704e-02,  5.4565e-03,  6.4502e-03,  1.1712e-02,  1.0637e-02,\n",
      "         5.6434e-03,  4.9887e-03,  1.3704e-02,  3.9652e-03,  5.0498e-03,\n",
      "         8.5706e-03,  9.9271e-03,  5.8312e-03,  7.7375e-03,  9.2309e-03,\n",
      "         4.2361e-03,  7.3614e-03,  1.1471e-02,  7.8651e-03,  7.5488e-03,\n",
      "         7.5902e-03,  3.3864e-03,  5.2946e-03,  1.8199e-03,  9.9020e-03,\n",
      "         7.8847e-03,  5.4384e-03,  5.4811e-03,  4.0802e-02,  1.5960e-02,\n",
      "         5.5825e-03,  5.1232e-03,  9.8381e-03,  1.3792e-02,  1.0742e-02,\n",
      "         8.0104e-03,  5.9634e-03,  6.1403e-03, -9.1352e-04,  1.2955e-02,\n",
      "         7.1810e-03,  8.0889e-03,  1.2093e-02,  8.0128e-03,  6.3257e-03,\n",
      "         1.0150e-02,  1.0442e-02,  8.9944e-03,  9.5541e-03,  4.8380e-03,\n",
      "         8.7213e-03,  8.6279e-03,  3.5373e-03,  1.2043e-02,  4.7674e-03,\n",
      "         9.0939e-03,  7.2113e-03,  1.1641e-02,  1.3688e-02,  4.5441e-03,\n",
      "         6.1575e-03,  2.1933e-03,  1.1275e-02,  1.1646e-02,  1.0421e-02,\n",
      "         2.9453e-03,  1.3054e-02,  6.6707e-03,  1.8617e-02,  7.9424e-03,\n",
      "         7.6148e-03, -6.8813e-04,  1.1428e-02,  8.2003e-03,  2.1530e-02,\n",
      "         4.3414e-04,  6.0823e-03,  6.6208e-03,  1.0531e-02,  6.9487e-03,\n",
      "         2.0736e-02,  1.5209e-02,  2.1815e-02,  9.1732e-03,  8.7012e-03,\n",
      "        -2.9556e-05,  8.4058e-03,  9.3307e-03,  7.5921e-03, -1.8572e-03,\n",
      "         5.2810e-03,  9.3106e-03,  1.8051e-02,  5.6117e-03,  2.3701e-02,\n",
      "         1.4218e-02,  1.1044e-02,  7.5670e-03,  7.0624e-03,  6.0600e-03,\n",
      "         3.4249e-03,  1.0533e-02,  6.1327e-03,  1.3829e-02,  1.9669e-02,\n",
      "         4.9443e-03,  5.2167e-03,  1.1364e-03,  6.5941e-03,  6.4907e-03,\n",
      "         9.9805e-03, -1.9974e-03,  1.0498e-02,  4.7583e-03,  4.8719e-03,\n",
      "         5.6111e-03,  7.4023e-03,  1.4746e-02,  1.0640e-02,  5.9989e-03,\n",
      "         7.2535e-03,  7.6968e-03,  8.2788e-03,  6.8674e-03,  7.8447e-03,\n",
      "         1.4005e-03,  5.3893e-03,  3.7577e-03,  1.5755e-02,  5.3353e-03,\n",
      "         8.4134e-03,  1.6061e-02,  1.5072e-02,  1.0027e-02,  2.6001e-02,\n",
      "         2.6701e-03,  6.4251e-03,  7.6098e-03,  1.6897e-02,  5.5826e-03,\n",
      "         9.4362e-03,  1.3377e-02,  4.7489e-03,  1.4412e-02,  5.7140e-03,\n",
      "         7.4054e-03,  6.1590e-03,  8.4383e-03,  8.0396e-03,  2.1667e-03,\n",
      "         7.1563e-03,  8.8359e-03,  7.3719e-03,  4.6871e-03,  4.0550e-03,\n",
      "         2.7443e-03,  2.6356e-02,  5.1618e-03,  2.2725e-02,  9.3249e-03,\n",
      "         1.0055e-02,  5.7092e-04,  4.4518e-03,  1.0833e-02,  9.2932e-03,\n",
      "         8.9034e-03,  5.6018e-03,  8.1671e-03,  5.2348e-03,  1.0573e-02,\n",
      "         1.2781e-03,  1.3893e-02,  1.0569e-02,  1.1139e-02,  4.2890e-03,\n",
      "         1.1209e-02,  1.7237e-02,  6.5833e-03,  2.6637e-02,  9.4098e-03,\n",
      "         5.3252e-03,  1.0740e-02,  5.4945e-03,  6.5955e-03,  8.3271e-03,\n",
      "         5.8671e-03,  3.6919e-03,  2.4317e-02,  1.6450e-02,  4.8418e-03,\n",
      "         5.8348e-03,  9.6581e-03,  1.2748e-02,  3.8358e-03,  1.4150e-02,\n",
      "         5.7068e-03,  1.3763e-02,  5.4952e-03,  8.8490e-03,  1.8087e-02,\n",
      "         2.2048e-02,  8.5544e-03,  7.8457e-03, -9.4364e-04,  7.8707e-03,\n",
      "         4.0674e-03, -1.0352e-03,  5.2667e-03,  6.8017e-03,  7.5213e-03,\n",
      "         8.5918e-03,  6.4906e-03,  4.3946e-04,  1.3446e-02,  3.1275e-02,\n",
      "         1.1497e-02,  1.6299e-02,  7.3109e-03,  7.6853e-03,  7.8392e-03,\n",
      "         6.5121e-03,  8.1038e-03,  4.2407e-03,  7.0093e-03,  1.0996e-02,\n",
      "         7.1496e-03,  9.6786e-03,  1.0200e-02,  6.6493e-03,  1.2743e-02,\n",
      "         2.4417e-03,  2.1151e-02,  2.3370e-02,  5.8933e-03,  1.3728e-02,\n",
      "         8.5348e-03,  1.6446e-02,  1.3661e-02,  7.0260e-03,  8.9861e-03,\n",
      "         1.8646e-02,  4.1610e-03,  7.6375e-03,  1.3290e-02,  1.8410e-02,\n",
      "         3.8838e-03,  9.4253e-03,  6.8601e-03,  3.8697e-03, -9.0180e-04,\n",
      "         2.4666e-02,  1.1140e-02, -1.3515e-03,  9.3789e-03,  1.0559e-02,\n",
      "         1.6965e-02,  9.0444e-03,  1.2718e-02,  1.1602e-02,  7.3660e-03,\n",
      "         7.6765e-03,  1.0927e-02,  7.4784e-03,  2.9758e-03,  9.8392e-03,\n",
      "         8.5757e-03,  8.7527e-03,  7.8287e-03,  7.8632e-03,  1.0600e-02,\n",
      "         6.4352e-03,  3.1809e-02,  1.0152e-02,  1.2476e-02,  4.6323e-03,\n",
      "         1.1102e-02,  5.1287e-03,  7.5723e-03,  1.4384e-02,  1.1288e-02,\n",
      "         6.3621e-03,  6.3264e-03,  1.5251e-02,  7.2653e-03,  5.3958e-03,\n",
      "         1.1012e-02,  8.1249e-03,  8.1607e-03,  7.7136e-03,  1.1142e-02,\n",
      "        -1.5538e-03,  8.1544e-03,  4.9662e-03,  3.1534e-02,  9.3742e-03,\n",
      "         1.0197e-02,  7.1162e-03,  8.8872e-03,  7.8794e-03,  5.7150e-03,\n",
      "         5.8078e-03,  7.5075e-03,  1.0151e-02,  7.9600e-03,  2.0639e-02,\n",
      "         5.5820e-03,  1.0092e-02,  5.8952e-04,  5.1692e-03,  6.7236e-03,\n",
      "         1.2000e-02,  1.6905e-02,  3.0038e-03,  6.9007e-03,  7.4836e-03,\n",
      "         8.6714e-03,  7.6517e-03,  1.7400e-02,  8.4215e-03,  2.8513e-03,\n",
      "         3.7234e-03,  7.6400e-03,  7.2819e-03,  1.1173e-02,  6.0275e-03,\n",
      "         9.1486e-03,  1.2690e-02,  6.7119e-03,  1.1146e-02,  6.6922e-03,\n",
      "         8.7215e-03,  8.2891e-03,  5.9177e-03,  5.1303e-03,  3.6579e-03,\n",
      "         1.1595e-02,  8.3752e-03,  9.9396e-03,  2.2031e-03,  8.9667e-03,\n",
      "         6.9786e-03,  3.1187e-03,  7.7176e-03,  1.2198e-02,  3.6173e-03,\n",
      "         2.4488e-03,  9.4155e-03, -4.5048e-03,  7.1062e-03,  2.2102e-02,\n",
      "         1.3207e-02,  6.6344e-03,  1.6342e-03,  6.6448e-03,  1.1724e-02,\n",
      "         5.2632e-03,  8.9641e-03, -1.3764e-03,  8.1563e-03,  1.5122e-02,\n",
      "         4.5991e-03,  1.1364e-02,  1.7374e-02,  1.3564e-02,  5.5991e-03,\n",
      "         3.3544e-03,  7.1153e-03,  3.1604e-03,  1.2819e-02, -9.9208e-04,\n",
      "         5.1361e-03,  2.2233e-02,  7.2254e-03,  6.8067e-03,  8.2781e-03,\n",
      "         1.3918e-02,  6.7224e-03,  3.0158e-02,  7.9803e-03,  6.3365e-03,\n",
      "         1.8207e-02,  1.6428e-02,  5.3809e-03,  2.6093e-02,  1.7367e-02,\n",
      "         4.0859e-03,  1.5984e-02,  1.9253e-02,  7.0551e-03,  5.9457e-03,\n",
      "         4.4968e-03,  6.0581e-03,  5.9148e-03,  1.1153e-02,  3.4762e-04,\n",
      "         1.1841e-02,  5.2843e-03,  1.5481e-02,  1.9623e-02,  4.5580e-03,\n",
      "         6.4568e-03, -1.0524e-03,  6.0428e-03,  7.5748e-03,  6.1026e-03,\n",
      "         1.4691e-02,  6.1604e-03,  8.9550e-03,  1.9823e-03,  5.9766e-03,\n",
      "         1.1637e-02,  1.0469e-02,  4.7190e-03,  1.0447e-03,  2.7641e-02,\n",
      "         6.6164e-03,  1.5573e-02,  9.2616e-03,  6.7435e-03,  1.9350e-02,\n",
      "         1.6565e-02,  2.1998e-02,  1.6409e-02,  7.3530e-03,  6.4626e-03,\n",
      "         4.7459e-03,  9.9063e-03,  5.5931e-03,  3.1598e-03,  1.0070e-02,\n",
      "        -2.1735e-03, -1.5089e-04,  8.7828e-03,  9.2429e-03,  6.0150e-03,\n",
      "         5.7638e-03,  6.6921e-03, -1.4570e-03,  1.0277e-02,  6.5830e-03,\n",
      "         7.6764e-03,  2.2840e-02,  1.2783e-02,  7.2685e-03,  1.0548e-02,\n",
      "         4.8431e-03,  1.4763e-02,  4.2067e-03,  1.0167e-02,  7.3112e-03,\n",
      "         9.6999e-03,  2.3505e-02,  1.1187e-02,  9.5513e-03,  6.8260e-03,\n",
      "         3.9547e-03,  2.7147e-03,  3.6388e-03,  9.9349e-03,  4.8118e-03,\n",
      "         5.4062e-03,  6.9946e-03,  7.1612e-03,  7.2806e-03,  5.4354e-03,\n",
      "         7.4707e-03,  3.8752e-03,  5.9590e-03,  7.9449e-03,  1.0964e-04,\n",
      "         6.8028e-03,  7.5115e-03,  5.9669e-03,  1.4339e-02,  5.6852e-03,\n",
      "         6.0306e-03,  1.0659e-02,  9.1095e-03,  1.7026e-02,  1.0052e-02,\n",
      "         1.1133e-02,  5.9597e-03,  5.0044e-03,  6.8247e-03,  2.0261e-03,\n",
      "         5.1231e-03,  1.8234e-03,  5.4833e-03,  1.2350e-02,  6.3324e-03,\n",
      "         9.0757e-03,  1.0975e-02], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0139, -0.0126, -0.0063,  ...,  0.0049,  0.0053, -0.0034],\n",
      "        [-0.0239,  0.0068,  0.0093,  ..., -0.0058, -0.0111, -0.0030],\n",
      "        [-0.0044,  0.0075,  0.0029,  ..., -0.0217, -0.0045, -0.0036],\n",
      "        ...,\n",
      "        [-0.0129,  0.0031,  0.0206,  ..., -0.0097,  0.0040, -0.0005],\n",
      "        [-0.0119, -0.0116,  0.0113,  ...,  0.0136, -0.0099, -0.0084],\n",
      "        [-0.0081,  0.0234, -0.0037,  ..., -0.0012,  0.0011,  0.0081]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-1.0351e-03, -2.6656e-04, -4.6629e-04, -2.4033e-04, -2.2953e-03,\n",
      "        -2.7491e-03, -1.7265e-03, -5.2401e-03, -2.6724e-03,  2.0877e-03,\n",
      "        -2.7288e-03, -1.1437e-05,  2.3708e-03, -1.7212e-03,  1.1123e-03,\n",
      "        -2.9141e-04, -1.1861e-03,  2.4279e-03,  9.2043e-04,  1.7336e-03,\n",
      "        -1.4734e-02, -2.4233e-03, -1.9510e-03,  4.2750e-03,  2.8683e-03,\n",
      "         2.1125e-03,  1.6867e-03,  1.9612e-03,  2.9442e-03,  1.7394e-03,\n",
      "         1.3856e-02,  1.3044e-03,  2.6400e-03, -3.2025e-03,  3.1060e-03,\n",
      "         2.0147e-03,  3.6041e-03, -1.9564e-03,  1.7517e-03, -1.0338e-03,\n",
      "        -1.4890e-03,  2.1029e-03,  1.6972e-03,  2.9491e-03,  2.6669e-03,\n",
      "         2.5077e-03, -1.0553e-03,  2.2817e-03,  2.5447e-03,  9.4120e-04,\n",
      "        -5.7817e-04, -1.9435e-03, -4.8135e-05, -8.2213e-04,  2.1398e-03,\n",
      "        -2.0311e-03, -2.8496e-03,  4.6067e-05,  8.6509e-04, -1.0849e-03,\n",
      "        -2.7286e-03,  1.8522e-03, -2.2300e-03,  1.4640e-03,  2.4571e-03,\n",
      "         6.5798e-04, -2.4764e-03,  1.2458e-03,  1.5859e-03, -1.3645e-03,\n",
      "         2.7538e-03, -3.4835e-03,  1.5841e-03,  3.2246e-03, -2.2809e-03,\n",
      "        -1.5518e-03, -2.0009e-03,  1.9089e-03, -3.5843e-03,  6.7912e-04,\n",
      "        -2.7842e-03, -1.4979e-03,  2.5359e-03, -1.8129e-03,  1.3483e-03,\n",
      "         1.6883e-03, -1.9272e-03,  1.8502e-03, -3.2126e-03,  2.8574e-03,\n",
      "        -1.3846e-03, -2.4918e-03, -1.5119e-03, -2.3979e-03, -2.1466e-03,\n",
      "         1.2775e-03, -1.0643e-02,  3.4002e-03, -2.5401e-03, -2.8509e-03,\n",
      "         1.4765e-03, -3.8245e-03,  1.6627e-03,  2.2610e-03, -7.7766e-05,\n",
      "         1.1478e-03, -3.0997e-03, -1.6172e-03,  2.3784e-03,  4.0810e-04,\n",
      "         4.8825e-05, -1.6616e-03,  2.0014e-03, -1.9162e-03,  1.9186e-03,\n",
      "         1.4002e-03, -2.0848e-03, -2.2784e-03, -1.7684e-03,  2.4541e-03,\n",
      "         2.2649e-03, -3.6768e-03,  1.8554e-03, -2.3192e-03,  2.4980e-03,\n",
      "        -1.3461e-03, -2.6414e-03, -6.7055e-04], requires_grad=True), Parameter containing:\n",
      "tensor([0.9895, 0.9902, 0.9960, 0.9897, 0.9842, 0.9790, 0.9909, 0.9801, 0.9774,\n",
      "        0.9907, 0.9896, 0.9967, 0.9903, 0.9885, 0.9898, 0.9922, 0.9707, 0.9769,\n",
      "        0.9912, 0.9938, 0.9607, 0.9854, 0.9849, 0.9583, 0.9736, 0.9961, 0.9972,\n",
      "        0.9912, 0.9887, 0.9836, 0.9678, 0.9905, 0.9680, 0.9838, 0.9896, 0.9898,\n",
      "        0.9795, 0.9846, 0.9851, 0.9948, 0.9986, 0.9863, 0.9880, 0.9840, 0.9748,\n",
      "        0.9845, 0.9943, 0.9838, 0.9859, 0.9956, 0.9919, 0.9880, 0.9796, 0.9921,\n",
      "        0.9913, 0.9891, 0.9836, 0.9970, 0.9945, 0.9865, 0.9810, 0.9932, 0.9946,\n",
      "        0.9814, 0.9739, 0.9877, 0.9838, 0.9904, 0.9911, 0.9920, 0.9917, 0.9797,\n",
      "        0.9939, 0.9861, 0.9879, 0.9960, 0.9925, 0.9948, 0.9843, 0.9965, 0.9860,\n",
      "        0.9947, 0.9835, 0.9867, 0.9965, 0.9931, 0.9965, 0.9958, 0.9795, 0.9923,\n",
      "        0.9945, 0.9670, 0.9857, 0.9874, 0.9861, 0.9836, 0.9570, 0.9813, 0.9682,\n",
      "        0.9890, 0.9977, 0.9794, 0.9977, 0.9834, 0.9911, 0.9917, 0.9735, 0.9944,\n",
      "        0.9870, 0.9953, 0.9914, 0.9877, 0.9932, 0.9935, 0.9683, 0.9771, 0.9943,\n",
      "        0.9835, 0.9854, 0.9886, 0.9920, 0.9780, 0.9842, 0.9876, 0.9853, 0.9642,\n",
      "        0.9941, 0.9924], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0045,  0.0011,  0.0004,  0.0022, -0.0055, -0.0080, -0.0048, -0.0041,\n",
      "        -0.0045,  0.0051, -0.0050,  0.0022,  0.0046, -0.0046,  0.0026, -0.0042,\n",
      "        -0.0079,  0.0054, -0.0006,  0.0069, -0.0013, -0.0050, -0.0049,  0.0057,\n",
      "         0.0061,  0.0107,  0.0057,  0.0055,  0.0063,  0.0035,  0.0011, -0.0043,\n",
      "         0.0006,  0.0004,  0.0007,  0.0061,  0.0055, -0.0037,  0.0035, -0.0036,\n",
      "        -0.0049,  0.0007,  0.0005,  0.0023, -0.0018,  0.0088, -0.0045,  0.0049,\n",
      "        -0.0009,  0.0039, -0.0015, -0.0060,  0.0030, -0.0036,  0.0050, -0.0059,\n",
      "        -0.0080, -0.0013, -0.0031, -0.0028, -0.0033,  0.0037, -0.0025,  0.0019,\n",
      "         0.0058,  0.0002,  0.0008,  0.0016,  0.0041, -0.0026,  0.0060, -0.0085,\n",
      "         0.0026, -0.0027, -0.0055, -0.0028, -0.0045,  0.0082, -0.0035,  0.0044,\n",
      "        -0.0095, -0.0048,  0.0042, -0.0018, -0.0016,  0.0030, -0.0059,  0.0059,\n",
      "        -0.0062,  0.0034, -0.0033, -0.0069, -0.0032, -0.0068, -0.0096,  0.0041,\n",
      "        -0.0058,  0.0061,  0.0008, -0.0071,  0.0029, -0.0056,  0.0049,  0.0036,\n",
      "         0.0022, -0.0005, -0.0059, -0.0065,  0.0045,  0.0002,  0.0023, -0.0065,\n",
      "         0.0048, -0.0036,  0.0027,  0.0055, -0.0065, -0.0049, -0.0044,  0.0058,\n",
      "         0.0019, -0.0047,  0.0045, -0.0054,  0.0059,  0.0022, -0.0065, -0.0024],\n",
      "       requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# Create the decision transformer model\n",
    "model = DecisionTransformerModel.from_pretrained('trained_models')\n",
    "model = model.to(device)\n",
    "\n",
    "print(list(model.encoder.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20c2431",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "\n",
    "Here we are defining the `get_action` function, where is the core inference function for the Decision Transformer during evaluation. It performs autoregression action prediction using a sliding window approach.\n",
    "\n",
    "This function takes the current trading history and predicts the next action the Decision Transformer should take, conditioned on the desired return-to-go target.\n",
    "\n",
    "The autoregressive generation uses the previous 20 timesteps to predict the next action. Each prediction is based on recent history and target return.\n",
    "\n",
    "Actions are conditioned on the target performance and the model learns to achieve the specified return target.\n",
    "\n",
    "#### Input Reshaping (Line 5-8)\n",
    "\n",
    "* Reshape all inputs to batch format: `(batch_size=1, sequences_length, feature_dim)`\n",
    "* Prepares data for the transformer model\n",
    "\n",
    "#### Sliding Window (Lines 12-16)\n",
    "\n",
    "* Takes only the last `max_length` timesteps (typically 20)\n",
    "* Creates a sliding window of recent history\n",
    "* Calcualtes how much padding is needed\n",
    "\n",
    "#### Padding (Lines 19-24)\n",
    "\n",
    "* Pads sequences to a fixed length\n",
    "* Adds zeros at the beginning for padding\n",
    "* Creates attention mask: 0 for padding, 1 for real data\n",
    "\n",
    "#### Model Prediction (Lines 26-32)\n",
    "\n",
    "* Feeds the padded sequence to the Decision Transformer\n",
    "* Model processes the sequence through its attention layers\n",
    "* Returns predictions for states, actions, return-to-go\n",
    "\n",
    "#### Extract Action (Lines 34)\n",
    "* Returns only the last predicted action `([0,1])`\n",
    "* This is the action for the current timestep\n",
    "* Ignores predictions for previous timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d8d57be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that gets an action from the model using autoregressive prediction with a window of the previous 20 timesteps.\n",
    "def get_action(model, states, actions, rewards, returns_to_go, timesteps):\n",
    "    # This implementation does not condition on past rewards\n",
    "\n",
    "    # Reshape inputs to batch format\n",
    "    states = states.reshape(1, -1, model.config.state_dim)\n",
    "    actions = actions.reshape(1, -1, model.config.act_dim)\n",
    "    returns_to_go = returns_to_go.reshape(1, -1, 1)\n",
    "    timesteps = timesteps.reshape(1, -1)\n",
    "\n",
    "    #Sliding Window \n",
    "    states = states[:, -model.config.max_length :]\n",
    "    actions = actions[:, -model.config.max_length :]\n",
    "    returns_to_go = returns_to_go[:, -model.config.max_length :]\n",
    "    timesteps = timesteps[:, -model.config.max_length :]\n",
    "    padding = model.config.max_length - states.shape[1]\n",
    "    \n",
    "    # pad all tokens to sequence length\n",
    "    attention_mask = torch.cat([torch.zeros(padding), torch.ones(states.shape[1])]).to(device=device)\n",
    "    attention_mask = attention_mask.to(dtype=torch.long).reshape(1, -1)\n",
    "    states = torch.cat([torch.zeros((1, padding, model.config.state_dim)), states], dim=1).float().to(device=device)\n",
    "    actions = torch.cat([torch.zeros((1, padding, model.config.act_dim)), actions], dim=1).float().to(device=device)\n",
    "    returns_to_go = torch.cat([torch.zeros((1, padding, 1)), returns_to_go], dim=1).float().to(device=device)\n",
    "    timesteps = torch.cat([torch.zeros((1, padding), dtype=torch.long), timesteps], dim=1).to(device=device)\n",
    "\n",
    "    state_preds, action_preds, return_preds = model(\n",
    "        states=states,\n",
    "        actions=actions,\n",
    "        rewards=rewards,\n",
    "        returns_to_go=returns_to_go,\n",
    "        timesteps=timesteps,\n",
    "        attention_mask=attention_mask,\n",
    "        return_dict=False,\n",
    "    )\n",
    "\n",
    "    return action_preds[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "944faa96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(180845)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_steps = e_trade_gym.df.tic.count() - 1\n",
    "max_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d06f3e",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "This is the main evluation loop for the Decision Transformer, where it interacts with the trading environment to test the model's performance.\n",
    "\n",
    "#### Initialization (Lines 4-17)\n",
    "\n",
    "* Resets environment and initializes tracking variables\n",
    "* Sets targets return (the performance goal the DT should achieve)\n",
    "* Initializes empty tensors for states, actions, rewards, and timesteps\n",
    "* Prepares data structures for the autoregressive generation\n",
    "\n",
    "#### Action Prediction (Lines 20-32)\n",
    "\n",
    "* Adds placeholder for current action and reward\n",
    "* Calls the Decision Transformer to predict next trading action\n",
    "* uses normalized states (subtracts mean, divides by std)\n",
    "\n",
    "#### Environment Interaction (Lines 35-40)\n",
    "* Executes the predicted action in the trading environment\n",
    "* Receives new state and reward from the environment\n",
    "* Updates the state and reward history\n",
    "\n",
    "#### Target Return Updates (Lines 42-44)\n",
    "* Updates the target return by subtracting the achieved reward\n",
    "* Maintains the remaining target for future timesteps\n",
    "* Updates timesteps counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0d77d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drebi\\AppData\\Local\\Temp\\ipykernel_38216\\392077640.py:42: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  pred_return = target_return[0, -1] - (reward / scale)\n",
      "C:\\Users\\drebi\\AppData\\Local\\Temp\\ipykernel_38216\\392077640.py:42: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  pred_return = target_return[0, -1] - (reward / scale)\n"
     ]
    }
   ],
   "source": [
    "# Interact with the environment\n",
    "#max_ep_len = 1000\n",
    "\n",
    "episode_return, episode_length = 0, 0\n",
    "state = env.reset()\n",
    "target_return = torch.tensor(TARGET_RETURN, device=device, dtype=torch.float32).reshape(1, 1)\n",
    "states = torch.from_numpy(state).reshape(1, state_dim).to(device=device, dtype=torch.float32)\n",
    "actions = torch.zeros((0, act_dim), device=device, dtype=torch.float32)\n",
    "rewards = torch.zeros(0, device=device, dtype=torch.float32)\n",
    "\n",
    "timesteps = torch.tensor(0, device=device, dtype=torch.long).reshape(1, 1)\n",
    "\n",
    "#max_steps = e_trade_gym.df.tic.count() - 1\n",
    "max_steps = len(e_trade_gym.df.index.unique()) - 1\n",
    "\n",
    "account_memory = None  # This help avoid unnecessary list creation\n",
    "actions_memory = None  # optimize memory consumption\n",
    "\n",
    "for t in range(max_steps+1):\n",
    "    actions = torch.cat([actions, torch.zeros((1, act_dim), device=device)], dim=0)\n",
    "    rewards = torch.cat([rewards, torch.zeros(1, device=device)])\n",
    "\n",
    "    action = get_action(\n",
    "        model,\n",
    "        (states - state_mean) / state_std,\n",
    "        actions,\n",
    "        rewards,\n",
    "        target_return,\n",
    "        timesteps,\n",
    "    )\n",
    "\n",
    "    actions[-1] = action\n",
    "    actions_numpy = actions.detach().cpu().numpy()\n",
    "\n",
    "    #state, reward, done, truncated, info = env.step(actions_numpy)\n",
    "    state, reward, done, _ = env.step(actions_numpy)\n",
    "\n",
    "    cur_state = torch.from_numpy(state).to(device=device).reshape(1, state_dim)\n",
    "    states = torch.cat([states, cur_state], dim=0)\n",
    "    rewards[-1] = torch.from_numpy(reward).to(device=device)\n",
    "\n",
    "    pred_return = target_return[0, -1] - (reward / scale)\n",
    "    target_return = torch.cat([target_return, pred_return.reshape(1, 1)], dim=1)\n",
    "    timesteps = torch.cat([timesteps, torch.ones((1, 1), device=device, dtype=torch.long) * (t + 1)], dim=1)\n",
    "\n",
    "    episode_return += reward\n",
    "    episode_length += 1\n",
    "\n",
    "    if (t == max_steps - 1):  # more descriptive condition for early termination to clarify the logic\n",
    "        # Call instance methods of vectorized environments\n",
    "        # https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html\n",
    "        account_memory = env.env_method(method_name=\"save_asset_memory\")\n",
    "        actions_memory = env.env_method(method_name=\"save_action_memory\")\n",
    "\n",
    "    if done[0]:# or truncated:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f2fb65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_dt, df_actions_dt = account_memory[0], actions_memory[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b29e3e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((459, 2), (458, 394))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value_dt.shape, df_actions_dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8aff81e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>1.000000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-05</td>\n",
       "      <td>9.986497e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-06</td>\n",
       "      <td>9.992926e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-07</td>\n",
       "      <td>1.004898e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-08</td>\n",
       "      <td>1.002063e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  account_value\n",
       "0  2022-07-01   1.000000e+06\n",
       "1  2022-07-05   9.986497e+05\n",
       "2  2022-07-06   9.992926e+05\n",
       "3  2022-07-07   1.004898e+06\n",
       "4  2022-07-08   1.002063e+06"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value_dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99e34ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>1.285404e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>2024-04-24</td>\n",
       "      <td>1.285611e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>2024-04-25</td>\n",
       "      <td>1.281273e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>2024-04-26</td>\n",
       "      <td>1.283513e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>1.288143e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  account_value\n",
       "454  2024-04-23   1.285404e+06\n",
       "455  2024-04-24   1.285611e+06\n",
       "456  2024-04-25   1.281273e+06\n",
       "457  2024-04-26   1.283513e+06\n",
       "458  2024-04-29   1.288143e+06"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value_dt.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52e0f833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>ADI</th>\n",
       "      <th>ADM</th>\n",
       "      <th>ADP</th>\n",
       "      <th>...</th>\n",
       "      <th>WU</th>\n",
       "      <th>WY</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XRX</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZION</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-07-01</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-05</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-06</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-07</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-08</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             A  AAL  AAP  AAPL  ABT  ACN  ADBE  ADI  ADM  ADP  ...  WU  WY  \\\n",
       "date                                                           ...           \n",
       "2022-07-01  13    3    6     0    0    0     0    5    0    0  ...   0   0   \n",
       "2022-07-05  13    3    6     0    0    0     0    5    0    0  ...   0   0   \n",
       "2022-07-06  13    3    6     0    0    0     0    5    0    0  ...   0   0   \n",
       "2022-07-07  13    3    6     0    0    0     0    5    0    0  ...   0   0   \n",
       "2022-07-08  13    0    0     0    0    0     0    0    0    0  ...   0   0   \n",
       "\n",
       "            WYNN  XEL  XOM  XRAY  XRX  YUM  ZBH  ZION  \n",
       "date                                                   \n",
       "2022-07-01     0    0    0    20    5   11    5     3  \n",
       "2022-07-05     0    0    0    20    5   11    5     3  \n",
       "2022-07-06     0    0    0    20    5   11    5     3  \n",
       "2022-07-07     0    0    0    20    5   11    5     3  \n",
       "2022-07-08     0    0    0    20    0   11    0     0  \n",
       "\n",
       "[5 rows x 394 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions_dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fa3b196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>ADI</th>\n",
       "      <th>ADM</th>\n",
       "      <th>ADP</th>\n",
       "      <th>...</th>\n",
       "      <th>WU</th>\n",
       "      <th>WY</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XRX</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZION</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-04-22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            A  AAL  AAP  AAPL  ABT  ACN  ADBE  ADI  ADM  ADP  ...  WU  WY  \\\n",
       "date                                                          ...           \n",
       "2024-04-22  0    0    0     0    0    0     0    0    0    0  ...   0   0   \n",
       "2024-04-23  0    0    0     0    0    0     0    0    0    0  ...   0   0   \n",
       "2024-04-24  0    0    0     0    0    0     0    0    0    0  ...   0   0   \n",
       "2024-04-25  0    0    0     0    0    0     0    0    0    0  ...   0   0   \n",
       "2024-04-26  0    0    0     0    0    0     0    0    0    0  ...   0   0   \n",
       "\n",
       "            WYNN  XEL  XOM  XRAY  XRX  YUM  ZBH  ZION  \n",
       "date                                                   \n",
       "2024-04-22     0    0    0     0    0    0    0     0  \n",
       "2024-04-23     0    0    0     0    0    0    0     0  \n",
       "2024-04-24     0    0    0     0    0    0    0     0  \n",
       "2024-04-25     0    0    0     0    0    0    0     0  \n",
       "2024-04-26     0    0    0     0    0    0    0     0  \n",
       "\n",
       "[5 rows x 394 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions_dt.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bc2b6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_dt.to_pickle('data/df_account_value_dt.pkl')\n",
    "df_actions_dt.to_pickle('data/df_actions_dt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09b76257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\drebi\\miniconda3\\envs\\summerresearch\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trained_PPO = PPO.load('trained_models/agent_ppo.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "205e510a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
    "    model=trained_PPO,\n",
    "    environment=e_trade_gym\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edcb3144",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_ppo.to_pickle('data/df_account_value_ppo.pkl')\n",
    "df_actions_ppo.to_pickle('data/df_actions_ppo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03fe1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summerresearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
