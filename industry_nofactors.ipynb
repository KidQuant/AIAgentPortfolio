{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_portfolio_allocation.env_portfolio import StockPortfolioEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    "    TRADE_START_DATE,\n",
    "    TRADE_END_DATE,\n",
    ")\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import itertools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = '1926-07-01'\n",
    "END_DATE = '2025-04-30'\n",
    "TRAIN_START_DATE = '1980-01-01'\n",
    "TRAIN_END_DATE = '2014-01-05'\n",
    "TRADE_START_DATE = '2014-01-06'\n",
    "TEST_START_DATE = '1990-01-01'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1980-01-01'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1926-07-01</td>\n",
       "      <td>Durbl</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1926-07-01</td>\n",
       "      <td>Enrgy</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1926-07-01</td>\n",
       "      <td>HiTec</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1926-07-01</td>\n",
       "      <td>Hlth</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1926-07-01</td>\n",
       "      <td>Manuf</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    tic  close  open  high   low\n",
       "0 1926-07-01  Durbl  -0.28 -0.28 -0.28 -0.28\n",
       "1 1926-07-01  Enrgy   0.57  0.57  0.57  0.57\n",
       "2 1926-07-01  HiTec  -0.21 -0.21 -0.21 -0.21\n",
       "3 1926-07-01   Hlth   0.97  0.97  0.97  0.97\n",
       "4 1926-07-01  Manuf  -0.23 -0.23 -0.23 -0.23"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/Industry_daily.csv')\n",
    "df.head()\n",
    "# Convert the Date column to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%Y%m%d')\n",
    "\n",
    "# Create price_long dataframe with proper date formatting\n",
    "price_long = pd.melt(df, id_vars=['Date'], value_vars=['NoDur', 'Durbl', 'Manuf', 'Enrgy', 'HiTec', 'Telcm', 'Shops', 'Hlth', 'Utils', 'Other'])\n",
    "price_long = price_long.rename(columns={'Date': 'date', 'variable': 'tic', 'value': 'close'})\n",
    "\n",
    "# Add required columns with same values as close price since we don't have this data\n",
    "price_long['open'] = price_long['close'] \n",
    "price_long['high'] = price_long['close']\n",
    "price_long['low'] = price_long['close']\n",
    "\n",
    "# Sort by date and tic\n",
    "price_long = price_long.sort_values(['date', 'tic']).reset_index(drop=True)\n",
    "price_long.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1926-07-01</td>\n",
       "      <td>Durbl</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.9972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1926-07-01</td>\n",
       "      <td>Enrgy</td>\n",
       "      <td>1.0057</td>\n",
       "      <td>1.0057</td>\n",
       "      <td>1.0057</td>\n",
       "      <td>1.0057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1926-07-01</td>\n",
       "      <td>HiTec</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1926-07-01</td>\n",
       "      <td>Hlth</td>\n",
       "      <td>1.0097</td>\n",
       "      <td>1.0097</td>\n",
       "      <td>1.0097</td>\n",
       "      <td>1.0097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1926-07-01</td>\n",
       "      <td>Manuf</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>0.9977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    tic   close    open    high     low\n",
       "0 1926-07-01  Durbl  0.9972  0.9972  0.9972  0.9972\n",
       "1 1926-07-01  Enrgy  1.0057  1.0057  1.0057  1.0057\n",
       "2 1926-07-01  HiTec  0.9979  0.9979  0.9979  0.9979\n",
       "3 1926-07-01   Hlth  1.0097  1.0097  1.0097  1.0097\n",
       "4 1926-07-01  Manuf  0.9977  0.9977  0.9977  0.9977"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def returns_to_prices_vectorized(returns_df, initial_price=100):\n",
    "    returns_df = returns_df.copy()\n",
    "    returns_df['close'] = returns_df['close'] / 100 +1\n",
    "\n",
    "    returns_df['close'] = returns_df.groupby('tic')['close'].cumprod()\n",
    "\n",
    "    returns_df['open'] = returns_df['close']\n",
    "    returns_df['high'] = returns_df['close']\n",
    "    returns_df['low'] = returns_df['close']\n",
    "\n",
    "    return returns_df\n",
    "\n",
    "price_long = returns_to_prices_vectorized(price_long, initial_price=100)\n",
    "price_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(259820, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "    use_technical_indicator=True,\n",
    "    tech_indicator_list=INDICATORS,\n",
    "    use_turbulence=False,\n",
    "    user_defined_feature=False\n",
    ")\n",
    "\n",
    "processed = fe.preprocess_data(price_long)\n",
    "processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1926-07-01</td>\n",
       "      <td>Durbl</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.017625</td>\n",
       "      <td>0.987445</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.9972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1926-07-01</td>\n",
       "      <td>Enrgy</td>\n",
       "      <td>1.0057</td>\n",
       "      <td>1.0057</td>\n",
       "      <td>1.0057</td>\n",
       "      <td>1.0057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.017625</td>\n",
       "      <td>0.987445</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0057</td>\n",
       "      <td>1.0057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1926-07-01</td>\n",
       "      <td>HiTec</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.017625</td>\n",
       "      <td>0.987445</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1926-07-01</td>\n",
       "      <td>Hlth</td>\n",
       "      <td>1.0097</td>\n",
       "      <td>1.0097</td>\n",
       "      <td>1.0097</td>\n",
       "      <td>1.0097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.017625</td>\n",
       "      <td>0.987445</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0097</td>\n",
       "      <td>1.0097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1926-07-01</td>\n",
       "      <td>Manuf</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.017625</td>\n",
       "      <td>0.987445</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>0.9977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    tic   close    open    high     low  macd   boll_ub   boll_lb  \\\n",
       "0 1926-07-01  Durbl  0.9972  0.9972  0.9972  0.9972   0.0  1.017625  0.987445   \n",
       "1 1926-07-01  Enrgy  1.0057  1.0057  1.0057  1.0057   0.0  1.017625  0.987445   \n",
       "2 1926-07-01  HiTec  0.9979  0.9979  0.9979  0.9979   0.0  1.017625  0.987445   \n",
       "3 1926-07-01   Hlth  1.0097  1.0097  1.0097  1.0097   0.0  1.017625  0.987445   \n",
       "4 1926-07-01  Manuf  0.9977  0.9977  0.9977  0.9977   0.0  1.017625  0.987445   \n",
       "\n",
       "   rsi_30     cci_30  dx_30  close_30_sma  close_60_sma  \n",
       "0   100.0  66.666667  100.0        0.9972        0.9972  \n",
       "1   100.0  66.666667  100.0        1.0057        1.0057  \n",
       "2   100.0  66.666667  100.0        0.9979        0.9979  \n",
       "3   100.0  66.666667  100.0        1.0097        1.0097  \n",
       "4   100.0  66.666667  100.0        0.9977        0.9977  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combination = pd.DataFrame(combination, columns=['date', 'tic'])\n",
    "# Convert date column in combination to datetime to match processed dataframe\n",
    "combination['date'] = pd.to_datetime(combination['date'])\n",
    "processed_full = combination.merge(processed, on=['date', 'tic'], how='left')\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date', 'tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)\n",
    "processed_full.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>return_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1928-02-06</td>\n",
       "      <td>Durbl</td>\n",
       "      <td>2.008443</td>\n",
       "      <td>2.008443</td>\n",
       "      <td>2.008443</td>\n",
       "      <td>2.008443</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>2.028020</td>\n",
       "      <td>1.948959</td>\n",
       "      <td>53.864537</td>\n",
       "      <td>29.674070</td>\n",
       "      <td>6.963338</td>\n",
       "      <td>1.997875</td>\n",
       "      <td>1.976695</td>\n",
       "      <td>[[0.00023139518038852933, 4.7798223866789966e-...</td>\n",
       "      <td>tic          Durbl   Enrgy   HiTec    Hlth   M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1928-02-06</td>\n",
       "      <td>Enrgy</td>\n",
       "      <td>0.980183</td>\n",
       "      <td>0.980183</td>\n",
       "      <td>0.980183</td>\n",
       "      <td>0.980183</td>\n",
       "      <td>-0.009040</td>\n",
       "      <td>1.031943</td>\n",
       "      <td>0.974752</td>\n",
       "      <td>36.716143</td>\n",
       "      <td>-157.928381</td>\n",
       "      <td>50.326020</td>\n",
       "      <td>1.009746</td>\n",
       "      <td>1.010272</td>\n",
       "      <td>[[0.00023139518038852933, 4.7798223866789966e-...</td>\n",
       "      <td>tic          Durbl   Enrgy   HiTec    Hlth   M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1928-02-06</td>\n",
       "      <td>HiTec</td>\n",
       "      <td>1.613793</td>\n",
       "      <td>1.613793</td>\n",
       "      <td>1.613793</td>\n",
       "      <td>1.613793</td>\n",
       "      <td>0.004329</td>\n",
       "      <td>1.637618</td>\n",
       "      <td>1.576751</td>\n",
       "      <td>54.237195</td>\n",
       "      <td>34.889200</td>\n",
       "      <td>6.101492</td>\n",
       "      <td>1.607898</td>\n",
       "      <td>1.593451</td>\n",
       "      <td>[[0.00023139518038852933, 4.7798223866789966e-...</td>\n",
       "      <td>tic          Durbl   Enrgy   HiTec    Hlth   M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1928-02-06</td>\n",
       "      <td>Hlth</td>\n",
       "      <td>1.669301</td>\n",
       "      <td>1.669301</td>\n",
       "      <td>1.669301</td>\n",
       "      <td>1.669301</td>\n",
       "      <td>0.006687</td>\n",
       "      <td>1.708407</td>\n",
       "      <td>1.640190</td>\n",
       "      <td>54.629899</td>\n",
       "      <td>16.566485</td>\n",
       "      <td>3.053309</td>\n",
       "      <td>1.665174</td>\n",
       "      <td>1.648649</td>\n",
       "      <td>[[0.00023139518038852933, 4.7798223866789966e-...</td>\n",
       "      <td>tic          Durbl   Enrgy   HiTec    Hlth   M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1928-02-06</td>\n",
       "      <td>Manuf</td>\n",
       "      <td>1.597110</td>\n",
       "      <td>1.597110</td>\n",
       "      <td>1.597110</td>\n",
       "      <td>1.597110</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>1.622752</td>\n",
       "      <td>1.559963</td>\n",
       "      <td>53.837268</td>\n",
       "      <td>20.572064</td>\n",
       "      <td>3.933540</td>\n",
       "      <td>1.593258</td>\n",
       "      <td>1.582827</td>\n",
       "      <td>[[0.00023139518038852933, 4.7798223866789966e-...</td>\n",
       "      <td>tic          Durbl   Enrgy   HiTec    Hlth   M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    tic     close      open      high       low      macd  \\\n",
       "0 1928-02-06  Durbl  2.008443  2.008443  2.008443  2.008443  0.002385   \n",
       "1 1928-02-06  Enrgy  0.980183  0.980183  0.980183  0.980183 -0.009040   \n",
       "2 1928-02-06  HiTec  1.613793  1.613793  1.613793  1.613793  0.004329   \n",
       "3 1928-02-06   Hlth  1.669301  1.669301  1.669301  1.669301  0.006687   \n",
       "4 1928-02-06  Manuf  1.597110  1.597110  1.597110  1.597110  0.002618   \n",
       "\n",
       "    boll_ub   boll_lb     rsi_30      cci_30      dx_30  close_30_sma  \\\n",
       "0  2.028020  1.948959  53.864537   29.674070   6.963338      1.997875   \n",
       "1  1.031943  0.974752  36.716143 -157.928381  50.326020      1.009746   \n",
       "2  1.637618  1.576751  54.237195   34.889200   6.101492      1.607898   \n",
       "3  1.708407  1.640190  54.629899   16.566485   3.053309      1.665174   \n",
       "4  1.622752  1.559963  53.837268   20.572064   3.933540      1.593258   \n",
       "\n",
       "   close_60_sma                                           cov_list  \\\n",
       "0      1.976695  [[0.00023139518038852933, 4.7798223866789966e-...   \n",
       "1      1.010272  [[0.00023139518038852933, 4.7798223866789966e-...   \n",
       "2      1.593451  [[0.00023139518038852933, 4.7798223866789966e-...   \n",
       "3      1.648649  [[0.00023139518038852933, 4.7798223866789966e-...   \n",
       "4      1.582827  [[0.00023139518038852933, 4.7798223866789966e-...   \n",
       "\n",
       "                                         return_list  \n",
       "0  tic          Durbl   Enrgy   HiTec    Hlth   M...  \n",
       "1  tic          Durbl   Enrgy   HiTec    Hlth   M...  \n",
       "2  tic          Durbl   Enrgy   HiTec    Hlth   M...  \n",
       "3  tic          Durbl   Enrgy   HiTec    Hlth   M...  \n",
       "4  tic          Durbl   Enrgy   HiTec    Hlth   M...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full = processed_full.sort_values(['date','tic'], ignore_index=True)\n",
    "processed_full.index = processed_full.date.factorize()[0]\n",
    "\n",
    "cov_list = []\n",
    "return_list = []\n",
    "\n",
    "lookback = 480\n",
    "for i in range(lookback, len(processed_full.index.unique())):\n",
    "    data_lookback = processed_full.iloc[i-lookback:i]\n",
    "    price_lookback = data_lookback.pivot_table(index='date', columns='tic', values='close')\n",
    "    return_lookback = price_lookback.pct_change().dropna()\n",
    "    return_list.append(return_lookback)\n",
    "\n",
    "    cov = return_lookback.cov().values\n",
    "    cov_list.append(cov)\n",
    "\n",
    "df_cov = pd.DataFrame({'date': processed_full.date.unique()[lookback:], 'cov_list':cov_list, 'return_list':return_list})\n",
    "processed_full = processed_full.merge(df_cov, on='date')\n",
    "processed_full = processed_full.sort_values(['date', 'tic']).reset_index(drop=True)\n",
    "\n",
    "processed_full.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_split(processed_full, start=TRAIN_START_DATE, end=TRAIN_END_DATE)\n",
    "trade = data_split(processed_full, start=TRADE_START_DATE, end=TRADE_END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 10, State Space: 10\n"
     ]
    }
   ],
   "source": [
    "# stock_dimension = len(train.tic.unique())\n",
    "# state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "# print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
    "\n",
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = stock_dimension\n",
    "print(f'Stock Dimension: {stock_dimension}, State Space: {state_space}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    'hmax': 100,\n",
    "    'initial_amount': 1000000,\n",
    "    'transaction_cost_pct': 0.005,\n",
    "    'state_space': state_space,\n",
    "    'stock_dim': stock_dimension,\n",
    "    'tech_indicator_list': INDICATORS,\n",
    "    'action_space': stock_dimension,\n",
    "    'reward_scaling': 1e-4\n",
    "}\n",
    "\n",
    "e_train_gym = StockPortfolioEnv(df=train, **env_kwargs)\n",
    "e_trade_gym = StockPortfolioEnv(df=trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_train = {\n",
    "    \"PPO\": {\n",
    "        'total_timesteps': 50000,\n",
    "        'policy': 'MlpPolicy',\n",
    "        'model_kwargs': {\n",
    "            'learning_rate': 0.0003,\n",
    "            'n_steps': 2048,\n",
    "            'batch_size': 64,\n",
    "            'n_epochs': 10,\n",
    "            'gamma': 0.99,\n",
    "            'gae_lambda': 0.95,\n",
    "            'clip_range': 0.2,\n",
    "            'ent_coef': 0.0,\n",
    "            'vf_coef': 0.5,\n",
    "            'max_grad_norm': 0.5,\n",
    "            # tensorboard_log removed - FinRL handles this separately\n",
    "        },\n",
    "    },\n",
    "    'A2C': {\n",
    "        'total_timesteps': 50000,\n",
    "        'policy': 'MlpPolicy',\n",
    "        'model_kwargs': {\n",
    "            'learning_rate': 0.0007,\n",
    "            'n_steps': 5,\n",
    "            'gamma': 0.99,\n",
    "            'gae_lambda': 1.0,\n",
    "            'ent_coef': 0.01,\n",
    "            'vf_coef': 0.25,\n",
    "            'max_grad_norm': 0.5,\n",
    "            # tensorboard_log removed - FinRL handles this separately\n",
    "        },\n",
    "    },\n",
    "    'DDPG': {\n",
    "        'total_timesteps': 50000,\n",
    "        'policy': 'MlpPolicy',\n",
    "        'model_kwargs': {\n",
    "            'learning_rate': 0.001,\n",
    "            'buffer_size': 1000000,\n",
    "            'learning_starts': 100,\n",
    "            'batch_size': 100,\n",
    "            'tau': 0.005,\n",
    "            'gamma': 0.99,\n",
    "            # tensorboard_log removed - FinRL handles this separately\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training PPO model...\n",
      "==================================================\n",
      "{'learning_rate': 0.0003, 'n_steps': 2048, 'batch_size': 64, 'n_epochs': 10, 'gamma': 0.99, 'gae_lambda': 0.95, 'clip_range': 0.2, 'ent_coef': 0.0, 'vf_coef': 0.5, 'max_grad_norm': 0.5}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 377       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 5         |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 3510932.0 |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 340          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.720679e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -14.2        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.83e+14     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -1.6e-06     |\n",
      "|    reward               | 11007375.0   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.54e+15     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 332           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.1909516e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -14.2         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.23e+15      |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -1.89e-07     |\n",
      "|    reward               | 22661668.0    |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 1.25e+16      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 329            |\n",
      "|    iterations           | 4              |\n",
      "|    time_elapsed         | 24             |\n",
      "|    total_timesteps      | 8192           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -3.0559022e-09 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -14.2          |\n",
      "|    explained_variance   | 2.98e-07       |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 5.28e+16       |\n",
      "|    n_updates            | 30             |\n",
      "|    policy_gradient_loss | -1.25e-07      |\n",
      "|    reward               | 39253276.0     |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 1.03e+17       |\n",
      "--------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:55238477.65089727\n",
      "Sharpe:  0.794548673027735\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.58e+03       |\n",
      "|    ep_rew_mean          | 1.34e+11       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 324            |\n",
      "|    iterations           | 5              |\n",
      "|    time_elapsed         | 31             |\n",
      "|    total_timesteps      | 10240          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.5133992e-09 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -14.2          |\n",
      "|    explained_variance   | -2.38e-07      |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 1.25e+17       |\n",
      "|    n_updates            | 40             |\n",
      "|    policy_gradient_loss | -1.19e-07      |\n",
      "|    reward               | 3421281.2      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 2.47e+17       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.58e+03       |\n",
      "|    ep_rew_mean          | 1.34e+11       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 323            |\n",
      "|    iterations           | 6              |\n",
      "|    time_elapsed         | 37             |\n",
      "|    total_timesteps      | 12288          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.0372681e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -14.2          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 5.69e+16       |\n",
      "|    n_updates            | 50             |\n",
      "|    policy_gradient_loss | -1.53e-07      |\n",
      "|    reward               | 8659930.0      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 1.11e+17       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.58e+03     |\n",
      "|    ep_rew_mean          | 1.34e+11     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 322          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.608875e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -14.2        |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.84e+15     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -2.09e-07    |\n",
      "|    reward               | 20126022.0   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.05e+16     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.58e+03      |\n",
      "|    ep_rew_mean          | 1.34e+11      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 321           |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 50            |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6589183e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -14.2         |\n",
      "|    explained_variance   | -2.38e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.62e+16      |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -2.25e-07     |\n",
      "|    reward               | 45079460.0    |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 1.11e+17      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:69921630.80001836\n",
      "Sharpe:  0.8361693805634219\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.58e+03      |\n",
      "|    ep_rew_mean          | 1.48e+11      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 320           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 57            |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -6.024493e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -14.2         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.53e+17      |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -6.94e-08     |\n",
      "|    reward               | 2306225.0     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 3.05e+17      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.58e+03       |\n",
      "|    ep_rew_mean          | 1.48e+11       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 320            |\n",
      "|    iterations           | 10             |\n",
      "|    time_elapsed         | 63             |\n",
      "|    total_timesteps      | 20480          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -2.7066562e-09 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -14.2          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 1.48e+17       |\n",
      "|    n_updates            | 90             |\n",
      "|    policy_gradient_loss | -1.3e-07       |\n",
      "|    reward               | 7958585.0      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 2.98e+17       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.58e+03     |\n",
      "|    ep_rew_mean          | 1.48e+11     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 318          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.802132e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -14.2        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.74e+15     |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -2.33e-07    |\n",
      "|    reward               | 25207258.0   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 6.98e+15     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.58e+03      |\n",
      "|    ep_rew_mean          | 1.48e+11      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 316           |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 77            |\n",
      "|    total_timesteps      | 24576         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -8.731149e-11 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -14.2         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.47e+16      |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | -1.85e-07     |\n",
      "|    reward               | 28876358.0    |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 9.84e+16      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:71798165.36617033\n",
      "Sharpe:  0.8407959063979327\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.58e+03       |\n",
      "|    ep_rew_mean          | 1.54e+11       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 315            |\n",
      "|    iterations           | 13             |\n",
      "|    time_elapsed         | 84             |\n",
      "|    total_timesteps      | 26624          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -6.1118044e-09 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -14.2          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 1.36e+17       |\n",
      "|    n_updates            | 120            |\n",
      "|    policy_gradient_loss | -8.75e-08      |\n",
      "|    reward               | 2088738.6      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 2.84e+17       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.58e+03       |\n",
      "|    ep_rew_mean          | 1.54e+11       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 314            |\n",
      "|    iterations           | 14             |\n",
      "|    time_elapsed         | 91             |\n",
      "|    total_timesteps      | 28672          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -6.5774657e-09 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -14.2          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 2.1e+17        |\n",
      "|    n_updates            | 130            |\n",
      "|    policy_gradient_loss | -7.88e-08      |\n",
      "|    reward               | 6369931.0      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 3.8e+17        |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.58e+03     |\n",
      "|    ep_rew_mean          | 1.54e+11     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 314          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.712515e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -14.2        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.35e+15     |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -5.59e-07    |\n",
      "|    reward               | 25919736.0   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 4.55e+15     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.58e+03      |\n",
      "|    ep_rew_mean          | 1.54e+11      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 314           |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 104           |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9499566e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -14.2         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.56e+16      |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -1.3e-07      |\n",
      "|    reward               | 42042744.0    |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 6.04e+16      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:69995874.0748568\n",
      "Sharpe:  0.8369822946638811\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.58e+03       |\n",
      "|    ep_rew_mean          | 1.57e+11       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 314            |\n",
      "|    iterations           | 17             |\n",
      "|    time_elapsed         | 110            |\n",
      "|    total_timesteps      | 34816          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -3.5215635e-09 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -14.2          |\n",
      "|    explained_variance   | 1.19e-07       |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 1.28e+17       |\n",
      "|    n_updates            | 160            |\n",
      "|    policy_gradient_loss | -1.16e-07      |\n",
      "|    reward               | 1321074.1      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 2.53e+17       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.58e+03       |\n",
      "|    ep_rew_mean          | 1.57e+11       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 314            |\n",
      "|    iterations           | 18             |\n",
      "|    time_elapsed         | 117            |\n",
      "|    total_timesteps      | 36864          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -7.1013346e-09 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -14.2          |\n",
      "|    explained_variance   | 5.96e-08       |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 1.97e+17       |\n",
      "|    n_updates            | 170            |\n",
      "|    policy_gradient_loss | -8.93e-08      |\n",
      "|    reward               | 5039309.0      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 4.22e+17       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.58e+03     |\n",
      "|    ep_rew_mean          | 1.57e+11     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 313          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 123          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.818461e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -14.2        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.65e+15     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -9.21e-07    |\n",
      "|    reward               | 18995892.0   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 3.13e+15     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.58e+03      |\n",
      "|    ep_rew_mean          | 1.57e+11      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 314           |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 130           |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.5588316e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -14.2         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.31e+16      |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -3.68e-07     |\n",
      "|    reward               | 31218294.0    |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 2.76e+16      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:58750228.53352584\n",
      "Sharpe:  0.8066015166161595\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.58e+03       |\n",
      "|    ep_rew_mean          | 1.55e+11       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 314            |\n",
      "|    iterations           | 21             |\n",
      "|    time_elapsed         | 136            |\n",
      "|    total_timesteps      | 43008          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.6007107e-09 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -14.2          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 8.58e+16       |\n",
      "|    n_updates            | 200            |\n",
      "|    policy_gradient_loss | -8.57e-08      |\n",
      "|    reward               | 1083024.4      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 1.63e+17       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.58e+03       |\n",
      "|    ep_rew_mean          | 1.55e+11       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 314            |\n",
      "|    iterations           | 22             |\n",
      "|    time_elapsed         | 143            |\n",
      "|    total_timesteps      | 45056          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -4.7439244e-09 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -14.2          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 1.95e+17       |\n",
      "|    n_updates            | 210            |\n",
      "|    policy_gradient_loss | -1.19e-07      |\n",
      "|    reward               | 4208735.5      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 3.69e+17       |\n",
      "--------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.58e+03    |\n",
      "|    ep_rew_mean          | 1.55e+11    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 8.58563e-09 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -14.2       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.83e+14    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -1.06e-06   |\n",
      "|    reward               | 12890901.0  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.05e+15    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.58e+03      |\n",
      "|    ep_rew_mean          | 1.55e+11      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 314           |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 156           |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7252903e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -14.2         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 8.8e+15       |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -1.63e-07     |\n",
      "|    reward               | 27110352.0    |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 1.74e+16      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 8.58e+03       |\n",
      "|    ep_rew_mean          | 1.55e+11       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 314            |\n",
      "|    iterations           | 25             |\n",
      "|    time_elapsed         | 162            |\n",
      "|    total_timesteps      | 51200          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -3.6670826e-09 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -14.2          |\n",
      "|    explained_variance   | 5.96e-08       |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 7.34e+16       |\n",
      "|    n_updates            | 240            |\n",
      "|    policy_gradient_loss | -1.17e-07      |\n",
      "|    reward               | 48811884.0     |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 1.44e+17       |\n",
      "--------------------------------------------\n",
      "PPO training completed and saved!\n",
      "\n",
      "==================================================\n",
      "Training A2C model...\n",
      "==================================================\n",
      "{'learning_rate': 0.0007, 'n_steps': 5, 'gamma': 0.99, 'gae_lambda': 1.0, 'ent_coef': 0.01, 'vf_coef': 0.25, 'max_grad_norm': 0.5}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | 5.26e+07  |\n",
      "|    reward             | 1342434.5 |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 1.93e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 8.32e+07  |\n",
      "|    reward             | 2141182.8 |\n",
      "|    std                | 0.993     |\n",
      "|    value_loss         | 5.05e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | 1.11e+08  |\n",
      "|    reward             | 2817789.8 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 8.32e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 1.49e+08  |\n",
      "|    reward             | 3349522.8 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 1.32e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 279       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 2.08e+08  |\n",
      "|    reward             | 5095158.5 |\n",
      "|    std                | 0.981     |\n",
      "|    value_loss         | 2.75e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 2.59e+08  |\n",
      "|    reward             | 6192730.5 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 3.94e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14       |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 3.32e+08  |\n",
      "|    reward             | 8249299.5 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 7.23e+14  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 278        |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | 4.31e+08   |\n",
      "|    reward             | 10460360.0 |\n",
      "|    std                | 0.974      |\n",
      "|    value_loss         | 1.21e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 279        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | 8.21e+08   |\n",
      "|    reward             | 17034360.0 |\n",
      "|    std                | 0.972      |\n",
      "|    value_loss         | 3.26e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 279        |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.9      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | 9.13e+08   |\n",
      "|    reward             | 22061010.0 |\n",
      "|    std                | 0.967      |\n",
      "|    value_loss         | 5.33e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 280        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | 7.54e+08   |\n",
      "|    reward             | 22070656.0 |\n",
      "|    std                | 0.96       |\n",
      "|    value_loss         | 4.71e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 281        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 21         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 9.05e+08   |\n",
      "|    reward             | 23384878.0 |\n",
      "|    std                | 0.959      |\n",
      "|    value_loss         | 5.38e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 282        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 23         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | 1.09e+09   |\n",
      "|    reward             | 29356386.0 |\n",
      "|    std                | 0.955      |\n",
      "|    value_loss         | 8.92e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 282        |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 24         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.7      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | 1.52e+09   |\n",
      "|    reward             | 38617244.0 |\n",
      "|    std                | 0.95       |\n",
      "|    value_loss         | 1.55e+16   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 283        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 26         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.6      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | 1.2e+09    |\n",
      "|    reward             | 30517268.0 |\n",
      "|    std                | 0.945      |\n",
      "|    value_loss         | 9.53e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 284        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.6      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 1.38e+09   |\n",
      "|    reward             | 38334536.0 |\n",
      "|    std                | 0.944      |\n",
      "|    value_loss         | 1.5e+16    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.6      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | 1.97e+09   |\n",
      "|    reward             | 56501144.0 |\n",
      "|    std                | 0.943      |\n",
      "|    value_loss         | 3.25e+16   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:61173316.4153563\n",
      "Sharpe:  0.8034142050122106\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.48e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 284       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 4.55e+07  |\n",
      "|    reward             | 1262403.2 |\n",
      "|    std                | 0.94      |\n",
      "|    value_loss         | 1.8e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.48e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 283       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 33        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 7.42e+07  |\n",
      "|    reward             | 2025320.0 |\n",
      "|    std                | 0.938     |\n",
      "|    value_loss         | 4.42e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.48e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 284       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.5     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 9.59e+07  |\n",
      "|    reward             | 2509514.0 |\n",
      "|    std                | 0.934     |\n",
      "|    value_loss         | 6.87e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.48e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 284       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 1.59e+08  |\n",
      "|    reward             | 4593842.5 |\n",
      "|    std                | 0.929     |\n",
      "|    value_loss         | 2.13e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.48e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 284       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | 2.06e+08  |\n",
      "|    reward             | 5006222.0 |\n",
      "|    std                | 0.929     |\n",
      "|    value_loss         | 2.52e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.48e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 285       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 2.61e+08  |\n",
      "|    reward             | 5666945.5 |\n",
      "|    std                | 0.924     |\n",
      "|    value_loss         | 3.46e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.48e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 285       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 42        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 3.08e+08  |\n",
      "|    reward             | 7541977.5 |\n",
      "|    std                | 0.922     |\n",
      "|    value_loss         | 5.88e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.48e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 285       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | 3.5e+08   |\n",
      "|    reward             | 9534519.0 |\n",
      "|    std                | 0.919     |\n",
      "|    value_loss         | 9.33e+14  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.48e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 2600       |\n",
      "|    time_elapsed       | 45         |\n",
      "|    total_timesteps    | 13000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.3      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2599       |\n",
      "|    policy_loss        | 5.55e+08   |\n",
      "|    reward             | 14476098.0 |\n",
      "|    std                | 0.918      |\n",
      "|    value_loss         | 2.28e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.48e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 286        |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 47         |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.3      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | 7.61e+08   |\n",
      "|    reward             | 22439590.0 |\n",
      "|    std                | 0.912      |\n",
      "|    value_loss         | 5.16e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.48e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 286        |\n",
      "|    iterations         | 2800       |\n",
      "|    time_elapsed       | 48         |\n",
      "|    total_timesteps    | 14000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2799       |\n",
      "|    policy_loss        | 9.15e+08   |\n",
      "|    reward             | 23126840.0 |\n",
      "|    std                | 0.911      |\n",
      "|    value_loss         | 6.12e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.48e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 286        |\n",
      "|    iterations         | 2900       |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 14500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.2      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2899       |\n",
      "|    policy_loss        | 8.14e+08   |\n",
      "|    reward             | 20909368.0 |\n",
      "|    std                | 0.91       |\n",
      "|    value_loss         | 4.44e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.48e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 284        |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | 1.06e+09   |\n",
      "|    reward             | 27161996.0 |\n",
      "|    std                | 0.906      |\n",
      "|    value_loss         | 7.81e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.48e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 284        |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 54         |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.2      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | 1.34e+09   |\n",
      "|    reward             | 37047590.0 |\n",
      "|    std                | 0.903      |\n",
      "|    value_loss         | 1.47e+16   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.48e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 284        |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 56         |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | 8.04e+08   |\n",
      "|    reward             | 23886812.0 |\n",
      "|    std                | 0.898      |\n",
      "|    value_loss         | 5.43e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.48e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 57         |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | 1.58e+09   |\n",
      "|    reward             | 37988308.0 |\n",
      "|    std                | 0.892      |\n",
      "|    value_loss         | 1.59e+16   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.48e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 285        |\n",
      "|    iterations         | 3400       |\n",
      "|    time_elapsed       | 59         |\n",
      "|    total_timesteps    | 17000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3399       |\n",
      "|    policy_loss        | 1.83e+09   |\n",
      "|    reward             | 50005096.0 |\n",
      "|    std                | 0.887      |\n",
      "|    value_loss         | 2.55e+16   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:56330672.367438085\n",
      "Sharpe:  0.7791138464607933\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.43e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 285       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 61        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13       |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 4.95e+07  |\n",
      "|    reward             | 1330577.5 |\n",
      "|    std                | 0.886     |\n",
      "|    value_loss         | 1.96e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.43e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 285       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13       |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | 7.73e+07  |\n",
      "|    reward             | 1963657.6 |\n",
      "|    std                | 0.884     |\n",
      "|    value_loss         | 4.01e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.43e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 285       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 64        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 1.02e+08  |\n",
      "|    reward             | 2364106.5 |\n",
      "|    std                | 0.879     |\n",
      "|    value_loss         | 5.89e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.43e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 285       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 1.37e+08  |\n",
      "|    reward             | 3939488.5 |\n",
      "|    std                | 0.877     |\n",
      "|    value_loss         | 1.82e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.43e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 285       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 1.56e+08  |\n",
      "|    reward             | 4363144.0 |\n",
      "|    std                | 0.873     |\n",
      "|    value_loss         | 1.98e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.43e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 286       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 1.92e+08  |\n",
      "|    reward             | 5484365.0 |\n",
      "|    std                | 0.866     |\n",
      "|    value_loss         | 3.13e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.43e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 286       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 71        |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 2.93e+08  |\n",
      "|    reward             | 7383556.0 |\n",
      "|    std                | 0.863     |\n",
      "|    value_loss         | 5.9e+14   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.43e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 286       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | 3.08e+08  |\n",
      "|    reward             | 8354547.5 |\n",
      "|    std                | 0.86      |\n",
      "|    value_loss         | 7.19e+14  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.43e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 286        |\n",
      "|    iterations         | 4300       |\n",
      "|    time_elapsed       | 75         |\n",
      "|    total_timesteps    | 21500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4299       |\n",
      "|    policy_loss        | 4.86e+08   |\n",
      "|    reward             | 13262886.0 |\n",
      "|    std                | 0.856      |\n",
      "|    value_loss         | 1.91e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.43e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 286        |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 76         |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | 6.88e+08   |\n",
      "|    reward             | 19783644.0 |\n",
      "|    std                | 0.853      |\n",
      "|    value_loss         | 4.24e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.43e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 286        |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 78         |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | 8.08e+08   |\n",
      "|    reward             | 22444718.0 |\n",
      "|    std                | 0.852      |\n",
      "|    value_loss         | 5.71e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.43e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 287        |\n",
      "|    iterations         | 4600       |\n",
      "|    time_elapsed       | 80         |\n",
      "|    total_timesteps    | 23000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4599       |\n",
      "|    policy_loss        | 6.35e+08   |\n",
      "|    reward             | 17113864.0 |\n",
      "|    std                | 0.85       |\n",
      "|    value_loss         | 3e+15      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.43e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 287        |\n",
      "|    iterations         | 4700       |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 23500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4699       |\n",
      "|    policy_loss        | 9.7e+08    |\n",
      "|    reward             | 27058836.0 |\n",
      "|    std                | 0.842      |\n",
      "|    value_loss         | 7.71e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.43e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 287        |\n",
      "|    iterations         | 4800       |\n",
      "|    time_elapsed       | 83         |\n",
      "|    total_timesteps    | 24000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4799       |\n",
      "|    policy_loss        | 1.31e+09   |\n",
      "|    reward             | 33794890.0 |\n",
      "|    std                | 0.839      |\n",
      "|    value_loss         | 1.22e+16   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.43e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 287        |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 85         |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | 6.69e+08   |\n",
      "|    reward             | 19977594.0 |\n",
      "|    std                | 0.837      |\n",
      "|    value_loss         | 4.33e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.43e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 287        |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 86         |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | 1.44e+09   |\n",
      "|    reward             | 36689732.0 |\n",
      "|    std                | 0.835      |\n",
      "|    value_loss         | 1.44e+16   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.43e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 287        |\n",
      "|    iterations         | 5100       |\n",
      "|    time_elapsed       | 88         |\n",
      "|    total_timesteps    | 25500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5099       |\n",
      "|    policy_loss        | 1.58e+09   |\n",
      "|    reward             | 44201216.0 |\n",
      "|    std                | 0.83       |\n",
      "|    value_loss         | 2.01e+16   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:56043914.90479581\n",
      "Sharpe:  0.7794458062348045\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.41e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 90        |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | 4.27e+07  |\n",
      "|    reward             | 1278666.2 |\n",
      "|    std                | 0.824     |\n",
      "|    value_loss         | 1.77e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.41e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 92        |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | 6.67e+07  |\n",
      "|    reward             | 1714166.1 |\n",
      "|    std                | 0.823     |\n",
      "|    value_loss         | 2.96e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.41e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 8.01e+07  |\n",
      "|    reward             | 2124798.2 |\n",
      "|    std                | 0.821     |\n",
      "|    value_loss         | 4.76e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.41e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | 1.13e+08  |\n",
      "|    reward             | 3281977.2 |\n",
      "|    std                | 0.82      |\n",
      "|    value_loss         | 1.16e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.41e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 97        |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | 1.34e+08  |\n",
      "|    reward             | 3860623.5 |\n",
      "|    std                | 0.814     |\n",
      "|    value_loss         | 1.57e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.41e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 99        |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | 1.41e+08  |\n",
      "|    reward             | 4387743.0 |\n",
      "|    std                | 0.809     |\n",
      "|    value_loss         | 1.89e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.41e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 100       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | 2.29e+08  |\n",
      "|    reward             | 6380881.5 |\n",
      "|    std                | 0.807     |\n",
      "|    value_loss         | 4.15e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.41e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 287       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 102       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 3.07e+08  |\n",
      "|    reward             | 7639815.0 |\n",
      "|    std                | 0.805     |\n",
      "|    value_loss         | 6.24e+14  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.41e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 288        |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 104        |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5999       |\n",
      "|    policy_loss        | 4.2e+08    |\n",
      "|    reward             | 11990829.0 |\n",
      "|    std                | 0.802      |\n",
      "|    value_loss         | 1.43e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.41e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 288        |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 105        |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | 5.36e+08   |\n",
      "|    reward             | 17823802.0 |\n",
      "|    std                | 0.798      |\n",
      "|    value_loss         | 3.11e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.41e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 288        |\n",
      "|    iterations         | 6200       |\n",
      "|    time_elapsed       | 107        |\n",
      "|    total_timesteps    | 31000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.9      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6199       |\n",
      "|    policy_loss        | 7.87e+08   |\n",
      "|    reward             | 22815554.0 |\n",
      "|    std                | 0.796      |\n",
      "|    value_loss         | 5.52e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.41e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 288        |\n",
      "|    iterations         | 6300       |\n",
      "|    time_elapsed       | 109        |\n",
      "|    total_timesteps    | 31500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6299       |\n",
      "|    policy_loss        | 5.37e+08   |\n",
      "|    reward             | 16951882.0 |\n",
      "|    std                | 0.793      |\n",
      "|    value_loss         | 3.01e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.41e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 288        |\n",
      "|    iterations         | 6400       |\n",
      "|    time_elapsed       | 110        |\n",
      "|    total_timesteps    | 32000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.8      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6399       |\n",
      "|    policy_loss        | 8.34e+08   |\n",
      "|    reward             | 23356330.0 |\n",
      "|    std                | 0.789      |\n",
      "|    value_loss         | 5.94e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.41e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 288        |\n",
      "|    iterations         | 6500       |\n",
      "|    time_elapsed       | 112        |\n",
      "|    total_timesteps    | 32500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.7      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6499       |\n",
      "|    policy_loss        | 9.49e+08   |\n",
      "|    reward             | 29974636.0 |\n",
      "|    std                | 0.786      |\n",
      "|    value_loss         | 9.29e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.41e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 288        |\n",
      "|    iterations         | 6600       |\n",
      "|    time_elapsed       | 114        |\n",
      "|    total_timesteps    | 33000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6599       |\n",
      "|    policy_loss        | 8.04e+08   |\n",
      "|    reward             | 23153190.0 |\n",
      "|    std                | 0.781      |\n",
      "|    value_loss         | 7.04e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.41e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 288        |\n",
      "|    iterations         | 6700       |\n",
      "|    time_elapsed       | 116        |\n",
      "|    total_timesteps    | 33500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6699       |\n",
      "|    policy_loss        | 1.15e+09   |\n",
      "|    reward             | 32130216.0 |\n",
      "|    std                | 0.781      |\n",
      "|    value_loss         | 1.07e+16   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.41e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 288        |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 117        |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.6      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | 1.39e+09   |\n",
      "|    reward             | 40212370.0 |\n",
      "|    std                | 0.777      |\n",
      "|    value_loss         | 1.78e+16   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:55008474.880165\n",
      "Sharpe:  0.7633680730276312\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.39e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 119       |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | 4.66e+07  |\n",
      "|    reward             | 1268622.5 |\n",
      "|    std                | 0.775     |\n",
      "|    value_loss         | 1.63e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.39e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 121       |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.6     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | 4.66e+07  |\n",
      "|    reward             | 1421216.0 |\n",
      "|    std                | 0.775     |\n",
      "|    value_loss         | 2.08e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.39e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 123       |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 6.83e+07  |\n",
      "|    reward             | 2122671.8 |\n",
      "|    std                | 0.77      |\n",
      "|    value_loss         | 4.87e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.39e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 124       |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | 1.18e+08  |\n",
      "|    reward             | 3387700.5 |\n",
      "|    std                | 0.77      |\n",
      "|    value_loss         | 1.19e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.39e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 126       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.5     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | 1.31e+08  |\n",
      "|    reward             | 3641281.2 |\n",
      "|    std                | 0.77      |\n",
      "|    value_loss         | 1.48e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.39e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 128       |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | 1.35e+08  |\n",
      "|    reward             | 4601846.0 |\n",
      "|    std                | 0.762     |\n",
      "|    value_loss         | 2.31e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.39e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 2.13e+08  |\n",
      "|    reward             | 6179150.0 |\n",
      "|    std                | 0.761     |\n",
      "|    value_loss         | 3.98e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.39e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 288       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 131       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | 2.23e+08  |\n",
      "|    reward             | 7450503.5 |\n",
      "|    std                | 0.76      |\n",
      "|    value_loss         | 5.95e+14  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.39e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 288        |\n",
      "|    iterations         | 7700       |\n",
      "|    time_elapsed       | 133        |\n",
      "|    total_timesteps    | 38500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7699       |\n",
      "|    policy_loss        | 4.05e+08   |\n",
      "|    reward             | 10727464.0 |\n",
      "|    std                | 0.757      |\n",
      "|    value_loss         | 1.28e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.39e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 288        |\n",
      "|    iterations         | 7800       |\n",
      "|    time_elapsed       | 135        |\n",
      "|    total_timesteps    | 39000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7799       |\n",
      "|    policy_loss        | 6.63e+08   |\n",
      "|    reward             | 19456492.0 |\n",
      "|    std                | 0.756      |\n",
      "|    value_loss         | 3.94e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.39e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 288        |\n",
      "|    iterations         | 7900       |\n",
      "|    time_elapsed       | 136        |\n",
      "|    total_timesteps    | 39500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7899       |\n",
      "|    policy_loss        | 7.73e+08   |\n",
      "|    reward             | 23873404.0 |\n",
      "|    std                | 0.755      |\n",
      "|    value_loss         | 5.91e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.39e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 288        |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 138        |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.3      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | 6.21e+08   |\n",
      "|    reward             | 19183592.0 |\n",
      "|    std                | 0.752      |\n",
      "|    value_loss         | 4.04e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.39e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 289        |\n",
      "|    iterations         | 8100       |\n",
      "|    time_elapsed       | 140        |\n",
      "|    total_timesteps    | 40500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.3      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8099       |\n",
      "|    policy_loss        | 7.62e+08   |\n",
      "|    reward             | 24059630.0 |\n",
      "|    std                | 0.75       |\n",
      "|    value_loss         | 6.25e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.39e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 289        |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 141        |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | 9.6e+08    |\n",
      "|    reward             | 27496098.0 |\n",
      "|    std                | 0.749      |\n",
      "|    value_loss         | 7.88e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.39e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 289        |\n",
      "|    iterations         | 8300       |\n",
      "|    time_elapsed       | 143        |\n",
      "|    total_timesteps    | 41500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8299       |\n",
      "|    policy_loss        | 1.15e+09   |\n",
      "|    reward             | 31559950.0 |\n",
      "|    std                | 0.749      |\n",
      "|    value_loss         | 1.11e+16   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.39e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 289        |\n",
      "|    iterations         | 8400       |\n",
      "|    time_elapsed       | 145        |\n",
      "|    total_timesteps    | 42000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.2      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8399       |\n",
      "|    policy_loss        | 9.64e+08   |\n",
      "|    reward             | 30686332.0 |\n",
      "|    std                | 0.745      |\n",
      "|    value_loss         | 9.01e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.39e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 289        |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 146        |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8499       |\n",
      "|    policy_loss        | 1.08e+09   |\n",
      "|    reward             | 37859332.0 |\n",
      "|    std                | 0.747      |\n",
      "|    value_loss         | 1.5e+16    |\n",
      "--------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:55712788.74397243\n",
      "Sharpe:  0.7652844706370934\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.38e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 148       |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | 3.35e+07  |\n",
      "|    reward             | 1036225.9 |\n",
      "|    std                | 0.742     |\n",
      "|    value_loss         | 1.1e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.38e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 150       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 4.74e+07  |\n",
      "|    reward             | 1278050.9 |\n",
      "|    std                | 0.742     |\n",
      "|    value_loss         | 1.82e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.38e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 152       |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 5.91e+07  |\n",
      "|    reward             | 1972981.8 |\n",
      "|    std                | 0.74      |\n",
      "|    value_loss         | 4.25e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.38e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 153       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 1.05e+08  |\n",
      "|    reward             | 3239451.5 |\n",
      "|    std                | 0.737     |\n",
      "|    value_loss         | 1.12e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.38e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 155       |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11       |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | 1.41e+08  |\n",
      "|    reward             | 3736672.2 |\n",
      "|    std                | 0.734     |\n",
      "|    value_loss         | 1.44e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.38e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 157       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 1.47e+08  |\n",
      "|    reward             | 4709093.0 |\n",
      "|    std                | 0.734     |\n",
      "|    value_loss         | 2.5e+14   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.38e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 159       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 1.9e+08   |\n",
      "|    reward             | 6023555.0 |\n",
      "|    std                | 0.73      |\n",
      "|    value_loss         | 3.84e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.58e+03  |\n",
      "|    ep_rew_mean        | 1.38e+11  |\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 160       |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11       |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | 2.7e+08   |\n",
      "|    reward             | 7611151.0 |\n",
      "|    std                | 0.727     |\n",
      "|    value_loss         | 6.62e+14  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.38e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 289        |\n",
      "|    iterations         | 9400       |\n",
      "|    time_elapsed       | 162        |\n",
      "|    total_timesteps    | 47000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9399       |\n",
      "|    policy_loss        | 3.26e+08   |\n",
      "|    reward             | 11240801.0 |\n",
      "|    std                | 0.727      |\n",
      "|    value_loss         | 1.34e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.38e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 289        |\n",
      "|    iterations         | 9500       |\n",
      "|    time_elapsed       | 164        |\n",
      "|    total_timesteps    | 47500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.9      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9499       |\n",
      "|    policy_loss        | 4.95e+08   |\n",
      "|    reward             | 18635286.0 |\n",
      "|    std                | 0.725      |\n",
      "|    value_loss         | 3.51e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.38e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 289        |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 165        |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.9      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | 7.24e+08   |\n",
      "|    reward             | 22886732.0 |\n",
      "|    std                | 0.722      |\n",
      "|    value_loss         | 5.88e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.38e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 289        |\n",
      "|    iterations         | 9700       |\n",
      "|    time_elapsed       | 167        |\n",
      "|    total_timesteps    | 48500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9699       |\n",
      "|    policy_loss        | 6.98e+08   |\n",
      "|    reward             | 23030572.0 |\n",
      "|    std                | 0.72       |\n",
      "|    value_loss         | 5.63e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.38e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 289        |\n",
      "|    iterations         | 9800       |\n",
      "|    time_elapsed       | 169        |\n",
      "|    total_timesteps    | 49000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9799       |\n",
      "|    policy_loss        | 6.88e+08   |\n",
      "|    reward             | 24959942.0 |\n",
      "|    std                | 0.719      |\n",
      "|    value_loss         | 6.76e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.38e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 289        |\n",
      "|    iterations         | 9900       |\n",
      "|    time_elapsed       | 170        |\n",
      "|    total_timesteps    | 49500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9899       |\n",
      "|    policy_loss        | 9.26e+08   |\n",
      "|    reward             | 29146970.0 |\n",
      "|    std                | 0.716      |\n",
      "|    value_loss         | 9.07e+15   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 8.58e+03   |\n",
      "|    ep_rew_mean        | 1.38e+11   |\n",
      "| time/                 |            |\n",
      "|    fps                | 289        |\n",
      "|    iterations         | 10000      |\n",
      "|    time_elapsed       | 172        |\n",
      "|    total_timesteps    | 50000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9999       |\n",
      "|    policy_loss        | 9.92e+08   |\n",
      "|    reward             | 33654544.0 |\n",
      "|    std                | 0.713      |\n",
      "|    value_loss         | 1.17e+16   |\n",
      "--------------------------------------\n",
      "A2C training completed and saved!\n",
      "\n",
      "==================================================\n",
      "Training DDPG model...\n",
      "==================================================\n",
      "{'learning_rate': 0.001, 'buffer_size': 1000000, 'learning_starts': 100, 'batch_size': 100, 'tau': 0.005, 'gamma': 0.99}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:68468258.1007796\n",
      "Sharpe:  0.8306643428801809\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:68333389.93164815\n",
      "Sharpe:  0.8306782602062505\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:68333389.93164815\n",
      "Sharpe:  0.8306782602062505\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:68333389.93164815\n",
      "Sharpe:  0.8306782602062505\n",
      "=================================\n",
      "-----------------------------------\n",
      "| rollout/           |            |\n",
      "|    ep_len_mean     | 8.58e+03   |\n",
      "|    ep_rew_mean     | 1.62e+11   |\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 140        |\n",
      "|    time_elapsed    | 243        |\n",
      "|    total_timesteps | 34316      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -1.32e+09  |\n",
      "|    critic_loss     | 2.26e+14   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 34215      |\n",
      "|    reward          | 68333390.0 |\n",
      "-----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:68333389.93164815\n",
      "Sharpe:  0.8306782602062505\n",
      "=================================\n",
      "DDPG training completed and saved!\n",
      "\n",
      "Successfully trained 3 models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train all models\n",
    "trained_models = {}\n",
    "model_results = {}\n",
    "\n",
    "for model_name, config in models_to_train.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {model_name} model...\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    try:\n",
    "        # Create agent\n",
    "        agent = DRLAgent(env=e_train_gym)\n",
    "        \n",
    "        # Get model\n",
    "        model = agent.get_model(\n",
    "            model_name=model_name.lower(),\n",
    "            policy=config['policy'],\n",
    "            model_kwargs=config['model_kwargs']\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        trained_model = agent.train_model(\n",
    "            model=model,\n",
    "            total_timesteps=config['total_timesteps'],\n",
    "            tb_log_name=model_name.lower()\n",
    "        )\n",
    "        \n",
    "        # Save model\n",
    "        model_path = f\"{TRAINED_MODEL_DIR}/{model_name.lower()}_ff_model\"\n",
    "        trained_model.save(model_path)\n",
    "        trained_models[model_name] = trained_model\n",
    "        \n",
    "        print(f\"{model_name} training completed and saved!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error training {model_name}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nSuccessfully trained {len(trained_models)} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_models['PPO'].policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, model_name, env):\n",
    "    \"\"\"\n",
    "    Test a trained model return results.\n",
    "    \"\"\"\n",
    "    print(f'\\nTesting {model_name}...')\n",
    "\n",
    "    obs = env.reset()\n",
    "\n",
    "    for i in range(len(env.get_attr('df')[0].index.unique())-1):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        if dones:\n",
    "            break\n",
    "\n",
    "    # Calculate daily returns from asset_memory\n",
    "    import numpy as np\n",
    "    asset_memory = env.get_attr('asset_memory')[0]\n",
    "    daily_returns = np.diff(asset_memory) / asset_memory[:-1]\n",
    "\n",
    "    results = {\n",
    "        'final_value': asset_memory[-1],\n",
    "        'total_return': (asset_memory[-1] / env.get_attr('initial_amount')[0] - 1) * 100,\n",
    "        'daily_returns': daily_returns,\n",
    "        'asset_memory': asset_memory,\n",
    "        'date_memory': env.get_attr('date_memory')[0],\n",
    "        'actions_memory': env.get_attr('actions_memory')[0]\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing PPO...\n",
      "PPO Results:\n",
      "  Final Portfolio Value: $2,699,085.02\n",
      "  Total Return: 169.91%\n",
      "  Sharpe Ratio: 0.8198\n",
      "  Max Drawdown: -0.4126\n",
      "\n",
      "Testing A2C...\n",
      "A2C Results:\n",
      "  Final Portfolio Value: $2,963,330.86\n",
      "  Total Return: 196.33%\n",
      "  Sharpe Ratio: 0.8532\n",
      "  Max Drawdown: -0.4378\n",
      "\n",
      "Testing DDPG...\n",
      "DDPG Results:\n",
      "  Final Portfolio Value: $2,657,911.12\n",
      "  Total Return: 165.79%\n",
      "  Sharpe Ratio: 0.8359\n",
      "  Max Drawdown: -0.3827\n"
     ]
    }
   ],
   "source": [
    "# Test all trained models\n",
    "test_results = {}\n",
    "\n",
    "for model_name, model in trained_models.items():\n",
    "    try:\n",
    "        # Create a vectorized environment for testing\n",
    "        test_env = DummyVecEnv([lambda: e_trade_gym])\n",
    "        \n",
    "        # Reset test environment\n",
    "        obs = test_env.reset()  # This will return just the observation\n",
    "        \n",
    "        # Test model\n",
    "        results = test_model(model, model_name, test_env)\n",
    "        test_results[model_name] = results\n",
    "        \n",
    "        print(f\"{model_name} Results:\")\n",
    "        print(f\"  Final Portfolio Value: ${results['final_value']:,.2f}\")\n",
    "        print(f\"  Total Return: {results['total_return']:.2f}%\")\n",
    "        \n",
    "        # Calculate additional metrics\n",
    "        daily_returns = pd.Series(results['daily_returns'])\n",
    "        sharpe_ratio = daily_returns.mean() / daily_returns.std() * np.sqrt(252)\n",
    "        max_drawdown = (daily_returns.cumsum() - daily_returns.cumsum().expanding().max()).min()\n",
    "        \n",
    "        print(f\"  Sharpe Ratio: {sharpe_ratio:.4f}\")\n",
    "        print(f\"  Max Drawdown: {max_drawdown:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error testing {model_name}: {str(e)}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Ranking:\n",
      "Model  Final Value  Total Return (%)  Sharpe Ratio  Max Drawdown\n",
      "  A2C 2.963331e+06        196.333086      0.853222     -0.437833\n",
      "  PPO 2.699085e+06        169.908502      0.819840     -0.412611\n",
      " DDPG 2.657911e+06        165.791112      0.835930     -0.382699\n"
     ]
    }
   ],
   "source": [
    "# Create comparsion dataframe\n",
    "comparison_data = []\n",
    "for model_name, results in test_results.items():\n",
    "    daily_returns = pd.Series(results['daily_returns'])\n",
    "    sharpe_ratio = daily_returns.mean() / daily_returns.std() * np.sqrt(252)\n",
    "    max_drawdown = (daily_returns.cumsum() - daily_returns.cumsum().expanding().max()).min()\n",
    "\n",
    "    comparison_data.append({\n",
    "        'Model': model_name,\n",
    "        'Final Value': results['final_value'],\n",
    "        'Total Return (%)': results['total_return'],\n",
    "        'Sharpe Ratio': sharpe_ratio,\n",
    "        'Max Drawdown': max_drawdown\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('Total Return (%)', ascending=False)\n",
    "\n",
    "print(\"\\nModel Performance Ranking:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save results\n",
    "comparison_df.to_csv(f\"{RESULTS_DIR}/industry_model_comparison_{lookback}_window.csv\", index=False)\n",
    "\n",
    "# Create performance visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Portfolio Value Over Time\n",
    "plt.subplot(2, 2, 1)\n",
    "for model_name, results in test_results.items():\n",
    "    dates = pd.to_datetime(results['date_memory'])\n",
    "    values = results['asset_memory']\n",
    "    plt.plot(dates, values, label=f\"{model_name}\", linewidth=2)\n",
    "\n",
    "plt.title('Portfolio Value Over Time (Industry Model: {} Window)'.format(lookback))\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Portfolio Value ($)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Plot 2: Total Returns Comparison\n",
    "plt.subplot(2, 2, 2)\n",
    "models = comparison_df['Model']\n",
    "returns = comparison_df['Total Return (%)']\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(models)))\n",
    "bars = plt.bar(models, returns, color=colors)\n",
    "plt.title('Total Returns Comparison')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Total Return (%)')\n",
    "plt.xticks(rotation=45)\n",
    "for bar, ret in zip(bars, returns):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "             f'{ret:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "# Plot 3: Sharpe Ratio Comparison\n",
    "plt.subplot(2, 2, 3)\n",
    "sharpe_ratios = comparison_df['Sharpe Ratio']\n",
    "bars = plt.bar(models, sharpe_ratios, color=colors)\n",
    "plt.title('Sharpe Ratio Comparison')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Sharpe Ratio')\n",
    "plt.xticks(rotation=45)\n",
    "for bar, sharpe in zip(bars, sharpe_ratios):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{sharpe:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Plot 4: Max Drawdown Comparison (negative values, so we flip for visualization)\n",
    "plt.subplot(2, 2, 4)\n",
    "drawdowns = comparison_df['Max Drawdown'].abs()\n",
    "bars = plt.bar(models, drawdowns, color=colors)\n",
    "plt.title('Max Drawdown Comparison')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Max Drawdown (abs)')\n",
    "plt.xticks(rotation=45)\n",
    "for bar, dd in zip(bars, drawdowns):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001, \n",
    "             f'{dd:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RESULTS_DIR}/industry_model_comparison_{lookback}_window.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to results/\n",
      "Analysis complete!\n",
      "\n",
      "============================================================\n",
      "FEATURE IMPORTANCE ANALYSIS\n",
      "============================================================\n",
      "Analyzing feature importance for best model: DDPG\n",
      "\n",
      "Industry Factor Statistics in Dataset:\n",
      "boll_lb:\n",
      "  Mean: 1876.277073\n",
      "  Std:  4802.400106\n",
      "  Min:  0.177937\n",
      "  Max:  48782.728733\n",
      "rsi_30:\n",
      "  Mean: 53.992009\n",
      "  Std:  10.143912\n",
      "  Min:  10.767050\n",
      "  Max:  92.790798\n",
      "cci_30:\n",
      "  Mean: 24.526670\n",
      "  Std:  112.532043\n",
      "  Min:  -683.239698\n",
      "  Max:  651.973013\n",
      "dx_30:\n",
      "  Mean: 22.981763\n",
      "  Std:  16.513114\n",
      "  Min:  0.000182\n",
      "  Max:  94.030229\n",
      "close_30_sma:\n",
      "  Mean: 1952.217829\n",
      "  Std:  4991.042794\n",
      "  Min:  0.217286\n",
      "  Max:  49355.706814\n",
      "close_60_sma:\n",
      "  Mean: 1940.663028\n",
      "  Std:  4959.959259\n",
      "  Min:  0.228138\n",
      "  Max:  48942.895230\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"\\nResults saved to {RESULTS_DIR}/\")\n",
    "print(\"Analysis complete!\")\n",
    "\n",
    "# Step 9: Feature Importance Analysis (for the best performing model)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "print(f\"Analyzing feature importance for best model: {best_model_name}\")\n",
    "\n",
    "# Print FF factor statistics\n",
    "print(\"\\nIndustry Factor Statistics in Dataset:\")\n",
    "for i in ['boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma' ]:\n",
    "    factor_data = processed_full[i]\n",
    "    print(f\"{i}:\")\n",
    "    print(f\"  Mean: {factor_data.mean():.6f}\")\n",
    "    print(f\"  Std:  {factor_data.std():.6f}\")\n",
    "    print(f\"  Min:  {factor_data.min():.6f}\")\n",
    "    print(f\"  Max:  {factor_data.max():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model                         DDPG\n",
       "Final Value         2760673.542961\n",
       "Total Return (%)        176.067354\n",
       "Sharpe Ratio               0.85105\n",
       "Max Drawdown             -0.405062\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'\\nTotal Features used: {len()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summerresearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
