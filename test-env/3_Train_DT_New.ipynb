{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b5dda53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import DecisionTransformerConfig, DecisionTransformerModel, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5608fbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "892f94c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"data/dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d09602f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mean = dataset['state_mean']\n",
    "state_std = dataset['state_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "297c5ee2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dataset = dataset[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\drebi\\miniconda3\\envs\\summerresearch\\Lib\\site-packages\\datasets\\arrow_dataset.py:2861\u001b[39m, in \u001b[36mDataset.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   2859\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[32m   2860\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2861\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\drebi\\miniconda3\\envs\\summerresearch\\Lib\\site-packages\\datasets\\arrow_dataset.py:2846\u001b[39m, in \u001b[36mDataset._getitem\u001b[39m\u001b[34m(self, key, **kwargs)\u001b[39m\n\u001b[32m   2844\u001b[39m formatter = get_formatter(format_type, features=\u001b[38;5;28mself\u001b[39m._info.features, **format_kwargs)\n\u001b[32m   2845\u001b[39m pa_subtable = query_table(\u001b[38;5;28mself\u001b[39m._data, key, indices=\u001b[38;5;28mself\u001b[39m._indices)\n\u001b[32m-> \u001b[39m\u001b[32m2846\u001b[39m formatted_output = format_table(\n\u001b[32m   2847\u001b[39m     pa_subtable, key, formatter=formatter, format_columns=format_columns, output_all_columns=output_all_columns\n\u001b[32m   2848\u001b[39m )\n\u001b[32m   2849\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\drebi\\miniconda3\\envs\\summerresearch\\Lib\\site-packages\\datasets\\formatting\\formatting.py:633\u001b[39m, in \u001b[36mformat_table\u001b[39m\u001b[34m(table, key, formatter, format_columns, output_all_columns)\u001b[39m\n\u001b[32m    631\u001b[39m python_formatter = PythonFormatter(features=formatter.features)\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m formatter(pa_table, query_type=query_type)\n\u001b[32m    634\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m query_type == \u001b[33m\"\u001b[39m\u001b[33mcolumn\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    635\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\drebi\\miniconda3\\envs\\summerresearch\\Lib\\site-packages\\datasets\\formatting\\formatting.py:399\u001b[39m, in \u001b[36mFormatter.__call__\u001b[39m\u001b[34m(self, pa_table, query_type)\u001b[39m\n\u001b[32m    397\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format_row(pa_table)\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m query_type == \u001b[33m\"\u001b[39m\u001b[33mcolumn\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format_column(pa_table)\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m query_type == \u001b[33m\"\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format_batch(pa_table)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\drebi\\miniconda3\\envs\\summerresearch\\Lib\\site-packages\\datasets\\formatting\\formatting.py:442\u001b[39m, in \u001b[36mPythonFormatter.format_column\u001b[39m\u001b[34m(self, pa_table)\u001b[39m\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mformat_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa.Table) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m     column = \u001b[38;5;28mself\u001b[39m.python_arrow_extractor().extract_column(pa_table)\n\u001b[32m    443\u001b[39m     column = \u001b[38;5;28mself\u001b[39m.python_features_decoder.decode_column(column, pa_table.column_names[\u001b[32m0\u001b[39m])\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m column\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\drebi\\miniconda3\\envs\\summerresearch\\Lib\\site-packages\\datasets\\formatting\\formatting.py:148\u001b[39m, in \u001b[36mPythonArrowExtractor.extract_column\u001b[39m\u001b[34m(self, pa_table)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa.Table) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pa_table.column(\u001b[32m0\u001b[39m).to_pylist()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\drebi\\miniconda3\\envs\\summerresearch\\Lib\\site-packages\\pyarrow\\table.pxi:1335\u001b[39m, in \u001b[36mpyarrow.lib.ChunkedArray.to_pylist\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\drebi\\miniconda3\\envs\\summerresearch\\Lib\\site-packages\\pyarrow\\array.pxi:1607\u001b[39m, in \u001b[36mpyarrow.lib.Array.to_pylist\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\drebi\\miniconda3\\envs\\summerresearch\\Lib\\site-packages\\pyarrow\\scalar.pxi:793\u001b[39m, in \u001b[36mpyarrow.lib.StructScalar.as_py\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen _collections_abc>:788\u001b[39m, in \u001b[36mkeys\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen _collections_abc>:812\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, mapping)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05cc107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5334, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset), len(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e1235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['actions', 'dones', 'observations', 'rewards'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3657cd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_dim = len(dataset[0]['actions'][0])\n",
    "act_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea5bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4324"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dim = len(dataset[0]['observations'][0])\n",
    "state_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d167040",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mean = state_mean[:state_dim]\n",
    "state_std = state_std[:state_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53766eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0]['observations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d16f5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.019129622727632523,\n",
       "  -0.006513502448797226,\n",
       "  0.04570562019944191,\n",
       "  0.15612338483333588,\n",
       "  0.041282929480075836,\n",
       "  0.18546512722969055,\n",
       "  -0.16300007700920105,\n",
       "  0.045858871191740036,\n",
       "  -0.0598205029964447,\n",
       "  -0.046219564974308014,\n",
       "  -0.26312240958213806,\n",
       "  -0.10800012946128845,\n",
       "  -0.07765176892280579,\n",
       "  -0.11391003429889679,\n",
       "  -0.15980571508407593,\n",
       "  0.04218614101409912,\n",
       "  -0.08814289420843124,\n",
       "  0.15767569839954376,\n",
       "  -0.17028531432151794,\n",
       "  -0.04312672093510628,\n",
       "  -0.14606116712093353,\n",
       "  0.08254409581422806,\n",
       "  -0.03896056115627289,\n",
       "  -0.15955659747123718,\n",
       "  -0.09140151739120483,\n",
       "  -0.11390421539545059,\n",
       "  0.06155223771929741,\n",
       "  0.08480572700500488,\n",
       "  0.0758899450302124,\n",
       "  0.12660588324069977,\n",
       "  0.0731610432267189,\n",
       "  -0.08008327335119247,\n",
       "  0.0851617380976677,\n",
       "  -0.10980658233165741,\n",
       "  0.05300186946988106,\n",
       "  -0.1484784483909607,\n",
       "  -0.10654953122138977,\n",
       "  0.27709102630615234,\n",
       "  -0.09234079718589783,\n",
       "  0.22396980226039886,\n",
       "  -0.13589535653591156,\n",
       "  -0.023483429104089737,\n",
       "  0.13119491934776306,\n",
       "  0.12207475304603577,\n",
       "  -0.1550835818052292,\n",
       "  -0.09702271223068237,\n",
       "  0.08805494010448456,\n",
       "  -0.12205922603607178,\n",
       "  -0.15140973031520844,\n",
       "  0.18454954028129578,\n",
       "  -0.15592306852340698,\n",
       "  0.11566626280546188,\n",
       "  -0.3938932418823242,\n",
       "  -0.04749225080013275,\n",
       "  -0.17145314812660217,\n",
       "  0.11628907173871994,\n",
       "  0.14143335819244385,\n",
       "  -0.14097225666046143,\n",
       "  0.08632486313581467,\n",
       "  0.04534684866666794,\n",
       "  0.08977846801280975,\n",
       "  0.04657837003469467,\n",
       "  -0.11981949210166931,\n",
       "  0.01956748589873314,\n",
       "  0.04547429829835892,\n",
       "  -0.30591845512390137,\n",
       "  0.01681298203766346,\n",
       "  0.08338478952646255,\n",
       "  -0.0564526692032814,\n",
       "  0.10381109267473221,\n",
       "  -0.04996318370103836,\n",
       "  0.03845621272921562,\n",
       "  0.08929190784692764,\n",
       "  -0.23185314238071442,\n",
       "  0.058365996927022934,\n",
       "  -0.07523667812347412,\n",
       "  -0.055573832243680954,\n",
       "  0.09410503506660461,\n",
       "  0.04434235394001007,\n",
       "  -0.08533303439617157,\n",
       "  -0.11249087750911713,\n",
       "  0.181909441947937,\n",
       "  0.059727251529693604,\n",
       "  -0.14309898018836975,\n",
       "  0.08457023650407791,\n",
       "  -0.12468112260103226,\n",
       "  0.1156143918633461,\n",
       "  -0.054794639348983765,\n",
       "  0.013791460543870926,\n",
       "  0.13833190500736237,\n",
       "  0.14101152122020721,\n",
       "  0.2143004685640335,\n",
       "  -0.12447583675384521,\n",
       "  -0.0010652588680386543,\n",
       "  -0.1036682277917862,\n",
       "  0.08868923783302307,\n",
       "  0.08926049619913101,\n",
       "  0.010699380189180374,\n",
       "  0.06915980577468872,\n",
       "  -0.020331867039203644,\n",
       "  -0.16326604783535004,\n",
       "  -0.22459596395492554,\n",
       "  0.003875455819070339,\n",
       "  -0.06131215766072273,\n",
       "  -0.06622494757175446,\n",
       "  -0.06054436415433884,\n",
       "  0.10320678353309631,\n",
       "  0.09470837563276291,\n",
       "  0.019725734367966652,\n",
       "  0.022231370210647583,\n",
       "  -0.09469139575958252,\n",
       "  0.14335525035858154,\n",
       "  -0.010354511439800262,\n",
       "  -0.055920254439115524,\n",
       "  -0.012793758884072304,\n",
       "  0.05878803879022598,\n",
       "  -0.12422314286231995,\n",
       "  0.010873083025217056,\n",
       "  0.04413093626499176,\n",
       "  0.1739288866519928,\n",
       "  0.095482736825943,\n",
       "  -0.14172261953353882,\n",
       "  0.011248095892369747,\n",
       "  -0.23415233194828033,\n",
       "  -0.13243593275547028,\n",
       "  -0.07181935012340546,\n",
       "  0.0482163242995739,\n",
       "  -0.021945955231785774,\n",
       "  0.26125842332839966,\n",
       "  -0.2630883455276489,\n",
       "  0.01652301475405693,\n",
       "  -0.014665668830275536,\n",
       "  -0.0038554761558771133,\n",
       "  -0.19102761149406433,\n",
       "  -0.14547905325889587,\n",
       "  0.0315881185233593,\n",
       "  -0.13905024528503418,\n",
       "  -0.029192067682743073,\n",
       "  0.19149252772331238,\n",
       "  -0.12976039946079254,\n",
       "  0.1408194750547409,\n",
       "  0.14567646384239197,\n",
       "  0.014484493061900139,\n",
       "  -0.023027213290333748,\n",
       "  -0.004975572228431702,\n",
       "  -0.07412650436162949,\n",
       "  -0.1300441473722458,\n",
       "  0.10640610009431839,\n",
       "  -0.10823260247707367,\n",
       "  0.1302853524684906,\n",
       "  0.08819358050823212,\n",
       "  0.2419726699590683,\n",
       "  -0.054021645337343216,\n",
       "  -0.1122906506061554,\n",
       "  -0.015599793754518032,\n",
       "  -0.2994743287563324,\n",
       "  -0.057254113256931305,\n",
       "  -0.04862567037343979,\n",
       "  0.057833343744277954,\n",
       "  -0.14449237287044525,\n",
       "  0.07878055423498154,\n",
       "  0.022441662847995758,\n",
       "  -0.13031861186027527,\n",
       "  0.12427015602588654,\n",
       "  -0.08728455007076263,\n",
       "  0.008611053228378296,\n",
       "  0.07204502075910568,\n",
       "  0.05998943746089935,\n",
       "  0.061622459441423416,\n",
       "  0.029870562255382538,\n",
       "  0.02072700299322605,\n",
       "  0.061550214886665344,\n",
       "  0.02356528863310814,\n",
       "  -0.056648798286914825,\n",
       "  0.13117754459381104,\n",
       "  -0.1344272643327713,\n",
       "  -0.21696311235427856,\n",
       "  0.06009163334965706,\n",
       "  0.10943633317947388,\n",
       "  0.16397127509117126,\n",
       "  -0.22841192781925201,\n",
       "  -0.07922861725091934,\n",
       "  0.07822979986667633,\n",
       "  0.07203443348407745,\n",
       "  0.1754179447889328,\n",
       "  0.045942891389131546,\n",
       "  0.032289616763591766,\n",
       "  -0.09191355854272842,\n",
       "  0.006326848641037941,\n",
       "  0.01876608468592167,\n",
       "  0.20936818420886993,\n",
       "  -0.13326819241046906,\n",
       "  -0.1643335074186325,\n",
       "  0.10403944551944733,\n",
       "  0.02952253632247448,\n",
       "  -0.04358552396297455,\n",
       "  0.0246938094496727,\n",
       "  -0.07975009083747864,\n",
       "  0.04598626121878624,\n",
       "  0.09393774718046188,\n",
       "  0.06240119785070419,\n",
       "  -0.08609365671873093,\n",
       "  0.2340666502714157,\n",
       "  0.12800845503807068,\n",
       "  0.19351963698863983,\n",
       "  -0.1704360395669937,\n",
       "  -0.048443879932165146,\n",
       "  0.27890923619270325,\n",
       "  0.01819630153477192,\n",
       "  -0.031085871160030365,\n",
       "  -0.062279511243104935,\n",
       "  0.02653040923178196,\n",
       "  0.0526890866458416,\n",
       "  -0.1296292245388031,\n",
       "  0.15781165659427643,\n",
       "  -0.06523596495389938,\n",
       "  -0.07857491075992584,\n",
       "  0.15760433673858643,\n",
       "  -0.12221657484769821,\n",
       "  -0.24755859375,\n",
       "  0.16018158197402954,\n",
       "  0.12026390433311462,\n",
       "  -0.13236898183822632,\n",
       "  -0.3582786023616791,\n",
       "  0.11661122739315033,\n",
       "  0.024358615279197693,\n",
       "  -0.10705956816673279,\n",
       "  0.009435595944523811,\n",
       "  -0.012392520904541016,\n",
       "  -0.023404378443956375,\n",
       "  -0.10225528478622437,\n",
       "  -0.03740821033716202,\n",
       "  -0.01348455622792244,\n",
       "  0.14645299315452576,\n",
       "  -0.1503860354423523,\n",
       "  -0.08688712865114212,\n",
       "  0.048438116908073425,\n",
       "  -0.10757283866405487,\n",
       "  0.09806112945079803,\n",
       "  -0.005889112129807472,\n",
       "  0.20520153641700745,\n",
       "  0.03283649682998657,\n",
       "  0.09747377038002014,\n",
       "  0.13692410290241241,\n",
       "  0.010773535817861557,\n",
       "  0.06708409637212753,\n",
       "  -0.022702042013406754,\n",
       "  0.19591188430786133,\n",
       "  0.09577450901269913,\n",
       "  -0.13959287106990814,\n",
       "  0.09419592469930649,\n",
       "  -0.002310335636138916,\n",
       "  0.2744647264480591,\n",
       "  -0.13900497555732727,\n",
       "  -0.18965554237365723,\n",
       "  -0.013707119971513748,\n",
       "  -0.00576268695294857,\n",
       "  -0.09669385850429535,\n",
       "  0.06642507016658783,\n",
       "  -0.012507885694503784,\n",
       "  0.18338549137115479,\n",
       "  -0.11409161239862442,\n",
       "  -0.11800993978977203,\n",
       "  -0.1498415321111679,\n",
       "  -0.02157382294535637,\n",
       "  0.041192006319761276,\n",
       "  0.09105132520198822,\n",
       "  -0.13929414749145508,\n",
       "  0.33765721321105957,\n",
       "  0.06604300439357758,\n",
       "  -0.0837375670671463,\n",
       "  -0.0011501170229166746,\n",
       "  -0.10990701615810394,\n",
       "  0.02054140716791153,\n",
       "  0.08552508801221848,\n",
       "  0.06188996136188507,\n",
       "  0.025458049029111862,\n",
       "  -0.08254879713058472,\n",
       "  0.3131052851676941,\n",
       "  0.037403833121061325,\n",
       "  -0.06274465471506119,\n",
       "  -0.10001670569181442,\n",
       "  0.03724636137485504,\n",
       "  0.02919120155274868,\n",
       "  0.2233903706073761,\n",
       "  0.12438753247261047,\n",
       "  -0.03399329259991646,\n",
       "  -0.010902725160121918,\n",
       "  0.08637859672307968,\n",
       "  -0.03207539767026901,\n",
       "  -0.11566541343927383,\n",
       "  -0.03978852927684784,\n",
       "  0.07048796117305756,\n",
       "  0.29506030678749084,\n",
       "  0.1533789336681366,\n",
       "  0.0811101496219635,\n",
       "  -0.034214332699775696,\n",
       "  -0.1044103279709816,\n",
       "  -0.05140616372227669,\n",
       "  -0.07829710096120834,\n",
       "  0.1818857491016388,\n",
       "  0.07574303448200226,\n",
       "  0.12836208939552307,\n",
       "  0.1438485085964203,\n",
       "  -0.010369667783379555,\n",
       "  0.14521007239818573,\n",
       "  -0.015172844752669334,\n",
       "  0.1746259331703186,\n",
       "  0.07048140466213226,\n",
       "  0.17593511939048767,\n",
       "  0.021818330511450768,\n",
       "  -0.020690875127911568,\n",
       "  0.004218213260173798,\n",
       "  0.13252343237400055,\n",
       "  0.030377600342035294,\n",
       "  0.2298489511013031,\n",
       "  0.01365698128938675,\n",
       "  -0.18875038623809814,\n",
       "  -0.056176189333200455,\n",
       "  0.030312612652778625,\n",
       "  -0.17872586846351624,\n",
       "  0.1756039410829544,\n",
       "  -0.02986956760287285,\n",
       "  0.17342960834503174,\n",
       "  -0.052892230451107025,\n",
       "  0.11680307239294052,\n",
       "  0.06500770896673203,\n",
       "  0.15505683422088623,\n",
       "  0.12534824013710022,\n",
       "  0.2720259130001068,\n",
       "  -0.1431962251663208,\n",
       "  -0.23185500502586365,\n",
       "  -0.19494102895259857,\n",
       "  -0.12368147075176239,\n",
       "  -0.15095002949237823,\n",
       "  0.0636216253042221,\n",
       "  0.20064795017242432,\n",
       "  0.1345912367105484,\n",
       "  0.014804277569055557,\n",
       "  0.13979633152484894,\n",
       "  0.18474411964416504,\n",
       "  -0.06860630214214325,\n",
       "  0.05886777490377426,\n",
       "  -0.33198779821395874,\n",
       "  0.05677008628845215,\n",
       "  0.3387921154499054,\n",
       "  0.04994253069162369,\n",
       "  -0.0368197001516819,\n",
       "  0.02112266793847084,\n",
       "  -0.345984548330307,\n",
       "  0.024707606062293053,\n",
       "  -0.01231711357831955,\n",
       "  -0.008452173322439194,\n",
       "  0.12196461856365204,\n",
       "  -0.019190147519111633,\n",
       "  0.1795465648174286,\n",
       "  0.04640037193894386,\n",
       "  -0.21318091452121735,\n",
       "  0.01870487630367279,\n",
       "  0.024645322933793068,\n",
       "  0.06216533109545708,\n",
       "  -0.07623794674873352,\n",
       "  0.05507480725646019,\n",
       "  -0.026072334498167038,\n",
       "  -0.08821775019168854,\n",
       "  0.010879404842853546,\n",
       "  0.10305887460708618,\n",
       "  0.027497414499521255,\n",
       "  0.06911509484052658,\n",
       "  -0.03143428638577461,\n",
       "  -0.20652857422828674,\n",
       "  0.08921688795089722,\n",
       "  -0.07027999311685562,\n",
       "  -0.07564659416675568,\n",
       "  0.06172061711549759,\n",
       "  0.0553714856505394,\n",
       "  0.09102475643157959,\n",
       "  -0.0711570754647255,\n",
       "  -0.14455033838748932,\n",
       "  0.07194173336029053,\n",
       "  0.10112550854682922,\n",
       "  0.0602753609418869,\n",
       "  -0.05564954876899719,\n",
       "  -0.033535197377204895,\n",
       "  0.08013659715652466,\n",
       "  0.05673367157578468,\n",
       "  0.13363920152187347,\n",
       "  0.002999609336256981,\n",
       "  -0.055401839315891266,\n",
       "  -0.02239161729812622,\n",
       "  -0.0908692255616188,\n",
       "  -0.227809339761734,\n",
       "  -0.045606907457113266],\n",
       " [-0.019129622727632523,\n",
       "  -0.006513502448797226,\n",
       "  0.04570562019944191,\n",
       "  0.15612338483333588,\n",
       "  0.041282929480075836,\n",
       "  0.18546512722969055,\n",
       "  -0.16300007700920105,\n",
       "  0.045858871191740036,\n",
       "  -0.0598205029964447,\n",
       "  -0.046219564974308014,\n",
       "  -0.26312240958213806,\n",
       "  -0.10800012946128845,\n",
       "  -0.07765176892280579,\n",
       "  -0.11391003429889679,\n",
       "  -0.15980571508407593,\n",
       "  0.04218614101409912,\n",
       "  -0.08814289420843124,\n",
       "  0.15767569839954376,\n",
       "  -0.17028531432151794,\n",
       "  -0.04312672093510628,\n",
       "  -0.14606116712093353,\n",
       "  0.08254409581422806,\n",
       "  -0.03896056115627289,\n",
       "  -0.15955659747123718,\n",
       "  -0.09140151739120483,\n",
       "  -0.11390421539545059,\n",
       "  0.06155223771929741,\n",
       "  0.08480572700500488,\n",
       "  0.0758899450302124,\n",
       "  0.12660588324069977,\n",
       "  0.0731610432267189,\n",
       "  -0.08008327335119247,\n",
       "  0.0851617380976677,\n",
       "  -0.10980658233165741,\n",
       "  0.05300186946988106,\n",
       "  -0.1484784483909607,\n",
       "  -0.10654953122138977,\n",
       "  0.27709102630615234,\n",
       "  -0.09234079718589783,\n",
       "  0.22396980226039886,\n",
       "  -0.13589535653591156,\n",
       "  -0.023483429104089737,\n",
       "  0.13119491934776306,\n",
       "  0.12207475304603577,\n",
       "  -0.1550835818052292,\n",
       "  -0.09702271223068237,\n",
       "  0.08805494010448456,\n",
       "  -0.12205922603607178,\n",
       "  -0.15140973031520844,\n",
       "  0.18454954028129578,\n",
       "  -0.15592306852340698,\n",
       "  0.11566626280546188,\n",
       "  -0.3938932418823242,\n",
       "  -0.04749225080013275,\n",
       "  -0.17145314812660217,\n",
       "  0.11628907173871994,\n",
       "  0.14143335819244385,\n",
       "  -0.14097225666046143,\n",
       "  0.08632486313581467,\n",
       "  0.04534684866666794,\n",
       "  0.08977846801280975,\n",
       "  0.04657837003469467,\n",
       "  -0.11981949210166931,\n",
       "  0.01956748589873314,\n",
       "  0.04547429829835892,\n",
       "  -0.30591845512390137,\n",
       "  0.01681298203766346,\n",
       "  0.08338478952646255,\n",
       "  -0.0564526692032814,\n",
       "  0.10381109267473221,\n",
       "  -0.04996318370103836,\n",
       "  0.03845621272921562,\n",
       "  0.08929190784692764,\n",
       "  -0.23185314238071442,\n",
       "  0.058365996927022934,\n",
       "  -0.07523667812347412,\n",
       "  -0.055573832243680954,\n",
       "  0.09410503506660461,\n",
       "  0.04434235394001007,\n",
       "  -0.08533303439617157,\n",
       "  -0.11249087750911713,\n",
       "  0.181909441947937,\n",
       "  0.059727251529693604,\n",
       "  -0.14309898018836975,\n",
       "  0.08457023650407791,\n",
       "  -0.12468112260103226,\n",
       "  0.1156143918633461,\n",
       "  -0.054794639348983765,\n",
       "  0.013791460543870926,\n",
       "  0.13833190500736237,\n",
       "  0.14101152122020721,\n",
       "  0.2143004685640335,\n",
       "  -0.12447583675384521,\n",
       "  -0.0010652588680386543,\n",
       "  -0.1036682277917862,\n",
       "  0.08868923783302307,\n",
       "  0.08926049619913101,\n",
       "  0.010699380189180374,\n",
       "  0.06915980577468872,\n",
       "  -0.020331867039203644,\n",
       "  -0.16326604783535004,\n",
       "  -0.22459596395492554,\n",
       "  0.003875455819070339,\n",
       "  -0.06131215766072273,\n",
       "  -0.06622494757175446,\n",
       "  -0.06054436415433884,\n",
       "  0.10320678353309631,\n",
       "  0.09470837563276291,\n",
       "  0.019725734367966652,\n",
       "  0.022231370210647583,\n",
       "  -0.09469139575958252,\n",
       "  0.14335525035858154,\n",
       "  -0.010354511439800262,\n",
       "  -0.055920254439115524,\n",
       "  -0.012793758884072304,\n",
       "  0.05878803879022598,\n",
       "  -0.12422314286231995,\n",
       "  0.010873083025217056,\n",
       "  0.04413093626499176,\n",
       "  0.1739288866519928,\n",
       "  0.095482736825943,\n",
       "  -0.14172261953353882,\n",
       "  0.011248095892369747,\n",
       "  -0.23415233194828033,\n",
       "  -0.13243593275547028,\n",
       "  -0.07181935012340546,\n",
       "  0.0482163242995739,\n",
       "  -0.021945955231785774,\n",
       "  0.26125842332839966,\n",
       "  -0.2630883455276489,\n",
       "  0.01652301475405693,\n",
       "  -0.014665668830275536,\n",
       "  -0.0038554761558771133,\n",
       "  -0.19102761149406433,\n",
       "  -0.14547905325889587,\n",
       "  0.0315881185233593,\n",
       "  -0.13905024528503418,\n",
       "  -0.029192067682743073,\n",
       "  0.19149252772331238,\n",
       "  -0.12976039946079254,\n",
       "  0.1408194750547409,\n",
       "  0.14567646384239197,\n",
       "  0.014484493061900139,\n",
       "  -0.023027213290333748,\n",
       "  -0.004975572228431702,\n",
       "  -0.07412650436162949,\n",
       "  -0.1300441473722458,\n",
       "  0.10640610009431839,\n",
       "  -0.10823260247707367,\n",
       "  0.1302853524684906,\n",
       "  0.08819358050823212,\n",
       "  0.2419726699590683,\n",
       "  -0.054021645337343216,\n",
       "  -0.1122906506061554,\n",
       "  -0.015599793754518032,\n",
       "  -0.2994743287563324,\n",
       "  -0.057254113256931305,\n",
       "  -0.04862567037343979,\n",
       "  0.057833343744277954,\n",
       "  -0.14449237287044525,\n",
       "  0.07878055423498154,\n",
       "  0.022441662847995758,\n",
       "  -0.13031861186027527,\n",
       "  0.12427015602588654,\n",
       "  -0.08728455007076263,\n",
       "  0.008611053228378296,\n",
       "  0.07204502075910568,\n",
       "  0.05998943746089935,\n",
       "  0.061622459441423416,\n",
       "  0.029870562255382538,\n",
       "  0.02072700299322605,\n",
       "  0.061550214886665344,\n",
       "  0.02356528863310814,\n",
       "  -0.056648798286914825,\n",
       "  0.13117754459381104,\n",
       "  -0.1344272643327713,\n",
       "  -0.21696311235427856,\n",
       "  0.06009163334965706,\n",
       "  0.10943633317947388,\n",
       "  0.16397127509117126,\n",
       "  -0.22841192781925201,\n",
       "  -0.07922861725091934,\n",
       "  0.07822979986667633,\n",
       "  0.07203443348407745,\n",
       "  0.1754179447889328,\n",
       "  0.045942891389131546,\n",
       "  0.032289616763591766,\n",
       "  -0.09191355854272842,\n",
       "  0.006326848641037941,\n",
       "  0.01876608468592167,\n",
       "  0.20936818420886993,\n",
       "  -0.13326819241046906,\n",
       "  -0.1643335074186325,\n",
       "  0.10403944551944733,\n",
       "  0.02952253632247448,\n",
       "  -0.04358552396297455,\n",
       "  0.0246938094496727,\n",
       "  -0.07975009083747864,\n",
       "  0.04598626121878624,\n",
       "  0.09393774718046188,\n",
       "  0.06240119785070419,\n",
       "  -0.08609365671873093,\n",
       "  0.2340666502714157,\n",
       "  0.12800845503807068,\n",
       "  0.19351963698863983,\n",
       "  -0.1704360395669937,\n",
       "  -0.048443879932165146,\n",
       "  0.27890923619270325,\n",
       "  0.01819630153477192,\n",
       "  -0.031085871160030365,\n",
       "  -0.062279511243104935,\n",
       "  0.02653040923178196,\n",
       "  0.0526890866458416,\n",
       "  -0.1296292245388031,\n",
       "  0.15781165659427643,\n",
       "  -0.06523596495389938,\n",
       "  -0.07857491075992584,\n",
       "  0.15760433673858643,\n",
       "  -0.12221657484769821,\n",
       "  -0.24755859375,\n",
       "  0.16018158197402954,\n",
       "  0.12026390433311462,\n",
       "  -0.13236898183822632,\n",
       "  -0.3582786023616791,\n",
       "  0.11661122739315033,\n",
       "  0.024358615279197693,\n",
       "  -0.10705956816673279,\n",
       "  0.009435595944523811,\n",
       "  -0.012392520904541016,\n",
       "  -0.023404378443956375,\n",
       "  -0.10225528478622437,\n",
       "  -0.03740821033716202,\n",
       "  -0.01348455622792244,\n",
       "  0.14645299315452576,\n",
       "  -0.1503860354423523,\n",
       "  -0.08688712865114212,\n",
       "  0.048438116908073425,\n",
       "  -0.10757283866405487,\n",
       "  0.09806112945079803,\n",
       "  -0.005889112129807472,\n",
       "  0.20520153641700745,\n",
       "  0.03283649682998657,\n",
       "  0.09747377038002014,\n",
       "  0.13692410290241241,\n",
       "  0.010773535817861557,\n",
       "  0.06708409637212753,\n",
       "  -0.022702042013406754,\n",
       "  0.19591188430786133,\n",
       "  0.09577450901269913,\n",
       "  -0.13959287106990814,\n",
       "  0.09419592469930649,\n",
       "  -0.002310335636138916,\n",
       "  0.2744647264480591,\n",
       "  -0.13900497555732727,\n",
       "  -0.18965554237365723,\n",
       "  -0.013707119971513748,\n",
       "  -0.00576268695294857,\n",
       "  -0.09669385850429535,\n",
       "  0.06642507016658783,\n",
       "  -0.012507885694503784,\n",
       "  0.18338549137115479,\n",
       "  -0.11409161239862442,\n",
       "  -0.11800993978977203,\n",
       "  -0.1498415321111679,\n",
       "  -0.02157382294535637,\n",
       "  0.041192006319761276,\n",
       "  0.09105132520198822,\n",
       "  -0.13929414749145508,\n",
       "  0.33765721321105957,\n",
       "  0.06604300439357758,\n",
       "  -0.0837375670671463,\n",
       "  -0.0011501170229166746,\n",
       "  -0.10990701615810394,\n",
       "  0.02054140716791153,\n",
       "  0.08552508801221848,\n",
       "  0.06188996136188507,\n",
       "  0.025458049029111862,\n",
       "  -0.08254879713058472,\n",
       "  0.3131052851676941,\n",
       "  0.037403833121061325,\n",
       "  -0.06274465471506119,\n",
       "  -0.10001670569181442,\n",
       "  0.03724636137485504,\n",
       "  0.02919120155274868,\n",
       "  0.2233903706073761,\n",
       "  0.12438753247261047,\n",
       "  -0.03399329259991646,\n",
       "  -0.010902725160121918,\n",
       "  0.08637859672307968,\n",
       "  -0.03207539767026901,\n",
       "  -0.11566541343927383,\n",
       "  -0.03978852927684784,\n",
       "  0.07048796117305756,\n",
       "  0.29506030678749084,\n",
       "  0.1533789336681366,\n",
       "  0.0811101496219635,\n",
       "  -0.034214332699775696,\n",
       "  -0.1044103279709816,\n",
       "  -0.05140616372227669,\n",
       "  -0.07829710096120834,\n",
       "  0.1818857491016388,\n",
       "  0.07574303448200226,\n",
       "  0.12836208939552307,\n",
       "  0.1438485085964203,\n",
       "  -0.010369667783379555,\n",
       "  0.14521007239818573,\n",
       "  -0.015172844752669334,\n",
       "  0.1746259331703186,\n",
       "  0.07048140466213226,\n",
       "  0.17593511939048767,\n",
       "  0.021818330511450768,\n",
       "  -0.020690875127911568,\n",
       "  0.004218213260173798,\n",
       "  0.13252343237400055,\n",
       "  0.030377600342035294,\n",
       "  0.2298489511013031,\n",
       "  0.01365698128938675,\n",
       "  -0.18875038623809814,\n",
       "  -0.056176189333200455,\n",
       "  0.030312612652778625,\n",
       "  -0.17872586846351624,\n",
       "  0.1756039410829544,\n",
       "  -0.02986956760287285,\n",
       "  0.17342960834503174,\n",
       "  -0.052892230451107025,\n",
       "  0.11680307239294052,\n",
       "  0.06500770896673203,\n",
       "  0.15505683422088623,\n",
       "  0.12534824013710022,\n",
       "  0.2720259130001068,\n",
       "  -0.1431962251663208,\n",
       "  -0.23185500502586365,\n",
       "  -0.19494102895259857,\n",
       "  -0.12368147075176239,\n",
       "  -0.15095002949237823,\n",
       "  0.0636216253042221,\n",
       "  0.20064795017242432,\n",
       "  0.1345912367105484,\n",
       "  0.014804277569055557,\n",
       "  0.13979633152484894,\n",
       "  0.18474411964416504,\n",
       "  -0.06860630214214325,\n",
       "  0.05886777490377426,\n",
       "  -0.33198779821395874,\n",
       "  0.05677008628845215,\n",
       "  0.3387921154499054,\n",
       "  0.04994253069162369,\n",
       "  -0.0368197001516819,\n",
       "  0.02112266793847084,\n",
       "  -0.345984548330307,\n",
       "  0.024707606062293053,\n",
       "  -0.01231711357831955,\n",
       "  -0.008452173322439194,\n",
       "  0.12196461856365204,\n",
       "  -0.019190147519111633,\n",
       "  0.1795465648174286,\n",
       "  0.04640037193894386,\n",
       "  -0.21318091452121735,\n",
       "  0.01870487630367279,\n",
       "  0.024645322933793068,\n",
       "  0.06216533109545708,\n",
       "  -0.07623794674873352,\n",
       "  0.05507480725646019,\n",
       "  -0.026072334498167038,\n",
       "  -0.08821775019168854,\n",
       "  0.010879404842853546,\n",
       "  0.10305887460708618,\n",
       "  0.027497414499521255,\n",
       "  0.06911509484052658,\n",
       "  -0.03143428638577461,\n",
       "  -0.20652857422828674,\n",
       "  0.08921688795089722,\n",
       "  -0.07027999311685562,\n",
       "  -0.07564659416675568,\n",
       "  0.06172061711549759,\n",
       "  0.0553714856505394,\n",
       "  0.09102475643157959,\n",
       "  -0.0711570754647255,\n",
       "  -0.14455033838748932,\n",
       "  0.07194173336029053,\n",
       "  0.10112550854682922,\n",
       "  0.0602753609418869,\n",
       "  -0.05564954876899719,\n",
       "  -0.033535197377204895,\n",
       "  0.08013659715652466,\n",
       "  0.05673367157578468,\n",
       "  0.13363920152187347,\n",
       "  0.002999609336256981,\n",
       "  -0.055401839315891266,\n",
       "  -0.02239161729812622,\n",
       "  -0.0908692255616188,\n",
       "  -0.227809339761734,\n",
       "  -0.045606907457113266]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['actions'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc244628",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DecisionTransformerGymDataCollator:\n",
    "    return_tensors: str = \"pt\"\n",
    "    max_len: int = 20 #subsets of the episode we use for training\n",
    "    state_dim: int = 4324  # size of state space\n",
    "    act_dim: int = 393  # size of action space\n",
    "    max_ep_len: int = 985 # max episode length in the dataset\n",
    "    scale: float = 1000.0  # normalization of rewards/returns\n",
    "    #state_mean: np.array = None  # to store state means\n",
    "    #state_std: np.array = None  # to store state stds\n",
    "    p_sample: np.array = None  # a distribution to take account trajectory lengths\n",
    "    n_traj: int = 0 # to store the number of trajectories in the dataset\n",
    "\n",
    "    def __init__(self, dataset, state_mean, state_std) -> None:\n",
    "        self.act_dim = len(dataset[0]['actions'][0])\n",
    "        self.state_dim = len(dataset[0]['observations'][0])\n",
    "        self.dataset = dataset\n",
    "        self.state_mean = state_mean\n",
    "        self.state_std = state_std\n",
    "        # calculate dataset stats for normalization of states\n",
    "        states = []\n",
    "        traj_lens = []\n",
    "\n",
    "        self.n_traj = len(self.dataset)\n",
    "\n",
    "        traj_lens = [len(self.dataset[0]) for i in range(self.n_traj)]\n",
    "        traj_lens = np.array(traj_lens)\n",
    "        self.p_sample = traj_lens / sum(traj_lens)\n",
    "\n",
    "    def _discount_cumsum(self, x, gamma):\n",
    "        discount_cumsum = np.zeros_like(x)\n",
    "        discount_cumsum[-1] = x[-1]\n",
    "        for t in reversed(range(x.shape[0] - 1)):\n",
    "            discount_cumsum[t] = x[t] + gamma * discount_cumsum[t + 1]\n",
    "        return discount_cumsum\n",
    "\n",
    "    def __call__(self, features):\n",
    "        batch_size = len(features)\n",
    "        # this is a bit of a hack to be able to sample of a non-uniform distribution\n",
    "        batch_inds = np.random.choice(\n",
    "            np.arange(self.n_traj),\n",
    "            size=batch_size,\n",
    "            replace=True,\n",
    "            p=self.p_sample,  # reweights so we sample according to timesteps\n",
    "        )\n",
    "        # a batch of dataset features\n",
    "        s, a, r, d, rtg, timesteps, mask = [], [], [], [], [], [], []\n",
    "\n",
    "        for ind in batch_inds:\n",
    "            # for feature in features:\n",
    "            feature = self.dataset[int(ind)]\n",
    "            si = random.randint(0, len(feature[\"rewards\"]) - 1)\n",
    "\n",
    "            # get sequences from dataset\n",
    "            s.append(np.array(feature[\"observations\"][si : si + self.max_len]).reshape(1, -1, self.state_dim))\n",
    "            a.append(np.array(feature[\"actions\"][si : si + self.max_len]).reshape(1, -1, self.act_dim))\n",
    "            r.append(np.array(feature[\"rewards\"][si : si + self.max_len]).reshape(1, -1, 1))\n",
    "\n",
    "            d.append(np.array(feature[\"dones\"][si : si + self.max_len]).reshape(1, -1))\n",
    "            timesteps.append(np.arange(si, si + s[-1].shape[1]).reshape(1, -1))\n",
    "            timesteps[-1][timesteps[-1] >= self.max_ep_len] = self.max_ep_len - 1  # padding cutoff\n",
    "            rtg.append(\n",
    "                self._discount_cumsum(np.array(feature[\"rewards\"][si:]), gamma=1.0)[\n",
    "                    : s[-1].shape[1]   # TODO check the +1 removed here\n",
    "                ].reshape(1, -1, 1)\n",
    "            )\n",
    "            if rtg[-1].shape[1] < s[-1].shape[1]:\n",
    "                print(\"if true\")\n",
    "                rtg[-1] = np.concatenate([rtg[-1], np.zeros((1, 1, 1))], axis=1)\n",
    "\n",
    "            # padding and state + reward normalization\n",
    "            tlen = s[-1].shape[1]\n",
    "            s[-1] = np.concatenate([np.zeros((1, self.max_len - tlen, self.state_dim)), s[-1]], axis=1)\n",
    "            s[-1] = (s[-1] - self.state_mean) / self.state_std\n",
    "            a[-1] = np.concatenate(\n",
    "                [np.ones((1, self.max_len - tlen, self.act_dim)) * -10.0, a[-1]],\n",
    "                axis=1,\n",
    "            )\n",
    "            r[-1] = np.concatenate([np.zeros((1, self.max_len - tlen, 1)), r[-1]], axis=1)\n",
    "            d[-1] = np.concatenate([np.ones((1, self.max_len - tlen)) * 2, d[-1]], axis=1)\n",
    "            rtg[-1] = np.concatenate([np.zeros((1, self.max_len - tlen, 1)), rtg[-1]], axis=1) / self.scale\n",
    "            timesteps[-1] = np.concatenate([np.zeros((1, self.max_len - tlen)), timesteps[-1]], axis=1)\n",
    "            mask.append(np.concatenate([np.zeros((1, self.max_len - tlen)), np.ones((1, tlen))], axis=1))\n",
    "\n",
    "        s = torch.from_numpy(np.concatenate(s, axis=0)).float()\n",
    "        a = torch.from_numpy(np.concatenate(a, axis=0)).float()\n",
    "        r = torch.from_numpy(np.concatenate(r, axis=0)).float()\n",
    "        d = torch.from_numpy(np.concatenate(d, axis=0))\n",
    "        rtg = torch.from_numpy(np.concatenate(rtg, axis=0)).float()\n",
    "        timesteps = torch.from_numpy(np.concatenate(timesteps, axis=0)).long()\n",
    "        mask = torch.from_numpy(np.concatenate(mask, axis=0)).float()\n",
    "\n",
    "        return {\n",
    "            \"states\": s,\n",
    "            \"actions\": a,\n",
    "            \"rewards\": r,\n",
    "            \"returns_to_go\": rtg,\n",
    "            \"timesteps\": timesteps,\n",
    "            \"attention_mask\": mask,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff0a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DecisionTransformerGymDataCollator(dataset, state_mean, state_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011778a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import DecisionTransformerConfig, DecisionTransformerModel, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f004e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainableDT(DecisionTransformerModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        output = super().forward(**kwargs)\n",
    "        # add the DT loss\n",
    "        action_preds = output[1]\n",
    "        action_targets = kwargs[\"actions\"]\n",
    "        attention_mask = kwargs[\"attention_mask\"]\n",
    "        act_dim = action_preds.shape[2]\n",
    "        action_preds = action_preds.reshape(-1, act_dim)[attention_mask.reshape(-1) > 0]\n",
    "        action_targets = action_targets.reshape(-1, act_dim)[attention_mask.reshape(-1) > 0]\n",
    "\n",
    "        loss = torch.mean((action_preds - action_targets) ** 2)\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def original_forward(self, **kwargs):\n",
    "        return super().forward(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3587710",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DecisionTransformerConfig(state_dim=collator.state_dim, act_dim=collator.act_dim)\n",
    "model = TrainableDT(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c1f53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\" # we disable weights and biases logging for this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8346c5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output/\",\n",
    "    remove_unused_columns=False,\n",
    "    num_train_epochs=120,\n",
    "    per_device_train_batch_size=64,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    warmup_ratio=0.1,\n",
    "    optim=\"adamw_torch\",\n",
    "    max_grad_norm=0.25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c2a09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e7b865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10080' max='10080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10080/10080 40:00, Epoch 120/120]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.024200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10080, training_loss=0.001679275388642776, metrics={'train_runtime': 2402.1044, 'train_samples_per_second': 266.466, 'train_steps_per_second': 4.196, 'total_flos': 6.005605220842752e+17, 'train_loss': 0.001679275388642776, 'epoch': 120.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    data_collator=collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e524146",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('trained_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289bb384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summerresearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
