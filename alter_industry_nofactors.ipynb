{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30f1f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_portfolio_allocation.env_portfolio import StockPortfolioEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    "    TRADE_START_DATE,\n",
    "    TRADE_END_DATE,\n",
    ")\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f8e4110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data...\n",
      "YF deprecation warning: set proxy via new config function: yf.set_config(proxy=proxy)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (62600, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998-12-22</td>\n",
       "      <td>11.746051</td>\n",
       "      <td>11.809159</td>\n",
       "      <td>11.706608</td>\n",
       "      <td>11.769716</td>\n",
       "      <td>15200</td>\n",
       "      <td>XLE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998-12-22</td>\n",
       "      <td>14.582212</td>\n",
       "      <td>14.582212</td>\n",
       "      <td>14.533279</td>\n",
       "      <td>14.533279</td>\n",
       "      <td>600</td>\n",
       "      <td>XLI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998-12-22</td>\n",
       "      <td>23.943205</td>\n",
       "      <td>24.281748</td>\n",
       "      <td>23.744748</td>\n",
       "      <td>24.211705</td>\n",
       "      <td>300500</td>\n",
       "      <td>XLK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998-12-22</td>\n",
       "      <td>14.274884</td>\n",
       "      <td>14.291718</td>\n",
       "      <td>13.938212</td>\n",
       "      <td>13.938212</td>\n",
       "      <td>150300</td>\n",
       "      <td>XLP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-12-22</td>\n",
       "      <td>11.913822</td>\n",
       "      <td>12.082326</td>\n",
       "      <td>11.913822</td>\n",
       "      <td>12.082326</td>\n",
       "      <td>7900</td>\n",
       "      <td>XLU</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price        date      close       high        low       open  volume  tic  \\\n",
       "0      1998-12-22  11.746051  11.809159  11.706608  11.769716   15200  XLE   \n",
       "1      1998-12-22  14.582212  14.582212  14.533279  14.533279     600  XLI   \n",
       "2      1998-12-22  23.943205  24.281748  23.744748  24.211705  300500  XLK   \n",
       "3      1998-12-22  14.274884  14.291718  13.938212  13.938212  150300  XLP   \n",
       "4      1998-12-22  11.913822  12.082326  11.913822  12.082326    7900  XLU   \n",
       "\n",
       "Price  day  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ETFs\n",
    "TICKERS = ['XLP', 'XLY', 'XLI', 'XLE', 'XLK', 'IYZ', 'XRT', 'XLV', 'XLU', 'VTI']\n",
    "\n",
    "# Mutual Funds\n",
    "# TICKERS = ['VCSAX', 'FSCPX', 'VINAX', 'FSENX', 'VITAX', 'FSDCX', 'FSRPX', 'VGHCX', 'VUIAX', 'VEXAX']\n",
    "\n",
    "# Futures\n",
    "# TICKERS = ['SPSU', 'SPSD', 'SPSI', 'SPEN', 'SPTL', 'SPTS', 'SPSD', 'SPHC', 'SPUT', 'ES']\n",
    "\n",
    "START_DATE = '1980-01-01'\n",
    "END_DATE = '2024-12-31'\n",
    "TRAIN_START_DATE = START_DATE\n",
    "TRAIN_END_DATE = '2020-01-01'\n",
    "TRADE_START_DATE = '2020-01-01'\n",
    "TRADE_END_DATE = '2022-11-20'\n",
    "\n",
    "print('Downloading data...')\n",
    "stock_data = YahooDownloader(\n",
    "    ticker_list=TICKERS,\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    ").fetch_data()\n",
    "\n",
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1b0a742",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data[\"date\"] = pd.to_datetime(stock_data[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d48f4c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date column type before: datetime64[ns]\n",
      "Date column type after: object\n",
      "Preprocessing data with FeatureEngineer...\n",
      "Successfully added technical indicators\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (6546, 8)\n",
      "Successfully added vix\n",
      "Successfully added turbulence index\n",
      "Processed data shape: (45822, 18)\n",
      "Final date column type: datetime64[ns]\n",
      "Features: ['date', 'close', 'high', 'low', 'open', 'volume', 'tic', 'day', 'macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma', 'vix', 'turbulence']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998-12-22</td>\n",
       "      <td>11.746051</td>\n",
       "      <td>11.809159</td>\n",
       "      <td>11.706608</td>\n",
       "      <td>11.769716</td>\n",
       "      <td>15200</td>\n",
       "      <td>XLE</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.214169</td>\n",
       "      <td>11.522481</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.746051</td>\n",
       "      <td>11.746051</td>\n",
       "      <td>22.780001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998-12-22</td>\n",
       "      <td>14.582212</td>\n",
       "      <td>14.582212</td>\n",
       "      <td>14.533279</td>\n",
       "      <td>14.533279</td>\n",
       "      <td>600</td>\n",
       "      <td>XLI</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.214169</td>\n",
       "      <td>11.522481</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14.582212</td>\n",
       "      <td>14.582212</td>\n",
       "      <td>22.780001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998-12-22</td>\n",
       "      <td>23.943205</td>\n",
       "      <td>24.281748</td>\n",
       "      <td>23.744748</td>\n",
       "      <td>24.211705</td>\n",
       "      <td>300500</td>\n",
       "      <td>XLK</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.214169</td>\n",
       "      <td>11.522481</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>23.943205</td>\n",
       "      <td>23.943205</td>\n",
       "      <td>22.780001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998-12-22</td>\n",
       "      <td>14.274884</td>\n",
       "      <td>14.291718</td>\n",
       "      <td>13.938212</td>\n",
       "      <td>13.938212</td>\n",
       "      <td>150300</td>\n",
       "      <td>XLP</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.214169</td>\n",
       "      <td>11.522481</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14.274884</td>\n",
       "      <td>14.274884</td>\n",
       "      <td>22.780001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998-12-22</td>\n",
       "      <td>11.913822</td>\n",
       "      <td>12.082326</td>\n",
       "      <td>11.913822</td>\n",
       "      <td>12.082326</td>\n",
       "      <td>7900</td>\n",
       "      <td>XLU</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.214169</td>\n",
       "      <td>11.522481</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.913822</td>\n",
       "      <td>11.913822</td>\n",
       "      <td>22.780001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      close       high        low       open  volume  tic  day  \\\n",
       "0 1998-12-22  11.746051  11.809159  11.706608  11.769716   15200  XLE    1   \n",
       "1 1998-12-22  14.582212  14.582212  14.533279  14.533279     600  XLI    1   \n",
       "2 1998-12-22  23.943205  24.281748  23.744748  24.211705  300500  XLK    1   \n",
       "3 1998-12-22  14.274884  14.291718  13.938212  13.938212  150300  XLP    1   \n",
       "4 1998-12-22  11.913822  12.082326  11.913822  12.082326    7900  XLU    1   \n",
       "\n",
       "   macd    boll_ub    boll_lb  rsi_30     cci_30  dx_30  close_30_sma  \\\n",
       "0   0.0  12.214169  11.522481   100.0  66.666667  100.0     11.746051   \n",
       "1   0.0  12.214169  11.522481   100.0  66.666667  100.0     14.582212   \n",
       "2   0.0  12.214169  11.522481   100.0  66.666667  100.0     23.943205   \n",
       "3   0.0  12.214169  11.522481   100.0  66.666667  100.0     14.274884   \n",
       "4   0.0  12.214169  11.522481   100.0  66.666667  100.0     11.913822   \n",
       "\n",
       "   close_60_sma        vix  turbulence  \n",
       "0     11.746051  22.780001         0.0  \n",
       "1     14.582212  22.780001         0.0  \n",
       "2     23.943205  22.780001         0.0  \n",
       "3     14.274884  22.780001         0.0  \n",
       "4     11.913822  22.780001         0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = stock_data.copy()\n",
    "df[\"date\"] = df[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(f\"Date column type before: {stock_data['date'].dtype}\")\n",
    "print(f\"Date column type after: {df['date'].dtype}\")\n",
    "\n",
    "fe = FeatureEngineer(\n",
    "    use_technical_indicator=True,\n",
    "    tech_indicator_list=INDICATORS,\n",
    "    use_vix=True,\n",
    "    use_turbulence=True,\n",
    "    user_defined_feature=False,\n",
    ")\n",
    "\n",
    "print(\"Preprocessing data with FeatureEngineer...\")\n",
    "processed_data = fe.preprocess_data(df)\n",
    "\n",
    "# Convert date to datetime after processing\n",
    "processed_data[\"date\"] = pd.to_datetime(processed_data[\"date\"])\n",
    "processed_data = processed_data.dropna().reset_index(drop=True)\n",
    "\n",
    "print(f\"Processed data shape: {processed_data.shape}\")\n",
    "print(f\"Final date column type: {processed_data['date'].dtype}\")\n",
    "print(f\"Features: {processed_data.columns.tolist()}\")\n",
    "\n",
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8040ccdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>return_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-12-22</td>\n",
       "      <td>13.516106</td>\n",
       "      <td>13.628339</td>\n",
       "      <td>13.500072</td>\n",
       "      <td>13.548172</td>\n",
       "      <td>605300</td>\n",
       "      <td>XLE</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.103612</td>\n",
       "      <td>14.166833</td>\n",
       "      <td>13.373419</td>\n",
       "      <td>45.574828</td>\n",
       "      <td>-104.984033</td>\n",
       "      <td>22.227571</td>\n",
       "      <td>13.977273</td>\n",
       "      <td>13.829793</td>\n",
       "      <td>22.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tic       XLE       XLI       XLK       XLP   ...</td>\n",
       "      <td>tic              XLE       XLI       XLK      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-12-22</td>\n",
       "      <td>17.689074</td>\n",
       "      <td>17.788006</td>\n",
       "      <td>17.629714</td>\n",
       "      <td>17.738540</td>\n",
       "      <td>511700</td>\n",
       "      <td>XLI</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010759</td>\n",
       "      <td>17.973617</td>\n",
       "      <td>17.176688</td>\n",
       "      <td>49.821565</td>\n",
       "      <td>11.632671</td>\n",
       "      <td>7.185298</td>\n",
       "      <td>17.667051</td>\n",
       "      <td>17.639550</td>\n",
       "      <td>22.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tic       XLE       XLI       XLK       XLP   ...</td>\n",
       "      <td>tic              XLE       XLI       XLK      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-12-22</td>\n",
       "      <td>39.645401</td>\n",
       "      <td>40.112367</td>\n",
       "      <td>39.120064</td>\n",
       "      <td>39.972277</td>\n",
       "      <td>307700</td>\n",
       "      <td>XLK</td>\n",
       "      <td>2</td>\n",
       "      <td>1.361656</td>\n",
       "      <td>39.794930</td>\n",
       "      <td>34.553062</td>\n",
       "      <td>69.913484</td>\n",
       "      <td>160.096590</td>\n",
       "      <td>38.563927</td>\n",
       "      <td>36.267855</td>\n",
       "      <td>33.651679</td>\n",
       "      <td>22.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tic       XLE       XLI       XLK       XLP   ...</td>\n",
       "      <td>tic              XLE       XLI       XLK      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-12-22</td>\n",
       "      <td>12.483128</td>\n",
       "      <td>12.576730</td>\n",
       "      <td>12.321451</td>\n",
       "      <td>12.363998</td>\n",
       "      <td>750600</td>\n",
       "      <td>XLP</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.275549</td>\n",
       "      <td>14.056470</td>\n",
       "      <td>11.978246</td>\n",
       "      <td>42.296779</td>\n",
       "      <td>-110.384911</td>\n",
       "      <td>31.926271</td>\n",
       "      <td>13.197083</td>\n",
       "      <td>13.134717</td>\n",
       "      <td>22.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tic       XLE       XLI       XLK       XLP   ...</td>\n",
       "      <td>tic              XLE       XLI       XLK      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-12-22</td>\n",
       "      <td>11.768038</td>\n",
       "      <td>11.889820</td>\n",
       "      <td>11.742399</td>\n",
       "      <td>11.857772</td>\n",
       "      <td>84600</td>\n",
       "      <td>XLU</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.033414</td>\n",
       "      <td>12.055390</td>\n",
       "      <td>11.618069</td>\n",
       "      <td>47.905721</td>\n",
       "      <td>-59.163115</td>\n",
       "      <td>6.755286</td>\n",
       "      <td>11.878775</td>\n",
       "      <td>11.891841</td>\n",
       "      <td>22.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tic       XLE       XLI       XLK       XLP   ...</td>\n",
       "      <td>tic              XLE       XLI       XLK      ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      close       high        low       open  volume  tic  day  \\\n",
       "0 1999-12-22  13.516106  13.628339  13.500072  13.548172  605300  XLE    2   \n",
       "1 1999-12-22  17.689074  17.788006  17.629714  17.738540  511700  XLI    2   \n",
       "2 1999-12-22  39.645401  40.112367  39.120064  39.972277  307700  XLK    2   \n",
       "3 1999-12-22  12.483128  12.576730  12.321451  12.363998  750600  XLP    2   \n",
       "4 1999-12-22  11.768038  11.889820  11.742399  11.857772   84600  XLU    2   \n",
       "\n",
       "       macd    boll_ub    boll_lb     rsi_30      cci_30      dx_30  \\\n",
       "0 -0.103612  14.166833  13.373419  45.574828 -104.984033  22.227571   \n",
       "1  0.010759  17.973617  17.176688  49.821565   11.632671   7.185298   \n",
       "2  1.361656  39.794930  34.553062  69.913484  160.096590  38.563927   \n",
       "3 -0.275549  14.056470  11.978246  42.296779 -110.384911  31.926271   \n",
       "4 -0.033414  12.055390  11.618069  47.905721  -59.163115   6.755286   \n",
       "\n",
       "   close_30_sma  close_60_sma    vix  turbulence  \\\n",
       "0     13.977273     13.829793  22.43         0.0   \n",
       "1     17.667051     17.639550  22.43         0.0   \n",
       "2     36.267855     33.651679  22.43         0.0   \n",
       "3     13.197083     13.134717  22.43         0.0   \n",
       "4     11.878775     11.891841  22.43         0.0   \n",
       "\n",
       "                                            cov_list  \\\n",
       "0  tic       XLE       XLI       XLK       XLP   ...   \n",
       "1  tic       XLE       XLI       XLK       XLP   ...   \n",
       "2  tic       XLE       XLI       XLK       XLP   ...   \n",
       "3  tic       XLE       XLI       XLK       XLP   ...   \n",
       "4  tic       XLE       XLI       XLK       XLP   ...   \n",
       "\n",
       "                                         return_list  \n",
       "0  tic              XLE       XLI       XLK      ...  \n",
       "1  tic              XLE       XLI       XLK      ...  \n",
       "2  tic              XLE       XLI       XLK      ...  \n",
       "3  tic              XLE       XLI       XLK      ...  \n",
       "4  tic              XLE       XLI       XLK      ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data = processed_data.sort_values([\"date\", \"tic\"], ignore_index=True)\n",
    "processed_data.index = processed_data.date.factorize()[0]\n",
    "\n",
    "cov_list = []\n",
    "return_list = []\n",
    "\n",
    "lookback = 252\n",
    "for i in range(lookback, len(processed_data.index.unique())):\n",
    "    data_lookback = processed_data.iloc[i - lookback : i]\n",
    "    price_lookback = data_lookback.pivot(index=\"date\", columns=\"tic\", values=\"close\")\n",
    "    return_lookback = price_lookback.pct_change().dropna()\n",
    "    return_list.append(return_lookback)\n",
    "\n",
    "    cov = return_lookback.cov()\n",
    "    cov_list.append(cov)\n",
    "\n",
    "df_cov = pd.DataFrame(\n",
    "    {\n",
    "        \"date\": processed_data.date.unique()[lookback:],\n",
    "        \"cov_list\": cov_list,\n",
    "        \"return_list\": return_list,\n",
    "    }\n",
    ")\n",
    "processed_data = processed_data.merge(df_cov, on=\"date\")\n",
    "processed_data = processed_data.sort_values([\"date\", \"tic\"]).reset_index(drop=True)\n",
    "\n",
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77634c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_split(processed_data, TRAIN_START_DATE, end=TRAIN_END_DATE)\n",
    "trade = data_split(processed_data, TRADE_START_DATE, end=TRADE_END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23819376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finrl.meta.env_portfolio_allocation.env_portfolio import StockPortfolioEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec932d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock dimensions: 7, State Space: 7\n"
     ]
    }
   ],
   "source": [
    "stock_dimensions = len(train.tic.unique())\n",
    "state_space = stock_dimensions\n",
    "print(f'Stock dimensions: {stock_dimensions}, State Space: {state_space}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63624830",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"transaction_cost_pct\": 0.005,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimensions,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimensions,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "}\n",
    "\n",
    "e_train_gym = StockPortfolioEnv(df=train, **env_kwargs)\n",
    "e_trade_gym = StockPortfolioEnv(df=trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d56ebdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_train = {\n",
    "    \"PPO\": {\n",
    "        \"total_timesteps\": 50000,\n",
    "        \"policy\": \"MlpPolicy\",\n",
    "        \"model_kwargs\": {\n",
    "            \"learning_rate\": 0.0003,\n",
    "            \"n_steps\": 2048,\n",
    "            \"batch_size\": 64,\n",
    "            \"n_epochs\": 10,\n",
    "            \"gamma\": 0.99,\n",
    "            \"gae_lambda\": 0.95,\n",
    "            \"clip_range\": 0.2,\n",
    "            \"vf_coef\": 0.5,\n",
    "            \"max_grad_norm\": 0.5,\n",
    "        },\n",
    "    },\n",
    "    \"A2C\": {\n",
    "        \"total_timesteps\": 50000,\n",
    "        \"policy\": \"MlpPolicy\",\n",
    "        \"model_kwargs\": {\n",
    "            'learning_rate': 0.0007,\n",
    "            'n_steps': 5,\n",
    "            'gamma': 0.99,\n",
    "            'gae_lambda': 1.0,\n",
    "            'ent_coef':0.01,\n",
    "            'vf_coef':0.25,\n",
    "            'max_grad_norm':0.5,\n",
    "        },\n",
    "    },\n",
    "    \"DDPG\": {\n",
    "        \"total_timesteps\": 50000,\n",
    "        \"policy\": \"MlpPolicy\",\n",
    "        \"model_kwargs\": {\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"buffer_size\": 1000000,\n",
    "            \"learning_starts\": 100,\n",
    "            \"batch_size\": 100,\n",
    "            \"tau\": 0.005,\n",
    "            \"gamma\": 0.99,\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9abedc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training PPO model...\n",
      "==================================================\n",
      "{'learning_rate': 0.0003, 'n_steps': 2048, 'batch_size': 64, 'n_epochs': 10, 'gamma': 0.99, 'gae_lambda': 0.95, 'clip_range': 0.2, 'vf_coef': 0.5, 'max_grad_norm': 0.5}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 430       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 4         |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 1324263.8 |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 375          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.837095e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.93        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.48e+14     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -2.52e-06    |\n",
      "|    reward               | 2719528.2    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 2.96e+14     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4091054.028799406\n",
      "Sharpe:  0.5045476914879545\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.04e+03    |\n",
      "|    ep_rew_mean          | 8.81e+09    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 365         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 8.20728e-09 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.93       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.11e+14    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -1.24e-06   |\n",
      "|    reward               | 1010028.7   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 9.53e+14    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.04e+03      |\n",
      "|    ep_rew_mean          | 8.81e+09      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 362           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 22            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.4133125e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.93         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.6e+14       |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -9.05e-07     |\n",
      "|    reward               | 1996947.1     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 1.56e+15      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4964827.623177167\n",
      "Sharpe:  0.5595792112965113\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.04e+03      |\n",
      "|    ep_rew_mean          | 9.54e+09      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 359           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 28            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.9267116e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.93         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.67e+14      |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -1.01e-06     |\n",
      "|    reward               | 993646.5      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 5.89e+14      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.04e+03     |\n",
      "|    ep_rew_mean          | 9.54e+09     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 356          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.627509e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.93        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.34e+15     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -5.97e-07    |\n",
      "|    reward               | 1062333.8    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 3.02e+15     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.04e+03      |\n",
      "|    ep_rew_mean          | 9.54e+09      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 353           |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 40            |\n",
      "|    total_timesteps      | 14336         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.8661985e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.93         |\n",
      "|    explained_variance   | 2.38e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.62e+14      |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | -2.61e-06     |\n",
      "|    reward               | 3258277.5     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 3.44e+14      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4870169.702211472\n",
      "Sharpe:  0.5553339447049154\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.04e+03      |\n",
      "|    ep_rew_mean          | 9.65e+09      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 352           |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 46            |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.9662852e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.93         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.07e+14      |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -8.23e-07     |\n",
      "|    reward               | 1116547.0     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 1.42e+15      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.04e+03      |\n",
      "|    ep_rew_mean          | 9.65e+09      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 350           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 52            |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.3842086e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.93         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.5e+14       |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -8.49e-07     |\n",
      "|    reward               | 2104827.0     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 1.85e+15      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4589096.809603399\n",
      "Sharpe:  0.5362716281378509\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.04e+03    |\n",
      "|    ep_rew_mean          | 9.65e+09    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 348         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 7.21775e-09 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.93       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.12e+14    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -1.07e-06   |\n",
      "|    reward               | 996901.5    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 6.02e+14    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.04e+03     |\n",
      "|    ep_rew_mean          | 9.65e+09     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 344          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.656613e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.93        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.19e+15     |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -6.03e-07    |\n",
      "|    reward               | 1099063.1    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 2.54e+15     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.04e+03     |\n",
      "|    ep_rew_mean          | 9.65e+09     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 343          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 71           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.265488e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.93        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.67e+14     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -1.81e-06    |\n",
      "|    reward               | 3222065.0    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 3.69e+14     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4340961.093736466\n",
      "Sharpe:  0.520481196841349\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.04e+03     |\n",
      "|    ep_rew_mean          | 9.58e+09     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 340          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 78           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.479684e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.93        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.99e+14     |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -1.01e-06    |\n",
      "|    reward               | 1105318.2    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.36e+15     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.04e+03      |\n",
      "|    ep_rew_mean          | 9.58e+09      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 339           |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 84            |\n",
      "|    total_timesteps      | 28672         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.2759576e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.93         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.08e+14      |\n",
      "|    n_updates            | 130           |\n",
      "|    policy_gradient_loss | -1.12e-06     |\n",
      "|    reward               | 2324391.8     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 1.29e+15      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4449629.9001342645\n",
      "Sharpe:  0.5299468733843398\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.04e+03     |\n",
      "|    ep_rew_mean          | 9.51e+09     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 338          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.799827e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.93        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.5e+14      |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -9.84e-07    |\n",
      "|    reward               | 919427.2     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 6.15e+14     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.04e+03     |\n",
      "|    ep_rew_mean          | 9.51e+09     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 337          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.296897e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.93        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.07e+15     |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -6.95e-07    |\n",
      "|    reward               | 1165701.0    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 2.21e+15     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.04e+03     |\n",
      "|    ep_rew_mean          | 9.51e+09     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 335          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 103          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.411007e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.93        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.61e+14     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -1.64e-06    |\n",
      "|    reward               | 3561423.2    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 3.37e+14     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4553608.216375265\n",
      "Sharpe:  0.5355454728297827\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.04e+03     |\n",
      "|    ep_rew_mean          | 9.44e+09     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 336          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 109          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.014023e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.93        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.48e+14     |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -8.2e-07     |\n",
      "|    reward               | 1347899.6    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.53e+15     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.04e+03     |\n",
      "|    ep_rew_mean          | 9.44e+09     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 336          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 115          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.469215e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.93        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.64e+14     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -1.12e-06    |\n",
      "|    reward               | 2824507.5    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.14e+15     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4900638.703469175\n",
      "Sharpe:  0.5577078484287507\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.04e+03     |\n",
      "|    ep_rew_mean          | 9.53e+09     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 336          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 121          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.326001e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.93        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.25e+14     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -7.29e-07    |\n",
      "|    reward               | 818095.1     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 8.54e+14     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.04e+03      |\n",
      "|    ep_rew_mean          | 9.53e+09      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 337           |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 127           |\n",
      "|    total_timesteps      | 43008         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.5774657e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.93         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.24e+15      |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | -1.07e-06     |\n",
      "|    reward               | 1411153.2     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 2.64e+15      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.04e+03     |\n",
      "|    ep_rew_mean          | 9.53e+09     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 337          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 133          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.807991e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.93        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.25e+14     |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -1.99e-06    |\n",
      "|    reward               | 4079367.5    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 4.1e+14      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4636675.567924543\n",
      "Sharpe:  0.5397633100825143\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.04e+03      |\n",
      "|    ep_rew_mean          | 9.57e+09      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 337           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 139           |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.6356733e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.93         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.21e+15      |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -6.6e-07      |\n",
      "|    reward               | 1392239.8     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 2.27e+15      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 5.04e+03      |\n",
      "|    ep_rew_mean          | 9.57e+09      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 337           |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 145           |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.1490725e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -9.93         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.49e+14      |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -1.44e-06     |\n",
      "|    reward               | 2742339.8     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 8.89e+14      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4245064.950769341\n",
      "Sharpe:  0.5155280262582684\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.04e+03     |\n",
      "|    ep_rew_mean          | 9.54e+09     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 337          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.119969e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.93        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.13e+14     |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -1.42e-06    |\n",
      "|    reward               | 750836.8     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 8.19e+14     |\n",
      "------------------------------------------\n",
      "PPO training completed and saved!\n",
      "\n",
      "==================================================\n",
      "Training A2C model...\n",
      "==================================================\n",
      "{'learning_rate': 0.0007, 'n_steps': 5, 'gamma': 0.99, 'gae_lambda': 1.0, 'ent_coef': 0.01, 'vf_coef': 0.25, 'max_grad_norm': 0.5}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -9.88    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 3.44e+07 |\n",
      "|    reward             | 979792.6 |\n",
      "|    std                | 0.993    |\n",
      "|    value_loss         | 1e+13    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.83     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 2.52e+07  |\n",
      "|    reward             | 1023717.4 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 1.08e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 305       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.76     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | 3.61e+07  |\n",
      "|    reward             | 1355324.8 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 1.94e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 305       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.72     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 4.89e+07  |\n",
      "|    reward             | 1784330.9 |\n",
      "|    std                | 0.971     |\n",
      "|    value_loss         | 3.2e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 305       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.69     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 4.29e+07  |\n",
      "|    reward             | 1513949.9 |\n",
      "|    std                | 0.966     |\n",
      "|    value_loss         | 2.36e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 306       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.65     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 5.57e+07  |\n",
      "|    reward             | 1795575.4 |\n",
      "|    std                | 0.961     |\n",
      "|    value_loss         | 3.9e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.6      |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 9.16e+07  |\n",
      "|    reward             | 2797062.2 |\n",
      "|    std                | 0.954     |\n",
      "|    value_loss         | 8.24e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.59     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 1.2e+08   |\n",
      "|    reward             | 3448413.2 |\n",
      "|    std                | 0.953     |\n",
      "|    value_loss         | 1.3e+14   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.56     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 1.26e+08  |\n",
      "|    reward             | 4539768.0 |\n",
      "|    std                | 0.948     |\n",
      "|    value_loss         | 2.16e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.58     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 1.6e+08   |\n",
      "|    reward             | 5390882.5 |\n",
      "|    std                | 0.951     |\n",
      "|    value_loss         | 3.04e+14  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5615492.111227334\n",
      "Sharpe:  0.6023271362641767\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.12e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 306       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.58     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 2.63e+07  |\n",
      "|    reward             | 848117.75 |\n",
      "|    std                | 0.952     |\n",
      "|    value_loss         | 7.38e+12  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.04e+03 |\n",
      "|    ep_rew_mean        | 1.12e+10 |\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -9.53    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 2.26e+07 |\n",
      "|    reward             | 839633.0 |\n",
      "|    std                | 0.944    |\n",
      "|    value_loss         | 7.71e+12 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.12e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.47     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 3e+07     |\n",
      "|    reward             | 1095230.2 |\n",
      "|    std                | 0.937     |\n",
      "|    value_loss         | 1.29e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.12e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.45     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 4.23e+07  |\n",
      "|    reward             | 1498672.6 |\n",
      "|    std                | 0.934     |\n",
      "|    value_loss         | 2.34e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.12e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.42     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 3.4e+07   |\n",
      "|    reward             | 1131850.8 |\n",
      "|    std                | 0.93      |\n",
      "|    value_loss         | 1.37e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.12e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.39     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 3.94e+07  |\n",
      "|    reward             | 1409020.1 |\n",
      "|    std                | 0.926     |\n",
      "|    value_loss         | 2.21e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.12e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.37     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 4.9e+07   |\n",
      "|    reward             | 2150139.2 |\n",
      "|    std                | 0.922     |\n",
      "|    value_loss         | 5.06e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.12e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 309       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 29        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.32     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 7.3e+07   |\n",
      "|    reward             | 2469930.0 |\n",
      "|    std                | 0.916     |\n",
      "|    value_loss         | 6.65e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.12e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 309       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 30        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.31     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 9.46e+07  |\n",
      "|    reward             | 3269443.2 |\n",
      "|    std                | 0.915     |\n",
      "|    value_loss         | 1.12e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.12e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 310       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.29     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 1.14e+08  |\n",
      "|    reward             | 3924273.5 |\n",
      "|    std                | 0.913     |\n",
      "|    value_loss         | 1.6e+14   |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4155366.1492426014\n",
      "Sharpe:  0.5105388473111382\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.04e+03 |\n",
      "|    ep_rew_mean        | 1.01e+10 |\n",
      "| time/                 |          |\n",
      "|    fps                | 309      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -9.26    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 2.53e+07 |\n",
      "|    reward             | 957691.3 |\n",
      "|    std                | 0.909    |\n",
      "|    value_loss         | 9.76e+12 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 310       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.24     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | 2.7e+07   |\n",
      "|    reward             | 873366.7  |\n",
      "|    std                | 0.906     |\n",
      "|    value_loss         | 8.04e+12  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 310       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.22     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 3.37e+07  |\n",
      "|    reward             | 1208810.5 |\n",
      "|    std                | 0.904     |\n",
      "|    value_loss         | 1.57e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 310       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.19     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 3.98e+07  |\n",
      "|    reward             | 1545617.9 |\n",
      "|    std                | 0.899     |\n",
      "|    value_loss         | 2.63e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 310       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.13     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | 3.39e+07  |\n",
      "|    reward             | 1233907.8 |\n",
      "|    std                | 0.891     |\n",
      "|    value_loss         | 1.6e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.12     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 4.95e+07  |\n",
      "|    reward             | 1490235.9 |\n",
      "|    std                | 0.89      |\n",
      "|    value_loss         | 3.14e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.07     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 5.51e+07  |\n",
      "|    reward             | 2341045.5 |\n",
      "|    std                | 0.884     |\n",
      "|    value_loss         | 5.71e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.02     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 7.38e+07  |\n",
      "|    reward             | 2865098.2 |\n",
      "|    std                | 0.878     |\n",
      "|    value_loss         | 8.69e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.99     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | 9.81e+07  |\n",
      "|    reward             | 3379152.8 |\n",
      "|    std                | 0.875     |\n",
      "|    value_loss         | 1.2e+14   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 312       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.94     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 9.82e+07  |\n",
      "|    reward             | 3962911.2 |\n",
      "|    std                | 0.868     |\n",
      "|    value_loss         | 1.7e+14   |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4224660.992516778\n",
      "Sharpe:  0.510690343493818\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 9.91e+09  |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.92     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | 2.83e+07  |\n",
      "|    reward             | 990459.5  |\n",
      "|    std                | 0.866     |\n",
      "|    value_loss         | 1.05e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 9.91e+09  |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.87     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 1.94e+07  |\n",
      "|    reward             | 825032.75 |\n",
      "|    std                | 0.859     |\n",
      "|    value_loss         | 7.17e+12  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 9.91e+09  |\n",
      "| time/                 |           |\n",
      "|    fps                | 312       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.8      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 3.09e+07  |\n",
      "|    reward             | 1173705.6 |\n",
      "|    std                | 0.851     |\n",
      "|    value_loss         | 1.5e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 9.91e+09  |\n",
      "| time/                 |           |\n",
      "|    fps                | 312       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.77     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 3.41e+07  |\n",
      "|    reward             | 1535460.6 |\n",
      "|    std                | 0.847     |\n",
      "|    value_loss         | 2.66e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 9.91e+09  |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.73     |\n",
      "|    explained_variance | 2.98e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 3.48e+07  |\n",
      "|    reward             | 1182504.9 |\n",
      "|    std                | 0.843     |\n",
      "|    value_loss         | 1.57e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 9.91e+09  |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.7      |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | 4.7e+07   |\n",
      "|    reward             | 1764731.2 |\n",
      "|    std                | 0.839     |\n",
      "|    value_loss         | 3.36e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 9.91e+09  |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.66     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 6.88e+07  |\n",
      "|    reward             | 2299083.5 |\n",
      "|    std                | 0.834     |\n",
      "|    value_loss         | 5.72e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 9.91e+09  |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.65     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 6.73e+07  |\n",
      "|    reward             | 2864354.8 |\n",
      "|    std                | 0.833     |\n",
      "|    value_loss         | 9.02e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 9.91e+09  |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.62     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 7.74e+07  |\n",
      "|    reward             | 3354603.5 |\n",
      "|    std                | 0.829     |\n",
      "|    value_loss         | 1.18e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 9.91e+09  |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 64        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.58     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 1.19e+08  |\n",
      "|    reward             | 3830279.8 |\n",
      "|    std                | 0.825     |\n",
      "|    value_loss         | 1.65e+14  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4335074.38436018\n",
      "Sharpe:  0.5202642585424422\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 9.85e+09  |\n",
      "| time/                 |           |\n",
      "|    fps                | 310       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.57     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 2.99e+07  |\n",
      "|    reward             | 1062711.0 |\n",
      "|    std                | 0.824     |\n",
      "|    value_loss         | 1.2e+13   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.04e+03 |\n",
      "|    ep_rew_mean        | 9.85e+09 |\n",
      "| time/                 |          |\n",
      "|    fps                | 310      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.56    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 1.91e+07 |\n",
      "|    reward             | 838589.1 |\n",
      "|    std                | 0.823    |\n",
      "|    value_loss         | 7.09e+12 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 9.85e+09  |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.54     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | 2.96e+07  |\n",
      "|    reward             | 1185952.9 |\n",
      "|    std                | 0.82      |\n",
      "|    value_loss         | 1.47e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 9.85e+09  |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 70        |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.53     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | 3.61e+07  |\n",
      "|    reward             | 1654293.1 |\n",
      "|    std                | 0.819     |\n",
      "|    value_loss         | 2.88e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 9.85e+09  |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.53     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | 2.52e+07  |\n",
      "|    reward             | 1206218.1 |\n",
      "|    std                | 0.818     |\n",
      "|    value_loss         | 1.53e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 9.85e+09  |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.48     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 5.48e+07  |\n",
      "|    reward             | 1953097.8 |\n",
      "|    std                | 0.813     |\n",
      "|    value_loss         | 4.09e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 9.85e+09  |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 75        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.47     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | 5.82e+07  |\n",
      "|    reward             | 2409519.5 |\n",
      "|    std                | 0.811     |\n",
      "|    value_loss         | 6.35e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 9.85e+09  |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 77        |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.44     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 8.43e+07  |\n",
      "|    reward             | 3224186.0 |\n",
      "|    std                | 0.808     |\n",
      "|    value_loss         | 1.09e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 9.85e+09  |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.42     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | 8.17e+07  |\n",
      "|    reward             | 3679679.8 |\n",
      "|    std                | 0.806     |\n",
      "|    value_loss         | 1.43e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 9.85e+09  |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 80        |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.38     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | 9.38e+07  |\n",
      "|    reward             | 4442436.0 |\n",
      "|    std                | 0.802     |\n",
      "|    value_loss         | 2.04e+14  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4861146.475340914\n",
      "Sharpe:  0.5513911535143038\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.04e+03   |\n",
      "|    ep_rew_mean        | 1e+10      |\n",
      "| time/                 |            |\n",
      "|    fps                | 311        |\n",
      "|    iterations         | 5100       |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 25500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.34      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5099       |\n",
      "|    policy_loss        | 2.4e+07    |\n",
      "|    reward             | 1003753.56 |\n",
      "|    std                | 0.797      |\n",
      "|    value_loss         | 1.26e+13   |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.04e+03 |\n",
      "|    ep_rew_mean        | 1e+10    |\n",
      "| time/                 |          |\n",
      "|    fps                | 311      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.31    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 1.75e+07 |\n",
      "|    reward             | 787614.3 |\n",
      "|    std                | 0.793    |\n",
      "|    value_loss         | 6e+12    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1e+10     |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 85        |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.32     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | 3.7e+07   |\n",
      "|    reward             | 1226527.1 |\n",
      "|    std                | 0.795     |\n",
      "|    value_loss         | 1.64e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1e+10     |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 86        |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.28     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 3.85e+07  |\n",
      "|    reward             | 1524494.8 |\n",
      "|    std                | 0.79      |\n",
      "|    value_loss         | 2.5e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1e+10     |\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 88        |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.24     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | 2.54e+07  |\n",
      "|    reward             | 994249.4  |\n",
      "|    std                | 0.786     |\n",
      "|    value_loss         | 1.28e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1e+10     |\n",
      "| time/                 |           |\n",
      "|    fps                | 312       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 89        |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.21     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | 4.85e+07  |\n",
      "|    reward             | 1928398.0 |\n",
      "|    std                | 0.782     |\n",
      "|    value_loss         | 4e+13     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1e+10     |\n",
      "| time/                 |           |\n",
      "|    fps                | 312       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 91        |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.16     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | 5.33e+07  |\n",
      "|    reward             | 2394598.0 |\n",
      "|    std                | 0.777     |\n",
      "|    value_loss         | 6.17e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1e+10     |\n",
      "| time/                 |           |\n",
      "|    fps                | 312       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 92        |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.14     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | 7.67e+07  |\n",
      "|    reward             | 3288875.2 |\n",
      "|    std                | 0.774     |\n",
      "|    value_loss         | 1.12e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1e+10     |\n",
      "| time/                 |           |\n",
      "|    fps                | 312       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 94        |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.08     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 8.81e+07  |\n",
      "|    reward             | 3672806.8 |\n",
      "|    std                | 0.768     |\n",
      "|    value_loss         | 1.41e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1e+10     |\n",
      "| time/                 |           |\n",
      "|    fps                | 312       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.05     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | 8.53e+07  |\n",
      "|    reward             | 4315816.5 |\n",
      "|    std                | 0.764     |\n",
      "|    value_loss         | 1.87e+14  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4943532.77304962\n",
      "Sharpe:  0.558417664099913\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 312       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 97        |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8        |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | 2.04e+07  |\n",
      "|    reward             | 1111892.8 |\n",
      "|    std                | 0.759     |\n",
      "|    value_loss         | 1.3e+13   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.04e+03 |\n",
      "|    ep_rew_mean        | 1.01e+10 |\n",
      "| time/                 |          |\n",
      "|    fps                | 312      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.94    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 1.86e+07 |\n",
      "|    reward             | 823975.3 |\n",
      "|    std                | 0.753    |\n",
      "|    value_loss         | 7.83e+12 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 312       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 100       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.91     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 4.03e+07  |\n",
      "|    reward             | 1188184.9 |\n",
      "|    std                | 0.751     |\n",
      "|    value_loss         | 1.48e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 312       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 102       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.92     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 3.93e+07  |\n",
      "|    reward             | 1525448.9 |\n",
      "|    std                | 0.751     |\n",
      "|    value_loss         | 2.52e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 103       |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.93     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | 2.95e+07  |\n",
      "|    reward             | 1235651.5 |\n",
      "|    std                | 0.752     |\n",
      "|    value_loss         | 1.39e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.92     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | 3.9e+07   |\n",
      "|    reward             | 1710576.0 |\n",
      "|    std                | 0.751     |\n",
      "|    value_loss         | 3.08e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 106       |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.92     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | 4.62e+07  |\n",
      "|    reward             | 2038112.9 |\n",
      "|    std                | 0.752     |\n",
      "|    value_loss         | 4.53e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.86     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | 5.72e+07  |\n",
      "|    reward             | 2973874.0 |\n",
      "|    std                | 0.745     |\n",
      "|    value_loss         | 8.91e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 110       |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.86     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | 6.59e+07  |\n",
      "|    reward             | 3257186.2 |\n",
      "|    std                | 0.745     |\n",
      "|    value_loss         | 1.09e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 111       |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.83     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | 1.14e+08  |\n",
      "|    reward             | 3792108.8 |\n",
      "|    std                | 0.742     |\n",
      "|    value_loss         | 1.63e+14  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4517104.68646669\n",
      "Sharpe:  0.5366109453888943\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 5.04e+03   |\n",
      "|    ep_rew_mean        | 1.01e+10   |\n",
      "| time/                 |            |\n",
      "|    fps                | 313        |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 113        |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.81      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7099       |\n",
      "|    policy_loss        | 2.67e+07   |\n",
      "|    reward             | 1048466.94 |\n",
      "|    std                | 0.74       |\n",
      "|    value_loss         | 1.19e+13   |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.04e+03 |\n",
      "|    ep_rew_mean        | 1.01e+10 |\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.8     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 1.81e+07 |\n",
      "|    reward             | 775554.7 |\n",
      "|    std                | 0.739    |\n",
      "|    value_loss         | 5.94e+12 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 116       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.79     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | 2.51e+07  |\n",
      "|    reward             | 1066979.4 |\n",
      "|    std                | 0.738     |\n",
      "|    value_loss         | 1.21e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 118       |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.78     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | 2.81e+07  |\n",
      "|    reward             | 1393312.6 |\n",
      "|    std                | 0.737     |\n",
      "|    value_loss         | 2.01e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 119       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.72     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 3.12e+07  |\n",
      "|    reward             | 1151922.8 |\n",
      "|    std                | 0.731     |\n",
      "|    value_loss         | 1.46e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 121       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.68     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | 3.21e+07  |\n",
      "|    reward             | 1606156.9 |\n",
      "|    std                | 0.727     |\n",
      "|    value_loss         | 2.61e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 122       |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.63     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | 3.85e+07  |\n",
      "|    reward             | 1996565.6 |\n",
      "|    std                | 0.721     |\n",
      "|    value_loss         | 4.44e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 124       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.62     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | 7.16e+07  |\n",
      "|    reward             | 2806251.5 |\n",
      "|    std                | 0.72      |\n",
      "|    value_loss         | 7.82e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 125       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.59     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | 7.21e+07  |\n",
      "|    reward             | 3144887.8 |\n",
      "|    std                | 0.717     |\n",
      "|    value_loss         | 1.06e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 127       |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.57     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | 9.48e+07  |\n",
      "|    reward             | 3940484.8 |\n",
      "|    std                | 0.715     |\n",
      "|    value_loss         | 1.75e+14  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4531885.420018249\n",
      "Sharpe:  0.5350636267159271\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 312       |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.53     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | 2.26e+07  |\n",
      "|    reward             | 1082741.5 |\n",
      "|    std                | 0.711     |\n",
      "|    value_loss         | 1.22e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 130       |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.53     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | 1.58e+07  |\n",
      "|    reward             | 714889.94 |\n",
      "|    std                | 0.711     |\n",
      "|    value_loss         | 5.46e+12  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 132       |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.48     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | 2.05e+07  |\n",
      "|    reward             | 1026953.8 |\n",
      "|    std                | 0.706     |\n",
      "|    value_loss         | 1.13e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 134       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.47     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | 2.5e+07   |\n",
      "|    reward             | 1333805.9 |\n",
      "|    std                | 0.705     |\n",
      "|    value_loss         | 1.9e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 135       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.45     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | 3.44e+07  |\n",
      "|    reward             | 1459389.9 |\n",
      "|    std                | 0.703     |\n",
      "|    value_loss         | 2.5e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 137       |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.45     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | 3.18e+07  |\n",
      "|    reward             | 1552247.0 |\n",
      "|    std                | 0.703     |\n",
      "|    value_loss         | 2.43e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 138       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.4      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 4.09e+07  |\n",
      "|    reward             | 2067509.2 |\n",
      "|    std                | 0.699     |\n",
      "|    value_loss         | 4.62e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 140       |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.38     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 5.77e+07  |\n",
      "|    reward             | 2917088.8 |\n",
      "|    std                | 0.697     |\n",
      "|    value_loss         | 8.97e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 141       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.37     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 6.78e+07  |\n",
      "|    reward             | 3262416.5 |\n",
      "|    std                | 0.696     |\n",
      "|    value_loss         | 1.16e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 143       |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.33     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | 8.35e+07  |\n",
      "|    reward             | 4092904.0 |\n",
      "|    std                | 0.692     |\n",
      "|    value_loss         | 1.75e+14  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4608679.43044621\n",
      "Sharpe:  0.5475884409329335\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 145       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.28     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 2.52e+07  |\n",
      "|    reward             | 1081187.4 |\n",
      "|    std                | 0.687     |\n",
      "|    value_loss         | 1.18e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.21     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 1.63e+07  |\n",
      "|    reward             | 837173.94 |\n",
      "|    std                | 0.68      |\n",
      "|    value_loss         | 7.15e+12  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 148       |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.16     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | 2.33e+07  |\n",
      "|    reward             | 1080504.5 |\n",
      "|    std                | 0.676     |\n",
      "|    value_loss         | 1.23e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 149       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.13     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 3.12e+07  |\n",
      "|    reward             | 1446726.4 |\n",
      "|    std                | 0.673     |\n",
      "|    value_loss         | 2.12e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.1      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | 3.57e+07  |\n",
      "|    reward             | 1692410.6 |\n",
      "|    std                | 0.669     |\n",
      "|    value_loss         | 3.12e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 152       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.08     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | 2.78e+07  |\n",
      "|    reward             | 1587071.2 |\n",
      "|    std                | 0.667     |\n",
      "|    value_loss         | 2.63e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 154       |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.08     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 4.18e+07  |\n",
      "|    reward             | 2131971.8 |\n",
      "|    std                | 0.667     |\n",
      "|    value_loss         | 4.99e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 314       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 156       |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.03     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | 7.13e+07  |\n",
      "|    reward             | 3156263.5 |\n",
      "|    std                | 0.663     |\n",
      "|    value_loss         | 1.07e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 314       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 157       |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.03     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | 7.73e+07  |\n",
      "|    reward             | 3460577.5 |\n",
      "|    std                | 0.663     |\n",
      "|    value_loss         | 1.22e+14  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.04e+03  |\n",
      "|    ep_rew_mean        | 1.01e+10  |\n",
      "| time/                 |           |\n",
      "|    fps                | 314       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 159       |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.99     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | 8e+07     |\n",
      "|    reward             | 4249345.0 |\n",
      "|    std                | 0.659     |\n",
      "|    value_loss         | 1.92e+14  |\n",
      "-------------------------------------\n",
      "A2C training completed and saved!\n",
      "\n",
      "==================================================\n",
      "Training DDPG model...\n",
      "==================================================\n",
      "{'learning_rate': 0.001, 'buffer_size': 1000000, 'learning_starts': 100, 'batch_size': 100, 'tau': 0.005, 'gamma': 0.99}\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5226793.8432835955\n",
      "Sharpe:  0.6091822175020843\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5036593.859951914\n",
      "Sharpe:  0.5973508372747074\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5036593.859951914\n",
      "Sharpe:  0.5973508372747074\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5036593.859951914\n",
      "Sharpe:  0.5973508372747074\n",
      "=================================\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 5.04e+03  |\n",
      "|    ep_rew_mean     | 1.03e+10  |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 142       |\n",
      "|    time_elapsed    | 141       |\n",
      "|    total_timesteps | 20152     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.2e+08  |\n",
      "|    critic_loss     | 5.48e+11  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 20051     |\n",
      "|    reward          | 5036594.0 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5036593.859951914\n",
      "Sharpe:  0.5973508372747074\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5036593.859951914\n",
      "Sharpe:  0.5973508372747074\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5036593.859951914\n",
      "Sharpe:  0.5973508372747074\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5036593.859951914\n",
      "Sharpe:  0.5973508372747074\n",
      "=================================\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 5.04e+03  |\n",
      "|    ep_rew_mean     | 1.02e+10  |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 141       |\n",
      "|    time_elapsed    | 284       |\n",
      "|    total_timesteps | 40304     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.59e+08 |\n",
      "|    critic_loss     | 2.25e+12  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 40203     |\n",
      "|    reward          | 5036594.0 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:5036593.859951914\n",
      "Sharpe:  0.5973508372747074\n",
      "=================================\n",
      "DDPG training completed and saved!\n",
      "\n",
      "Successfully trained 3 models\n"
     ]
    }
   ],
   "source": [
    "trained_models = {}\n",
    "model_results = {}\n",
    "\n",
    "for model_name, config in models_to_train.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {model_name} model...\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    try:\n",
    "        agent = DRLAgent(env=e_train_gym)\n",
    "\n",
    "        model = agent.get_model(\n",
    "            model_name=model_name.lower(),\n",
    "            policy=config[\"policy\"],\n",
    "            model_kwargs=config[\"model_kwargs\"],\n",
    "        )\n",
    "\n",
    "        trained_model = agent.train_model(\n",
    "            model=model,\n",
    "            total_timesteps=config[\"total_timesteps\"],\n",
    "            tb_log_name=model_name.lower(),\n",
    "        )\n",
    "\n",
    "        model_path = f\"{TRAINED_MODEL_DIR}/{model_name.lower()}_ff_model\"\n",
    "        trained_model.save(model_path)\n",
    "        trained_models[model_name] = trained_model\n",
    "\n",
    "        print(f\"{model_name} training completed and saved!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error training {model_name}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nSuccessfully trained {len(trained_models)} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8e930da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, model_name, env):\n",
    "    \"\"\" \"\n",
    "    Test a trained model return results\n",
    "    \"\"\"\n",
    "    print(f\"\\nTesting {model_name}...\")\n",
    "\n",
    "    obs = env.reset()\n",
    "\n",
    "    for i in range(len(env.get_attr(\"df\")[0].index.unique()) - 1):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        if dones:\n",
    "            break\n",
    "\n",
    "    asset_memory = env.get_attr(\"asset_memory\")[0]\n",
    "    daily_returns = np.diff(asset_memory) / asset_memory[:-1]\n",
    "\n",
    "    results = {\n",
    "        \"final_value\": asset_memory[-1],\n",
    "        \"total_return\": (asset_memory[-1] / env.get_attr(\"initial_amount\")[0] - 1)\n",
    "        * 100,\n",
    "        \"daily_returns\": daily_returns,\n",
    "        \"asset_memory\": asset_memory,\n",
    "        \"date_memory\": env.get_attr(\"date_memory\")[0],\n",
    "        \"actions_memory\": env.get_attr(\"actions_memory\")[0],\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31992e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing PPO...\n",
      "PPO Results:\n",
      " Final Portfolio Value: $1,439,709.65\n",
      " Total Return: 43.97%\n",
      " Sharpe Ratio: 0.6353\n",
      " Max Drawdown: -0.4051\n",
      "\n",
      "Testing A2C...\n",
      "A2C Results:\n",
      " Final Portfolio Value: $1,484,404.91\n",
      " Total Return: 48.44%\n",
      " Sharpe Ratio: 0.6744\n",
      " Max Drawdown: -0.4227\n",
      "\n",
      "Testing DDPG...\n",
      "DDPG Results:\n",
      " Final Portfolio Value: $1,332,054.91\n",
      " Total Return: 33.21%\n",
      " Sharpe Ratio: 0.5481\n",
      " Max Drawdown: -0.3376\n"
     ]
    }
   ],
   "source": [
    "test_results = {}\n",
    "\n",
    "for model_name, model in trained_models.items():\n",
    "    try:\n",
    "        # Create a vectorized environment for testing\n",
    "        test_env = DummyVecEnv([lambda: e_trade_gym])\n",
    "\n",
    "        # Reset test environment\n",
    "        obs = test_env.reset()\n",
    "\n",
    "        # Test model\n",
    "        results = test_model(model, model_name, test_env)\n",
    "        test_results[model_name] = results\n",
    "\n",
    "        print(f\"{model_name} Results:\")\n",
    "        print(f\" Final Portfolio Value: ${results['final_value']:,.2f}\")\n",
    "        print(f\" Total Return: {results['total_return']:.2f}%\")\n",
    "\n",
    "        # Calculate additional metrics\n",
    "        daily_returns = pd.Series(results[\"daily_returns\"])\n",
    "        sharpe_ratio = daily_returns.mean() / daily_returns.std() * np.sqrt(252)\n",
    "        max_drawdown = daily_returns.cumsum().min()\n",
    "\n",
    "        print(f\" Sharpe Ratio: {sharpe_ratio:.4f}\")\n",
    "        print(f\" Max Drawdown: {max_drawdown:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error testing {model_name}: {str(e)}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e9cff68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Ranking:\n",
      "Model  Final Value  Total Return (%)  Sharpe Ratio  Max Drawdown\n",
      "  A2C 1.484405e+06         48.440491      0.674410     -0.436207\n",
      "  PPO 1.439710e+06         43.970965      0.635252     -0.433477\n",
      " DDPG 1.332055e+06         33.205491      0.548114     -0.375929\n"
     ]
    }
   ],
   "source": [
    "# Create comparsion dataframe\n",
    "comparison_data = []\n",
    "for model_name, results in test_results.items():\n",
    "    daily_returns = pd.Series(results['daily_returns'])\n",
    "    sharpe_ratio = daily_returns.mean() / daily_returns.std() * np.sqrt(252)\n",
    "    max_drawdown = (daily_returns.cumsum() - daily_returns.cumsum().expanding().max()).min()\n",
    "\n",
    "    comparison_data.append({\n",
    "        'Model': model_name,\n",
    "        'Final Value': results['final_value'],\n",
    "        'Total Return (%)': results['total_return'],\n",
    "        'Sharpe Ratio': sharpe_ratio,\n",
    "        'Max Drawdown': max_drawdown\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('Total Return (%)', ascending=False)\n",
    "\n",
    "print(\"\\nModel Performance Ranking:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save results\n",
    "comparison_df.to_csv(f\"{RESULTS_DIR}/industry_model_comparison_{lookback}_window.csv\", index=False)\n",
    "\n",
    "# Create performance visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Portfolio Value Over Time\n",
    "plt.subplot(2, 2, 1)\n",
    "for model_name, results in test_results.items():\n",
    "    dates = pd.to_datetime(results['date_memory'])\n",
    "    values = results['asset_memory']\n",
    "    plt.plot(dates, values, label=f\"{model_name}\", linewidth=2)\n",
    "\n",
    "plt.title('Portfolio Value Over Time (Industry Model: {} Window)'.format(lookback))\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Portfolio Value ($)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Plot 2: Total Returns Comparison\n",
    "plt.subplot(2, 2, 2)\n",
    "models = comparison_df['Model']\n",
    "returns = comparison_df['Total Return (%)']\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(models)))\n",
    "bars = plt.bar(models, returns, color=colors)\n",
    "plt.title('Total Returns Comparison')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Total Return (%)')\n",
    "plt.xticks(rotation=45)\n",
    "for bar, ret in zip(bars, returns):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "             f'{ret:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "# Plot 3: Sharpe Ratio Comparison\n",
    "plt.subplot(2, 2, 3)\n",
    "sharpe_ratios = comparison_df['Sharpe Ratio']\n",
    "bars = plt.bar(models, sharpe_ratios, color=colors)\n",
    "plt.title('Sharpe Ratio Comparison')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Sharpe Ratio')\n",
    "plt.xticks(rotation=45)\n",
    "for bar, sharpe in zip(bars, sharpe_ratios):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{sharpe:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Plot 4: Max Drawdown Comparison (negative values, so we flip for visualization)\n",
    "plt.subplot(2, 2, 4)\n",
    "drawdowns = comparison_df['Max Drawdown'].abs()\n",
    "bars = plt.bar(models, drawdowns, color=colors)\n",
    "plt.title('Max Drawdown Comparison')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Max Drawdown (abs)')\n",
    "plt.xticks(rotation=45)\n",
    "for bar, dd in zip(bars, drawdowns):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001, \n",
    "             f'{dd:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RESULTS_DIR}/industry_model_comparison_{lookback}_window.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fddb04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summerresearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
